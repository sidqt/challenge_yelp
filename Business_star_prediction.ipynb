{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChandiniNagendra\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import io\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "import collections\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Open business.json file, create tsv file with business_id, business name, categories, and review count to be used as features \n",
    "#and stars as label\n",
    "\n",
    "outfile = open(\"business.tsv\", 'w')\n",
    "sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "sfile.writerow(['business_id','categories', 'stars', 'review_count', 'postal code'])\n",
    "with open('yelp_academic_dataset_business.json', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        sfile.writerow([row['business_id'], row['categories'], row['stars'], row['review_count'], row['postal_code']])\n",
    "\n",
    "outfile.close()\n",
    "\n",
    "business_df= pd.read_csv('business.tsv', delimiter =\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Open review.json file, create tsv file with business_id,text to be used as features \n",
    "#and stars as label\n",
    "\n",
    "outfile = open(\"review_stars.tsv\", 'w')\n",
    "sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "sfile.writerow(['business_id','stars', 'text'])\n",
    "with open('yelp_academic_dataset_review.json', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        # some special char must be encoded in 'utf-8'\n",
    "        sfile.writerow([row['business_id'], row['stars'], (row['text']).encode('utf-8')])\n",
    "\n",
    "outfile.close()\n",
    "\n",
    "review_df= pd.read_csv('review_stars.tsv', delimiter =\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Group all reviews by business_id\n",
    "review_agg_df = review_df.groupby('business_id')['text'].sum()\n",
    "review_df_ready_for_sklearn = pd.DataFrame({'business_id': review_agg_df.index, 'all_reviews': review_agg_df.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Merge the resulting review aggregate dataframe with business dataframe\n",
    "merge_df = pd.merge(business_df, review_df_ready_for_sklearn, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Normalization of review count field so it becomes comparable and remove bias\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "merge_df.insert(3,'normalized_count',((merge_df['review_count'] - merge_df['review_count'].min()) / (merge_df['review_count'].max() - merge_df['review_count'].min())).astype(float))\n",
    "merge_df['review_count'] = zscore(merge_df['review_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# removing NaN categories\n",
    "\n",
    "merge_df = merge_df[merge_df['categories'].notnull()]\n",
    "merge_df = merge_df[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extracting categories\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "encoded_categories = MultiLabelBinarizer()\n",
    "category_matrix = encoded_categories.fit_transform(merge_df['categories'].str.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TF-IDF calculation\n",
    "\n",
    "tfidf = sk_text.TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    " stop_words= 'english',ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit the reviews column with TFIDFvectorizer\n",
    "matrix = tfidf.fit_transform(merge_df['all_reviews'])\n",
    "matrix = matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We are adding the normalized count to the original matrix with TFIDFvectorizer\n",
    "x_matrix_minmax = np.column_stack((matrix, merge_df['normalized_count']))\n",
    "\n",
    "# Zscore\n",
    "x_matrix_zscore = np.column_stack((matrix, merge_df['review_count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train test data for linear regression\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_matrix_minmax, merge_df['stars'] , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training and prediction using Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# linear regression\n",
    "\n",
    "lin_reg_model = LinearRegression()\n",
    "\n",
    "lin_reg_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred_linear = lin_reg_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - hTF1Qo6PRFnDgg1rh9a9BQ actual stars  - 4.000000 predicted - 3.643041\n",
      "business id - bAPjkuNJ67j2F4C5HQQHhQ actual stars  - 4.000000 predicted - 3.900257\n",
      "business id - dFcs3q8ynbFEaAnbyGSLjQ actual stars  - 4.000000 predicted - 4.197429\n",
      "business id - jrhc4s5XMR8S8kpGdU08og actual stars  - 4.500000 predicted - 4.797609\n",
      "business id - e7207sqC-pSn6GIf31ikhQ actual stars  - 4.000000 predicted - 3.765016\n",
      "business id - CF9TxeEdP5QxihYFAl4sUg actual stars  - 4.000000 predicted - 4.057981\n",
      "business id - zZPCAFK85NtitSNVP_wfYg actual stars  - 3.500000 predicted - 3.503671\n",
      "business id - 42U4Vlzr7nmQa1Bk8J4flw actual stars  - 5.000000 predicted - 4.855848\n",
      "business id - TTrYd662CZFRPaiwl-sUqA actual stars  - 2.000000 predicted - 1.747432\n",
      "business id - -lBIxCbHxuN3YO_sUkWeUQ actual stars  - 2.500000 predicted - 2.484346\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test.index[i]\n",
    "    print(\"business id - %s actual stars  - %f predicted - %f\" \n",
    "          %(merge_df['business_id'][idx], y_test[idx], y_pred_linear[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.56\n",
      "R2 score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# RMS value\n",
    "\n",
    "score_lin_classic = np.sqrt(mean_squared_error(y_test, y_pred_linear))\n",
    "print(\"Root Mean Squared Error: %.2f\" % score_lin_classic)\n",
    "print('R2 score: %.2f' % r2_score(y_test, y_pred_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# label encoding data for logistic regression\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "merge_df['encoded_stars'] = label_encoder.fit_transform(merge_df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train test data afor other models\n",
    "\n",
    "x_train_lr, x_test_lr, y_train_lr, y_test_lr = train_test_split(x_matrix_minmax, merge_df['encoded_stars'] , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# logistic Regression\n",
    "\n",
    "Log_reg_model = LogisticRegression()\n",
    "\n",
    "Log_reg_model.fit(x_train_lr, y_train_lr)\n",
    "\n",
    "y_pred_logistic = Log_reg_model.predict(x_test_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 1.38\n",
      "R2 score: 0.54\n"
     ]
    }
   ],
   "source": [
    "# RMs for logistic\n",
    "\n",
    "score_log_classic = np.sqrt(mean_squared_error(y_test_lr, y_pred_logistic))\n",
    "print(\"Root Mean Squared Error: %.2f\" % score_log_classic)\n",
    "print('R2 score: %.2f' % r2_score(y_test_lr, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tensorflow Model for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Training without early stopping and Model Checkpoint and RELU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Tensor flow works well with 32 bit\n",
    "y_stars_regression = merge_df['stars'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_matrix_minmax, y_stars_regression , test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with RELU\n",
    "\n",
    "model_reg_relu = Sequential()\n",
    "\n",
    "model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "model_reg_relu.add(Dense(1)) # Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 2.0906\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.3293\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.2660\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.2482\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2355\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.2105\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.1797\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1524\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.1240\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.1018\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0840\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0712\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0596\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0513\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0440\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0399\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0342\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0301\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0282\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0261\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0242\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0228\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0203\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0193\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0191\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0175\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0167\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0156\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0165\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0146\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0141\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0123\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0119\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0124\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0122\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0114\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0123\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0119\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0107\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0105\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0102\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0091\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0097\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0089\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0083\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0084\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0083\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0090\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0088\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.0084\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.0081\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0077\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0071\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0073\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0070\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0068\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0065\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0064\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0070\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0076\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0073\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0070\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0070\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0062\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0054\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0057\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0059\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0059\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0058\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0058\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0060\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0059\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0057\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.0060\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.0057\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0047\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0043\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0049\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0054\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.0054\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0045\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0044\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0042\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0045\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0049\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0046\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0047\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0044\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0042\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0042\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0043\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0040\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0040\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0040\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26005d9b6d8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model training with Optimizer = adam\n",
    "\n",
    "model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_reg_relu.fit(x_train_reg,y_train_reg,verbose=2,epochs=100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_simple = model_reg_relu.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_simple.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [2.1067386]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.568747]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.682547]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [4.0523095]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.590995]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.7832203]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.6607018]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [5.4459567]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.0730624]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.7443786]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_simple[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5928863883018494\n",
      "R2 score: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_relu = np.sqrt(mean_squared_error(y_test_reg,pred_reg_simple))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_relu))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Training with early stopping and Model Checkpoint ReLU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.4768 - val_loss: 0.4563\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45625, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.3558 - val_loss: 0.3284\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45625 to 0.32835, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.2714 - val_loss: 0.2928\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32835 to 0.29276, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.2460 - val_loss: 0.2977\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.29276\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2301 - val_loss: 0.2890\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.29276 to 0.28904, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.2135 - val_loss: 0.2829\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.28904 to 0.28294, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.1873 - val_loss: 0.2782\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.28294 to 0.27818, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1612 - val_loss: 0.2712\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.27818 to 0.27118, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1369 - val_loss: 0.2728\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27118\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.1124 - val_loss: 0.2738\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27118\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0937 - val_loss: 0.2804\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27118\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0783 - val_loss: 0.2826\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27118\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0656 - val_loss: 0.2896\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27118\n",
      "Epoch 00013: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.9250 - val_loss: 0.4230\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27118\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.3345 - val_loss: 0.3111\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27118\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.2664 - val_loss: 0.3002\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27118\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.2416 - val_loss: 0.2839\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27118\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2170 - val_loss: 0.2789\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27118\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1908 - val_loss: 0.2777\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27118\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1693 - val_loss: 0.2713\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27118\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1460 - val_loss: 0.2755\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27118\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1240 - val_loss: 0.2880\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27118\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.1045 - val_loss: 0.2874\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27118\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0870 - val_loss: 0.2946\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27118\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0730 - val_loss: 0.2980\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27118\n",
      "Epoch 00012: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.1535 - val_loss: 0.4590\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27118\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3600 - val_loss: 0.3180\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27118\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2752 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27118\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.2519 - val_loss: 0.2920\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27118\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2382 - val_loss: 0.2941\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27118\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.2322 - val_loss: 0.2981\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27118\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.2137 - val_loss: 0.2847\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27118\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.1912 - val_loss: 0.2782\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27118\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.1740 - val_loss: 0.2806\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27118\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.1532 - val_loss: 0.2819\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27118\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.1325 - val_loss: 0.2874\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27118\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.1091 - val_loss: 0.2996\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27118\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0920 - val_loss: 0.2992\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27118\n",
      "Epoch 00013: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.8565 - val_loss: 0.3893\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27118\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3182 - val_loss: 0.2973\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27118\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2615 - val_loss: 0.2997\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27118\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2418 - val_loss: 0.2982\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27118\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2233 - val_loss: 0.2907\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27118\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.1980 - val_loss: 0.2897\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27118\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.1655 - val_loss: 0.2836\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27118\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.1338 - val_loss: 0.2856\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27118\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1074 - val_loss: 0.2887\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27118\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0852 - val_loss: 0.2938\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27118\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0707 - val_loss: 0.2940\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27118\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0581 - val_loss: 0.3040\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27118\n",
      "Epoch 00012: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.0521 - val_loss: 0.4513\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27118\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3474 - val_loss: 0.3152\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27118\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2704 - val_loss: 0.2981\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27118\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2494 - val_loss: 0.3017\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27118\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2382 - val_loss: 0.2930\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27118\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2296 - val_loss: 0.2873\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27118\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2085 - val_loss: 0.2905\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27118\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.1836 - val_loss: 0.2892\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27118\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.1578 - val_loss: 0.2789\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27118\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.1346 - val_loss: 0.2873\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27118\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.1129 - val_loss: 0.2871\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27118\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0937 - val_loss: 0.2960\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27118\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0788 - val_loss: 0.2987\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27118\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0658 - val_loss: 0.3009\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.27118\n",
      "Epoch 00014: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.0479 - val_loss: 0.4143\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27118\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.3346 - val_loss: 0.3059\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27118\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.2648 - val_loss: 0.2900\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27118\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.2440 - val_loss: 0.2926\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27118\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2291 - val_loss: 0.2889\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27118\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2122 - val_loss: 0.2850\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27118\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1840 - val_loss: 0.2827\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27118\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.1588 - val_loss: 0.2776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27118\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1322 - val_loss: 0.2820\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27118\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1091 - val_loss: 0.2993\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27118\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0900 - val_loss: 0.2922\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27118\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0741 - val_loss: 0.2974\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27118\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0615 - val_loss: 0.3067\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27118\n",
      "Epoch 00013: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.9543 - val_loss: 0.3867\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27118\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.3119 - val_loss: 0.3037\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27118\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.2562 - val_loss: 0.2886\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27118\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2385 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27118\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2209 - val_loss: 0.2859\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27118\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1969 - val_loss: 0.2981\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27118\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1660 - val_loss: 0.2747\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27118\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1334 - val_loss: 0.2770\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27118\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1049 - val_loss: 0.2894\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27118\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0853 - val_loss: 0.2921\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27118\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0675 - val_loss: 0.2947\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27118\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0554 - val_loss: 0.2960\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27118\n",
      "Epoch 00012: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.1019 - val_loss: 0.4284\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27118\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.3339 - val_loss: 0.3100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27118\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.2638 - val_loss: 0.2941\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27118\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.2380 - val_loss: 0.2928\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27118\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2189 - val_loss: 0.2921\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27118\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1937 - val_loss: 0.2877\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27118\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1603 - val_loss: 0.2854\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27118\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1276 - val_loss: 0.2842\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27118\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.1040 - val_loss: 0.2885\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27118\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0840 - val_loss: 0.2982\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27118\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0676 - val_loss: 0.2999\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27118\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0559 - val_loss: 0.3025\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27118\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0467 - val_loss: 0.3128\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27118\n",
      "Epoch 00013: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.9889 - val_loss: 0.4021\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27118\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3209 - val_loss: 0.3026\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27118\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2606 - val_loss: 0.2937\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27118\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.2398 - val_loss: 0.2914\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27118\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2253 - val_loss: 0.2906\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27118\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.2019 - val_loss: 0.2879\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27118\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1755 - val_loss: 0.2832\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27118\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.1470 - val_loss: 0.2859\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27118\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.1233 - val_loss: 0.2889\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27118\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0994 - val_loss: 0.2944\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27118\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0812 - val_loss: 0.2978\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27118\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0672 - val_loss: 0.3063\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27118\n",
      "Epoch 00012: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.9426 - val_loss: 0.4182\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27118\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3258 - val_loss: 0.3093\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27118\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2635 - val_loss: 0.2862\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27118\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2477 - val_loss: 0.2889\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27118\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2332 - val_loss: 0.2909\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27118\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.2103 - val_loss: 0.2840\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27118\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.1815 - val_loss: 0.2837\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27118\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.1525 - val_loss: 0.2762\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27118\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1268 - val_loss: 0.2906\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27118\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1031 - val_loss: 0.2840\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27118\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0821 - val_loss: 0.2894\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27118\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0697 - val_loss: 0.2982\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27118\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0560 - val_loss: 0.3044\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27118\n",
      "Epoch 00013: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_stopping = model_reg_relu.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.1589713]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.5486484]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.605691]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [4.002837]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.1924605]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.8385916]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.8331656]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [3.999655]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.003024]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.869155]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5207536816596985\n",
      "R2 score: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_relu_stopping = np.sqrt(mean_squared_error(y_test_reg,pred_reg_stopping))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_relu_stopping))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_stopping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Experimenting with different optimizers for ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_sgd.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.2486 - val_loss: 0.6791\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67909, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.5485 - val_loss: 0.3984\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67909 to 0.39845, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.3708 - val_loss: 0.3403\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39845 to 0.34029, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.3320 - val_loss: 0.3207\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.34029 to 0.32073, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.3134 - val_loss: 0.3099\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32073 to 0.30990, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.3002 - val_loss: 0.3073\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.30990 to 0.30729, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.2924 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.30729 to 0.29506, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2822 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.29506\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2763 - val_loss: 0.2882\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.29506 to 0.28824, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.2709 - val_loss: 0.2858\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.28824 to 0.28580, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.2656 - val_loss: 0.2831\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.28580 to 0.28314, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.2608 - val_loss: 0.3170\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28314\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2557 - val_loss: 0.2881\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.28314\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.2539 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.28314 to 0.27835, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.2487 - val_loss: 0.2873\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.27835\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2438 - val_loss: 0.2894\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.27835\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2413 - val_loss: 0.2818\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.27835\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.2385 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.27835 to 0.27235, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.2361 - val_loss: 0.2823\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.27235\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.2336 - val_loss: 0.2691\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.27235 to 0.26907, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.2286 - val_loss: 0.2708\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.26907\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.2269 - val_loss: 0.2788\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.26907\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.2230 - val_loss: 0.2688\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.26907 to 0.26884, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.2215 - val_loss: 0.2716\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.26884\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.2169 - val_loss: 0.2630\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.26884 to 0.26305, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.2146 - val_loss: 0.2619\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.26305 to 0.26185, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.2128 - val_loss: 0.2612\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.26185 to 0.26123, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.2106 - val_loss: 0.2605\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.26123 to 0.26052, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.2078 - val_loss: 0.2613\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.26052\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.2046 - val_loss: 0.2628\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.26052\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.2030 - val_loss: 0.2604\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.26052 to 0.26036, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.1988 - val_loss: 0.2622\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.26036\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.1966 - val_loss: 0.2626\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.26036\n",
      "Epoch 00033: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.5292 - val_loss: 0.7902\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26036\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6850 - val_loss: 0.5032\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26036\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.4272 - val_loss: 0.3663\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26036\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.3490 - val_loss: 0.3367\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26036\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.3227 - val_loss: 0.3185\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26036\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.3091 - val_loss: 0.3142\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26036\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.2960 - val_loss: 0.3030\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26036\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.2860 - val_loss: 0.3209\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26036\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2784 - val_loss: 0.2904\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26036\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2720 - val_loss: 0.2883\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26036\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.2669 - val_loss: 0.2896\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26036\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.2630 - val_loss: 0.2820\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26036\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2583 - val_loss: 0.2810\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26036\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.2541 - val_loss: 0.2782\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26036\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.2510 - val_loss: 0.2763\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26036\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2475 - val_loss: 0.2771\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26036\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2459 - val_loss: 0.2773\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26036\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2421 - val_loss: 0.2755\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26036\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.2382 - val_loss: 0.2715\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.26036\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.2352 - val_loss: 0.2717\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.26036\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.2329 - val_loss: 0.2701\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.26036\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.2307 - val_loss: 0.2687\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.26036\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.2282 - val_loss: 0.2729\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.26036\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.2255 - val_loss: 0.2703\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.26036\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.2229 - val_loss: 0.2657\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.26036\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.2210 - val_loss: 0.2687\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.26036\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.2180 - val_loss: 0.2652\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.26036\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.2154 - val_loss: 0.2676\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.26036\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.2129 - val_loss: 0.2626\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.26036\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.2119 - val_loss: 0.2610\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.26036\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.2104 - val_loss: 0.2678\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.26036\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.2050 - val_loss: 0.2661\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.26036\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.2049 - val_loss: 0.2593\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.26036 to 0.25926, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.2026 - val_loss: 0.2595\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.25926\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.1999 - val_loss: 0.2578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: val_loss improved from 0.25926 to 0.25778, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.1981 - val_loss: 0.2584\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.25778\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1952 - val_loss: 0.2560\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.25778 to 0.25605, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1937 - val_loss: 0.2657\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.25605\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1922 - val_loss: 0.2609\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.25605\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1906 - val_loss: 0.2587\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.25605\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1883 - val_loss: 0.2543\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.25605 to 0.25430, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1871 - val_loss: 0.2548\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.25430\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1852 - val_loss: 0.2555\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.25430\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1840 - val_loss: 0.2743\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.25430\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.1817 - val_loss: 0.2609\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.25430\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.1805 - val_loss: 0.2546\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.25430\n",
      "Epoch 00046: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.3393 - val_loss: 0.7251\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25430\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6054 - val_loss: 0.4320\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25430\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3898 - val_loss: 0.3455\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25430\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.3391 - val_loss: 0.3229\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25430\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.3181 - val_loss: 0.3150\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25430\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.3034 - val_loss: 0.3029\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25430\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.2920 - val_loss: 0.2958\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25430\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.2845 - val_loss: 0.2915\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25430\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.2781 - val_loss: 0.2898\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25430\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.2731 - val_loss: 0.2935\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25430\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.2673 - val_loss: 0.2867\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.25430\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.2623 - val_loss: 0.2825\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.25430\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2604 - val_loss: 0.2962\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.25430\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.2578 - val_loss: 0.2802\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.25430\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.2550 - val_loss: 0.2816\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25430\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2519 - val_loss: 0.2902\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.25430\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2505 - val_loss: 0.2789\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.25430\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2480 - val_loss: 0.2840\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.25430\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.2453 - val_loss: 0.2793\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.25430\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.2435 - val_loss: 0.2880\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.25430\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.2418 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.25430\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.2394 - val_loss: 0.2814\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.25430\n",
      "Epoch 00022: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.4310 - val_loss: 0.7878\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25430\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6675 - val_loss: 0.4802\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25430\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.4138 - val_loss: 0.3542\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25430\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3445 - val_loss: 0.3321\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25430\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3202 - val_loss: 0.3129\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25430\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.3048 - val_loss: 0.3043\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25430\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.2938 - val_loss: 0.3209\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25430\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.2846 - val_loss: 0.2928\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25430\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.2788 - val_loss: 0.3241\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25430\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.2710 - val_loss: 0.2872\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25430\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.2649 - val_loss: 0.2809\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.25430\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.2614 - val_loss: 0.2806\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.25430\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2570 - val_loss: 0.2838\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.25430\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.2529 - val_loss: 0.2758\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.25430\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.2480 - val_loss: 0.2741\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25430\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2449 - val_loss: 0.2878\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.25430\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2418 - val_loss: 0.2771\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.25430\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2379 - val_loss: 0.2802\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.25430\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.2362 - val_loss: 0.2701\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.25430\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.2332 - val_loss: 0.2819\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.25430\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.2293 - val_loss: 0.2726\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.25430\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.2287 - val_loss: 0.2756\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.25430\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.2241 - val_loss: 0.2739\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.25430\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.2216 - val_loss: 0.2734\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.25430\n",
      "Epoch 00024: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.3474 - val_loss: 0.7342\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25430\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.5935 - val_loss: 0.4264\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25430\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.3860 - val_loss: 0.3491\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25430\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3370 - val_loss: 0.3366\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25430\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3179 - val_loss: 0.3131\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25430\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.3025 - val_loss: 0.3127\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25430\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.2899 - val_loss: 0.2973\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25430\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.2824 - val_loss: 0.2943\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25430\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.2760 - val_loss: 0.2944\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25430\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.2698 - val_loss: 0.2852\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25430\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.2643 - val_loss: 0.2822\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.25430\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.2607 - val_loss: 0.2894\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.25430\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.2568 - val_loss: 0.2837\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.25430\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.2517 - val_loss: 0.2848\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.25430\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.2495 - val_loss: 0.2779\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25430\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2448 - val_loss: 0.2756\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.25430\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2430 - val_loss: 0.2772\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.25430\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2419 - val_loss: 0.2853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_loss did not improve from 0.25430\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.2383 - val_loss: 0.2734\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.25430\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.2350 - val_loss: 0.2750\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.25430\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.2314 - val_loss: 0.2708\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.25430\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.2299 - val_loss: 0.2719\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.25430\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.2260 - val_loss: 0.2679\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.25430\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.2241 - val_loss: 0.2754\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.25430\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.2216 - val_loss: 0.2662\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.25430\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.2189 - val_loss: 0.2821\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.25430\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.2172 - val_loss: 0.2668\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.25430\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.2140 - val_loss: 0.2635\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.25430\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.2121 - val_loss: 0.2631\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.25430\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.2105 - val_loss: 0.2660\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.25430\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.2093 - val_loss: 0.2627\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.25430\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.2053 - val_loss: 0.2663\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.25430\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.2044 - val_loss: 0.2634\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.25430\n",
      "Epoch 00033: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.3587 - val_loss: 0.7504\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25430\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6348 - val_loss: 0.4721\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25430\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.4078 - val_loss: 0.3657\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25430\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.3435 - val_loss: 0.3367\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25430\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3190 - val_loss: 0.3234\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25430\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3038 - val_loss: 0.3097\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25430\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.2923 - val_loss: 0.3040\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25430\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.2825 - val_loss: 0.3190\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25430\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.2763 - val_loss: 0.2940\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25430\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.2705 - val_loss: 0.2884\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25430\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.2649 - val_loss: 0.2856\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.25430\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.2610 - val_loss: 0.2841\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.25430\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2573 - val_loss: 0.2817\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.25430\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.2520 - val_loss: 0.2791\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.25430\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.2484 - val_loss: 0.2804\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25430\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2452 - val_loss: 0.2781\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.25430\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2420 - val_loss: 0.2754\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.25430\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2389 - val_loss: 0.2762\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.25430\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.2367 - val_loss: 0.2745\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.25430\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.2347 - val_loss: 0.2790\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.25430\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.2308 - val_loss: 0.2792\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.25430\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.2287 - val_loss: 0.2702\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.25430\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.2267 - val_loss: 0.2750\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.25430\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.2232 - val_loss: 0.2683\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.25430\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.2212 - val_loss: 0.2670\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.25430\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.2210 - val_loss: 0.2705\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.25430\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.2166 - val_loss: 0.2636\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.25430\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.2135 - val_loss: 0.2630\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.25430\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.2106 - val_loss: 0.2689\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.25430\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.2084 - val_loss: 0.2605\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.25430\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.2070 - val_loss: 0.2640\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.25430\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.2054 - val_loss: 0.2599\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.25430\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.2024 - val_loss: 0.2677\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.25430\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1999 - val_loss: 0.2579\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.25430\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.1973 - val_loss: 0.2948\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.25430\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.1954 - val_loss: 0.2555\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.25430\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1938 - val_loss: 0.2564\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.25430\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1918 - val_loss: 0.2590\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.25430\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1898 - val_loss: 0.2821\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.25430\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1866 - val_loss: 0.2604\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.25430\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1865 - val_loss: 0.2540\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.25430 to 0.25395, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1840 - val_loss: 0.2625\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.25395\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1810 - val_loss: 0.2554\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.25395\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1815 - val_loss: 0.2565\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.25395\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.1796 - val_loss: 0.2546\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.25395\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.1778 - val_loss: 0.2622\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.25395\n",
      "Epoch 00046: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.4262 - val_loss: 0.7556\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25395\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6219 - val_loss: 0.4525\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25395\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.3960 - val_loss: 0.3561\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25395\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.3403 - val_loss: 0.3303\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25395\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.3161 - val_loss: 0.3254\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25395\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3010 - val_loss: 0.3084\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25395\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2897 - val_loss: 0.3092\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25395\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2798 - val_loss: 0.2941\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25395\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2719 - val_loss: 0.2962\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25395\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2664 - val_loss: 0.2852\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25395\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.2615 - val_loss: 0.2902\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.25395\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.2556 - val_loss: 0.2798\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.25395\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2521 - val_loss: 0.2843\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.25395\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.2481 - val_loss: 0.2792\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.25395\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.2442 - val_loss: 0.2823\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25395\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2407 - val_loss: 0.2786\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.25395\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2380 - val_loss: 0.2744\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.25395\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2335 - val_loss: 0.2712\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.25395\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.2325 - val_loss: 0.2741\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.25395\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.2296 - val_loss: 0.2714\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.25395\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.2270 - val_loss: 0.2678\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.25395\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.2233 - val_loss: 0.2676\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.25395\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.2214 - val_loss: 0.2793\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.25395\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.2198 - val_loss: 0.2805\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.25395\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.2155 - val_loss: 0.2640\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.25395\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.2147 - val_loss: 0.2632\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.25395\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.2105 - val_loss: 0.2606\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.25395\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.2090 - val_loss: 0.2763\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.25395\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.2073 - val_loss: 0.2623\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.25395\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.2044 - val_loss: 0.2601\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.25395\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.2025 - val_loss: 0.2554\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.25395\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.2006 - val_loss: 0.2550\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.25395\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.1973 - val_loss: 0.2606\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.25395\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1947 - val_loss: 0.2534\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.25395 to 0.25342, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.1916 - val_loss: 0.2538\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.25342\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.1925 - val_loss: 0.2544\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.25342\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1890 - val_loss: 0.2509\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.25342 to 0.25089, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1872 - val_loss: 0.2516\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.25089\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1861 - val_loss: 0.2516\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.25089\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1850 - val_loss: 0.2503\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.25089 to 0.25029, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1824 - val_loss: 0.2522\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.25029\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1808 - val_loss: 0.2496\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.25029 to 0.24956, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1795 - val_loss: 0.2741\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.24956\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1784 - val_loss: 0.2514\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.24956\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.1766 - val_loss: 0.2504\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.24956\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.1758 - val_loss: 0.2508\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.24956\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.1738 - val_loss: 0.2497\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.24956\n",
      "Epoch 00047: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.2898 - val_loss: 0.7219\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24956\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.5974 - val_loss: 0.4310\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24956\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.3922 - val_loss: 0.3489\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24956\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.3437 - val_loss: 0.3271\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24956\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.3224 - val_loss: 0.3155\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24956\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3098 - val_loss: 0.3057\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24956\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2970 - val_loss: 0.3055\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.24956\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2880 - val_loss: 0.3061\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.24956\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.2808 - val_loss: 0.3006\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.24956\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.2744 - val_loss: 0.2941\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.24956\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.2695 - val_loss: 0.2848\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.24956\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.2647 - val_loss: 0.2892\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.24956\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.2601 - val_loss: 0.2812\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.24956\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.2576 - val_loss: 0.2817\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.24956\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.2547 - val_loss: 0.3152\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.24956\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.2517 - val_loss: 0.2994\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.24956\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2481 - val_loss: 0.2985\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.24956\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.2478 - val_loss: 0.2787\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.24956\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.2444 - val_loss: 0.2762\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.24956\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.2447 - val_loss: 0.2790\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.24956\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.2384 - val_loss: 0.2832\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.24956\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.2384 - val_loss: 0.2758\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.24956\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.2366 - val_loss: 0.2754\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.24956\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.2334 - val_loss: 0.2755\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.24956\n",
      "Epoch 00024: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.3696 - val_loss: 0.7369\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24956\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6050 - val_loss: 0.4344\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24956\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3818 - val_loss: 0.3621\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24956\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.3326 - val_loss: 0.3423\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24956\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3149 - val_loss: 0.3252\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24956\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.3009 - val_loss: 0.3154\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24956\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.2917 - val_loss: 0.3033\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.24956\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.2827 - val_loss: 0.2994\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.24956\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.2762 - val_loss: 0.2983\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.24956\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2711 - val_loss: 0.2954\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.24956\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.2656 - val_loss: 0.2881\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.24956\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.2625 - val_loss: 0.2982\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.24956\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2576 - val_loss: 0.3000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.24956\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.2538 - val_loss: 0.2833\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.24956\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.2540 - val_loss: 0.2820\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.24956\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.2485 - val_loss: 0.2909\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.24956\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.2448 - val_loss: 0.2812\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.24956\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.2431 - val_loss: 0.2900\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.24956\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.2416 - val_loss: 0.2850\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.24956\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2397 - val_loss: 0.2766\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.24956\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.2362 - val_loss: 0.2763\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.24956\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.2330 - val_loss: 0.2808\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.24956\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.2307 - val_loss: 0.2773\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.24956\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.2286 - val_loss: 0.2774\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.24956\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.2263 - val_loss: 0.2821\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.24956\n",
      "Epoch 00025: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.4480 - val_loss: 0.7691\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24956\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6533 - val_loss: 0.4780\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24956\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.4074 - val_loss: 0.3569\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24956\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.3442 - val_loss: 0.3340\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24956\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3205 - val_loss: 0.3219\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24956\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.3056 - val_loss: 0.3053\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24956\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.2932 - val_loss: 0.3081\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.24956\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.2833 - val_loss: 0.2959\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.24956\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.2743 - val_loss: 0.2959\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.24956\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2679 - val_loss: 0.2832\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.24956\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.2631 - val_loss: 0.2804\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.24956\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.2572 - val_loss: 0.2785\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.24956\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2530 - val_loss: 0.2782\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.24956\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.2498 - val_loss: 0.2742\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.24956\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.2458 - val_loss: 0.2782\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.24956\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2423 - val_loss: 0.2826\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.24956\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2374 - val_loss: 0.2689\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.24956\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2350 - val_loss: 0.2678\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.24956\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.2311 - val_loss: 0.2755\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.24956\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.2294 - val_loss: 0.2665\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.24956\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.2262 - val_loss: 0.2632\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.24956\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.2226 - val_loss: 0.2668\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.24956\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.2194 - val_loss: 0.2725\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.24956\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.2165 - val_loss: 0.2625\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.24956\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.2135 - val_loss: 0.2658\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.24956\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.2106 - val_loss: 0.2589\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.24956\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.2098 - val_loss: 0.2595\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.24956\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.2072 - val_loss: 0.2614\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.24956\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.2050 - val_loss: 0.2564\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.24956\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.2025 - val_loss: 0.2798\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.24956\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.2005 - val_loss: 0.2546\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.24956\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.1982 - val_loss: 0.2541\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.24956\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.1963 - val_loss: 0.2573\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.24956\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.1947 - val_loss: 0.2632\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.24956\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.1920 - val_loss: 0.2541\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.24956\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.1898 - val_loss: 0.2560\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.24956\n",
      "Epoch 00036: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with Stochastic gradient descent optimizer(SGD).\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_sgd.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_sgd = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.2288952]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.950254]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.646233]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [4.0801954]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.172542]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.6103296]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.7259464]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [3.8494282]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [3.9009638]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.7853088]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_sgd[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.4995602071285248\n",
      "R2 score: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_sgd = np.sqrt(mean_squared_error(y_test_reg,pred_reg_sgd))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_sgd))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## RMSProp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_rmsprop.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.3151 - val_loss: 0.3219\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32189, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2888 - val_loss: 0.3018\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.32189 to 0.30181, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2557 - val_loss: 0.3133\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30181\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2324 - val_loss: 0.2815\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30181 to 0.28149, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2083 - val_loss: 0.2724\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.28149 to 0.27244, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1821 - val_loss: 0.2796\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27244\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1587 - val_loss: 0.2676\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.27244 to 0.26760, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1372 - val_loss: 0.2644\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.26760 to 0.26444, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1175 - val_loss: 0.2828\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26444\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1004 - val_loss: 0.3290\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26444\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0872 - val_loss: 0.2763\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26444\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0751 - val_loss: 0.2800\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26444\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0667 - val_loss: 0.3238\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26444\n",
      "Epoch 00013: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.3739 - val_loss: 0.3300\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26444\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2935 - val_loss: 0.2964\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26444\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2616 - val_loss: 0.2893\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26444\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2394 - val_loss: 0.2957\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26444\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2168 - val_loss: 0.2882\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26444\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.1951 - val_loss: 0.2673\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26444\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1743 - val_loss: 0.2763\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26444\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1542 - val_loss: 0.2719\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26444\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1371 - val_loss: 0.2873\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26444\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1207 - val_loss: 0.2759\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26444\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1061 - val_loss: 0.2864\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26444\n",
      "Epoch 00011: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.2133 - val_loss: 0.3191\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26444\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2913 - val_loss: 0.2915\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26444\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2608 - val_loss: 0.2967\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26444\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2385 - val_loss: 0.2869\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26444\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2165 - val_loss: 0.2755\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26444\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1933 - val_loss: 0.2766\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26444\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1743 - val_loss: 0.2730\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26444\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1578 - val_loss: 0.2918\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26444\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1397 - val_loss: 0.2708\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26444\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1258 - val_loss: 0.2822\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26444\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1130 - val_loss: 0.2977\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26444\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1003 - val_loss: 0.2844\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26444\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0897 - val_loss: 0.3204\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26444\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0802 - val_loss: 0.3468\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26444\n",
      "Epoch 00014: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.5447 - val_loss: 0.3571\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26444\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2967 - val_loss: 0.2873\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26444\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2598 - val_loss: 0.2830\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26444\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2398 - val_loss: 0.2844\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26444\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2182 - val_loss: 0.2794\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26444\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1986 - val_loss: 0.2720\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26444\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1760 - val_loss: 0.2804\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26444\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1538 - val_loss: 0.2769\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26444\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1354 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26444\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1155 - val_loss: 0.2818\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26444\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1003 - val_loss: 0.2973\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26444\n",
      "Epoch 00011: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.4833 - val_loss: 0.3315\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26444\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2933 - val_loss: 0.2868\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26444\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2585 - val_loss: 0.2826\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26444\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2414 - val_loss: 0.2855\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26444\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2261 - val_loss: 0.2815\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26444\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2064 - val_loss: 0.2755\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26444\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1845 - val_loss: 0.2690\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26444\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1634 - val_loss: 0.2702\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26444\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1437 - val_loss: 0.2714\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26444\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1264 - val_loss: 0.2719\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26444\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1120 - val_loss: 0.2765\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26444\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0989 - val_loss: 0.2954\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26444\n",
      "Epoch 00012: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.3996 - val_loss: 0.3315\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26444\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2971 - val_loss: 0.3075\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26444\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2576 - val_loss: 0.2866\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26444\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2355 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26444\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2132 - val_loss: 0.2699\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26444\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1880 - val_loss: 0.2689\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26444\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1668 - val_loss: 0.2728\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26444\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1465 - val_loss: 0.2654\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26444\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1284 - val_loss: 0.2806\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26444\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1122 - val_loss: 0.2964\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26444\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0971 - val_loss: 0.3006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26444\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0858 - val_loss: 0.2983\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26444\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0775 - val_loss: 0.2990\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26444\n",
      "Epoch 00013: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.4877 - val_loss: 0.3448\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26444\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2927 - val_loss: 0.2918\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26444\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2590 - val_loss: 0.2944\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26444\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2422 - val_loss: 0.2858\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26444\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2238 - val_loss: 0.2792\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26444\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2021 - val_loss: 0.2913\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26444\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1771 - val_loss: 0.2742\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26444\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1588 - val_loss: 0.2724\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26444\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1384 - val_loss: 0.2646\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26444\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1214 - val_loss: 0.3000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26444\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1052 - val_loss: 0.2913\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26444\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0910 - val_loss: 0.3205\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26444\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0806 - val_loss: 0.2882\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26444\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0714 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26444\n",
      "Epoch 00014: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.2666 - val_loss: 0.3205\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26444\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2885 - val_loss: 0.2796\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26444\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2563 - val_loss: 0.2841\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26444\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2393 - val_loss: 0.2851\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26444\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2177 - val_loss: 0.2939\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26444\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1959 - val_loss: 0.2688\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26444\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1748 - val_loss: 0.2742\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26444\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1557 - val_loss: 0.2748\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26444\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1384 - val_loss: 0.2710\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26444\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1227 - val_loss: 0.2792\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26444\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1072 - val_loss: 0.2837\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26444\n",
      "Epoch 00011: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.7273 - val_loss: 0.3574\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26444\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3094 - val_loss: 0.3038\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26444\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2648 - val_loss: 0.2821\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26444\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2455 - val_loss: 0.3009\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26444\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2290 - val_loss: 0.2844\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26444\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2119 - val_loss: 0.2674\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26444\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1952 - val_loss: 0.2829\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26444\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1802 - val_loss: 0.2690\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26444\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1652 - val_loss: 0.3141\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26444\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1544 - val_loss: 0.2663\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26444\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1405 - val_loss: 0.2686\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26444\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1269 - val_loss: 0.2647\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26444\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1164 - val_loss: 0.2830\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26444\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1058 - val_loss: 0.2722\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26444\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0954 - val_loss: 0.2943\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26444\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0851 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26444\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0787 - val_loss: 0.2913\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26444\n",
      "Epoch 00017: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.1239 - val_loss: 0.3841\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26444\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3171 - val_loss: 0.2947\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26444\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2651 - val_loss: 0.2834\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26444\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2421 - val_loss: 0.2920\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26444\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2245 - val_loss: 0.2762\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26444\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2021 - val_loss: 0.2672\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26444\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1829 - val_loss: 0.2666\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26444\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1643 - val_loss: 0.2657\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26444\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1477 - val_loss: 0.2698\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26444\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1322 - val_loss: 0.2625\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.26444 to 0.26254, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1165 - val_loss: 0.2635\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26254\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1029 - val_loss: 0.2838\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26254\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0900 - val_loss: 0.2797\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26254\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0791 - val_loss: 0.2849\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26254\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0713 - val_loss: 0.2985\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26254\n",
      "Epoch 00015: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with RMSProp optimizer.\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_rmsprop.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_rmsprop = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.1625855]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.750733]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.80315]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [4.145072]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.4359465]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.924612]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.75189]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.1631236]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [3.9477315]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.8618743]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_rmsprop[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5123857855796814\n",
      "R2 score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_rmsprop = np.sqrt(mean_squared_error(y_test_reg,pred_reg_rmsprop))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_rmsprop))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_rmsprop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Adagrad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_adagrad.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.8264 - val_loss: 0.3450\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.34496, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2954 - val_loss: 0.3034\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.34496 to 0.30340, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2547 - val_loss: 0.2955\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.30340 to 0.29550, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2340 - val_loss: 0.2876\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.29550 to 0.28759, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2202 - val_loss: 0.2863\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.28759 to 0.28633, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2056 - val_loss: 0.2847\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.28633 to 0.28471, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1911 - val_loss: 0.2811\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.28471 to 0.28110, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1770 - val_loss: 0.2769\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.28110 to 0.27691, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1646 - val_loss: 0.2750\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.27691 to 0.27499, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1516 - val_loss: 0.2744\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.27499 to 0.27439, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1395 - val_loss: 0.2738\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.27439 to 0.27384, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1289 - val_loss: 0.2741\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27384\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1185 - val_loss: 0.2764\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27384\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1092 - val_loss: 0.2755\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.27384\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1007 - val_loss: 0.2758\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.27384\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0929 - val_loss: 0.2770\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.27384\n",
      "Epoch 00016: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.7666 - val_loss: 0.3542\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27384\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2948 - val_loss: 0.3010\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27384\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2538 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27384\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2329 - val_loss: 0.2884\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27384\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2176 - val_loss: 0.2837\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27384\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2018 - val_loss: 0.2787\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27384\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1850 - val_loss: 0.2787\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27384\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1705 - val_loss: 0.2747\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27384\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1570 - val_loss: 0.2768\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27384\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1445 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.27384 to 0.27225, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1335 - val_loss: 0.2717\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.27225 to 0.27172, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1231 - val_loss: 0.2715\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.27172 to 0.27151, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1138 - val_loss: 0.2720\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27151\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1052 - val_loss: 0.2735\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.27151\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0976 - val_loss: 0.2738\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.27151\n",
      "Epoch 00015: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.7773 - val_loss: 0.3394\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27151\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2956 - val_loss: 0.3014\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27151\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2601 - val_loss: 0.2897\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27151\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2419 - val_loss: 0.2852\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27151\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2269 - val_loss: 0.2810\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27151\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2103 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27151\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1934 - val_loss: 0.2736\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27151\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1770 - val_loss: 0.2722\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27151\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1625 - val_loss: 0.2740\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27151\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1496 - val_loss: 0.2725\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27151\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1375 - val_loss: 0.2681\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.27151 to 0.26807, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1270 - val_loss: 0.2691\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26807\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1170 - val_loss: 0.2703\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26807\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1081 - val_loss: 0.2700\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26807\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1000 - val_loss: 0.2712\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26807\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0926 - val_loss: 0.2726\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26807\n",
      "Epoch 00016: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.7511 - val_loss: 0.3301\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26807\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2878 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26807\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2524 - val_loss: 0.2899\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26807\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2360 - val_loss: 0.2829\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26807\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2215 - val_loss: 0.2782\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26807\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2081 - val_loss: 0.2765\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26807\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1932 - val_loss: 0.2720\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26807\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1803 - val_loss: 0.2726\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26807\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1676 - val_loss: 0.2675\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.26807 to 0.26748, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1561 - val_loss: 0.2686\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26748\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1460 - val_loss: 0.2670\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.26748 to 0.26697, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1366 - val_loss: 0.2656\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.26697 to 0.26563, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1274 - val_loss: 0.2671\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26563\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1188 - val_loss: 0.2676\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26563\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1105 - val_loss: 0.2669\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26563\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.1028 - val_loss: 0.2725\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26563\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0951 - val_loss: 0.2705\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26563\n",
      "Epoch 00017: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.8514 - val_loss: 0.3625\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26563\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3041 - val_loss: 0.3119\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26563\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.2571 - val_loss: 0.2931\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26563\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2346 - val_loss: 0.2857\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26563\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2178 - val_loss: 0.2858\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26563\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2023 - val_loss: 0.2783\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26563\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1867 - val_loss: 0.2732\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26563\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1717 - val_loss: 0.2685\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26563\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1577 - val_loss: 0.2674\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26563\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1445 - val_loss: 0.2665\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26563\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1318 - val_loss: 0.2697\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26563\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1211 - val_loss: 0.2646\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.26563 to 0.26455, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1098 - val_loss: 0.2646\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26455\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1002 - val_loss: 0.2653\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26455\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0910 - val_loss: 0.2668\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26455\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0826 - val_loss: 0.2674\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26455\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0754 - val_loss: 0.2689\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26455\n",
      "Epoch 00017: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.8189 - val_loss: 0.3650\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26455\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3111 - val_loss: 0.3192\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26455\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2688 - val_loss: 0.2999\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26455\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2495 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26455\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2378 - val_loss: 0.2858\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26455\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2252 - val_loss: 0.2815\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26455\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2134 - val_loss: 0.2796\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26455\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2021 - val_loss: 0.2746\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26455\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1921 - val_loss: 0.2716\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26455\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1827 - val_loss: 0.2691\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26455\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1733 - val_loss: 0.2676\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26455\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1646 - val_loss: 0.2670\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26455\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1554 - val_loss: 0.2657\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26455\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1464 - val_loss: 0.2655\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26455\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1378 - val_loss: 0.2656\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26455\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.1292 - val_loss: 0.2656\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26455\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.1207 - val_loss: 0.2651\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26455\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.1129 - val_loss: 0.2663\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26455\n",
      "Epoch 00018: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.8820 - val_loss: 0.3617\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26455\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3102 - val_loss: 0.3092\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26455\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2666 - val_loss: 0.2950\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26455\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2467 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26455\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2340 - val_loss: 0.2860\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26455\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2220 - val_loss: 0.2830\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26455\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2092 - val_loss: 0.2783\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26455\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1966 - val_loss: 0.2747\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26455\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1857 - val_loss: 0.2726\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26455\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1748 - val_loss: 0.2717\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26455\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1656 - val_loss: 0.2700\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26455\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1555 - val_loss: 0.2698\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26455\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1464 - val_loss: 0.2690\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26455\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1375 - val_loss: 0.2683\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26455\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1291 - val_loss: 0.2689\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26455\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.1211 - val_loss: 0.2685\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26455\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.1133 - val_loss: 0.2702\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26455\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.1059 - val_loss: 0.2702\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26455\n",
      "Epoch 00018: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.7111 - val_loss: 0.3339\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26455\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2863 - val_loss: 0.2983\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26455\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2529 - val_loss: 0.2903\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26455\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2349 - val_loss: 0.2866\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26455\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2199 - val_loss: 0.2812\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26455\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2043 - val_loss: 0.2788\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26455\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1886 - val_loss: 0.2741\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26455\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1735 - val_loss: 0.2758\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26455\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1601 - val_loss: 0.2705\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26455\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1479 - val_loss: 0.2713\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26455\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1375 - val_loss: 0.2698\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26455\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1265 - val_loss: 0.2688\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26455\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1173 - val_loss: 0.2692\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26455\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1085 - val_loss: 0.2719\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26455\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1008 - val_loss: 0.2712\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26455\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0934 - val_loss: 0.2718\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26455\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0872 - val_loss: 0.2730\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26455\n",
      "Epoch 00017: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.7487 - val_loss: 0.3519\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26455\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3043 - val_loss: 0.3074\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26455\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2656 - val_loss: 0.2932\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26455\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2481 - val_loss: 0.2899\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26455\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2370 - val_loss: 0.2875\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26455\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2268 - val_loss: 0.2845\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26455\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2155 - val_loss: 0.2814\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26455\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.2032 - val_loss: 0.2790\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26455\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1915 - val_loss: 0.2761\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26455\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1808 - val_loss: 0.2733\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26455\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1697 - val_loss: 0.2728\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26455\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1589 - val_loss: 0.2734\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26455\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1482 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26455\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1379 - val_loss: 0.2737\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26455\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1280 - val_loss: 0.2752\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26455\n",
      "Epoch 00015: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.7645 - val_loss: 0.3499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26455\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2937 - val_loss: 0.3056\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26455\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2534 - val_loss: 0.2953\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26455\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2333 - val_loss: 0.2868\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26455\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2202 - val_loss: 0.2824\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26455\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2075 - val_loss: 0.2810\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26455\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1963 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26455\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1852 - val_loss: 0.2785\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26455\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1743 - val_loss: 0.2770\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26455\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1635 - val_loss: 0.2776\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26455\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1531 - val_loss: 0.2753\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26455\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1430 - val_loss: 0.2753\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26455\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1332 - val_loss: 0.2740\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26455\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1242 - val_loss: 0.2747\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26455\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1151 - val_loss: 0.2744\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26455\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.1069 - val_loss: 0.2741\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26455\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0992 - val_loss: 0.2769\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26455\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0921 - val_loss: 0.2753\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26455\n",
      "Epoch 00018: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with Adagrad.\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adagrad')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_adagrad.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_adagrad = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.1785238]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.7580104]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.5060987]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [3.9313974]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [3.981377]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.911565]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.737559]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.0704503]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.077872]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.7188265]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_adagrad[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5143455862998962\n",
      "R2 score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_adagrad = np.sqrt(mean_squared_error(y_test_reg,pred_reg_adagrad))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_adagrad))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_adagrad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Adadelta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_adadelta.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.0485 - val_loss: 0.3101\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31010, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2797 - val_loss: 0.3100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31010 to 0.30998, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2562 - val_loss: 0.2936\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.30998 to 0.29357, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2396 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.29357 to 0.27844, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2150 - val_loss: 0.2892\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27844\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1954 - val_loss: 0.2971\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27844\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1708 - val_loss: 0.2988\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27844\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.1538 - val_loss: 0.2797\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27844\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1368 - val_loss: 0.2693\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.27844 to 0.26934, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.1208 - val_loss: 0.2707\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26934\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.1032 - val_loss: 0.3050\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26934\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.0947 - val_loss: 0.2778\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26934\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.0824 - val_loss: 0.3046\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26934\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.0749 - val_loss: 0.3019\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26934\n",
      "Epoch 00014: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.1215 - val_loss: 0.3022\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26934\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2804 - val_loss: 0.2802\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26934\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2530 - val_loss: 0.2811\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26934\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2367 - val_loss: 0.2871\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26934\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2187 - val_loss: 0.2697\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26934\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1966 - val_loss: 0.3013\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26934\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1787 - val_loss: 0.2681\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.26934 to 0.26810, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1587 - val_loss: 0.2621\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.26810 to 0.26210, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1397 - val_loss: 0.2668\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26210\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1253 - val_loss: 0.2985\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26210\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1121 - val_loss: 0.2689\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26210\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0979 - val_loss: 0.2851\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26210\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0855 - val_loss: 0.2882\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26210\n",
      "Epoch 00013: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.0764 - val_loss: 0.3061\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26210\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2774 - val_loss: 0.2828\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26210\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2535 - val_loss: 0.2882\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26210\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2307 - val_loss: 0.2797\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26210\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2138 - val_loss: 0.2695\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26210\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1911 - val_loss: 0.2716\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26210\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1702 - val_loss: 0.2695\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26210\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1527 - val_loss: 0.2909\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26210\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1330 - val_loss: 0.3162\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26210\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1134 - val_loss: 0.2986\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26210\n",
      "Epoch 00010: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.0826 - val_loss: 0.3278\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26210\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2775 - val_loss: 0.2827\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26210\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2548 - val_loss: 0.2886\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26210\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2375 - val_loss: 0.2761\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26210\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2237 - val_loss: 0.2871\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26210\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2012 - val_loss: 0.2627\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26210\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1802 - val_loss: 0.2608\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.26210 to 0.26085, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1594 - val_loss: 0.2632\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26085\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1430 - val_loss: 0.2619\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26085\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1257 - val_loss: 0.2633\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26085\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1134 - val_loss: 0.2757\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26085\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1006 - val_loss: 0.2844\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26085\n",
      "Epoch 00012: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.1231 - val_loss: 0.3072\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26085\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2810 - val_loss: 0.2813\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26085\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2533 - val_loss: 0.2855\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26085\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2431 - val_loss: 0.2882\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26085\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2283 - val_loss: 0.2959\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26085\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2081 - val_loss: 0.2764\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26085\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1915 - val_loss: 0.2984\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26085\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1709 - val_loss: 0.2737\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26085\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1481 - val_loss: 0.2734\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26085\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1291 - val_loss: 0.2976\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26085\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1151 - val_loss: 0.2726\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26085\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1011 - val_loss: 0.2833\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26085\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0866 - val_loss: 0.3021\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26085\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0792 - val_loss: 0.3374\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26085\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0692 - val_loss: 0.2911\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.26085\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0651 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26085\n",
      "Epoch 00016: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.1402 - val_loss: 0.3120\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26085\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2829 - val_loss: 0.2868\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26085\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2502 - val_loss: 0.2768\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26085\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2243 - val_loss: 0.2708\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26085\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2015 - val_loss: 0.2683\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26085\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1817 - val_loss: 0.2887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26085\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1647 - val_loss: 0.2639\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26085\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1422 - val_loss: 0.2649\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26085\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1256 - val_loss: 0.3029\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26085\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1106 - val_loss: 0.2863\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26085\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0986 - val_loss: 0.2797\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26085\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0867 - val_loss: 0.2772\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26085\n",
      "Epoch 00012: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.1219 - val_loss: 0.3077\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26085\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2783 - val_loss: 0.2823\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26085\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2539 - val_loss: 0.2766\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26085\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2374 - val_loss: 0.2735\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26085\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2177 - val_loss: 0.2629\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26085\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1953 - val_loss: 0.2862\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26085\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1773 - val_loss: 0.2554\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.26085 to 0.25543, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1591 - val_loss: 0.2597\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25543\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1403 - val_loss: 0.3142\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25543\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1259 - val_loss: 0.2765\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25543\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1108 - val_loss: 0.2674\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.25543\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0974 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.25543\n",
      "Epoch 00012: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.0469 - val_loss: 0.3344\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25543\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2836 - val_loss: 0.2854\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25543\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2571 - val_loss: 0.2899\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25543\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2458 - val_loss: 0.2789\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25543\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2315 - val_loss: 0.3332\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25543\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2139 - val_loss: 0.2941\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25543\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1929 - val_loss: 0.2779\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25543\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1733 - val_loss: 0.2786\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25543\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1556 - val_loss: 0.2849\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25543\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1373 - val_loss: 0.2654\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25543\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1207 - val_loss: 0.3202\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.25543\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1103 - val_loss: 0.3141\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.25543\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0920 - val_loss: 0.2826\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.25543\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0803 - val_loss: 0.3022\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.25543\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0701 - val_loss: 0.2840\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25543\n",
      "Epoch 00015: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.1926 - val_loss: 0.3146\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25543\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2809 - val_loss: 0.2881\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25543\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2536 - val_loss: 0.2811\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25543\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2373 - val_loss: 0.2765\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25543\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2184 - val_loss: 0.2682\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25543\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1973 - val_loss: 0.2753\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25543\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1747 - val_loss: 0.2655\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25543\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1543 - val_loss: 0.2637\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25543\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1338 - val_loss: 0.2630\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25543\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1203 - val_loss: 0.2710\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25543\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0995 - val_loss: 0.2700\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.25543\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0880 - val_loss: 0.2776\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.25543\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0784 - val_loss: 0.2903\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.25543\n",
      "Epoch 00013: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.2024 - val_loss: 0.3105\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25543\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2825 - val_loss: 0.2779\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25543\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2541 - val_loss: 0.2810\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25543\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2358 - val_loss: 0.2900\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25543\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2169 - val_loss: 0.2764\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25543\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1968 - val_loss: 0.2649\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25543\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1760 - val_loss: 0.2650\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25543\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1552 - val_loss: 0.2672\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25543\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1367 - val_loss: 0.2716\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25543\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1199 - val_loss: 0.2733\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25543\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1013 - val_loss: 0.2868\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.25543\n",
      "Epoch 00011: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with ADadelta.\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adadelta')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_adadelta.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_adadelta = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.1392732]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.8013694]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.764119]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [3.9387994]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.159484]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.923687]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.6242514]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.1230307]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.273744]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [3.0436504]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_adadelta[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5054019093513489\n",
      "R2 score: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_adadelta = np.sqrt(mean_squared_error(y_test_reg,pred_reg_adadelta))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_adadelta))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_adadelta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Adamax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_adamax.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.2227 - val_loss: 0.5059\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50589, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3817 - val_loss: 0.3265\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50589 to 0.32650, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2885 - val_loss: 0.3011\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32650 to 0.30106, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2597 - val_loss: 0.2866\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30106 to 0.28655, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2444 - val_loss: 0.2802\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.28655 to 0.28022, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2359 - val_loss: 0.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.28022 to 0.27765, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2274 - val_loss: 0.2857\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27765\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2213 - val_loss: 0.2844\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27765\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2150 - val_loss: 0.2971\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27765\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2066 - val_loss: 0.2853\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27765\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1949 - val_loss: 0.2914\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27765\n",
      "Epoch 00011: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.0952 - val_loss: 0.5060\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27765\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3855 - val_loss: 0.3302\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27765\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2884 - val_loss: 0.2909\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27765\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2579 - val_loss: 0.2809\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27765\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2402 - val_loss: 0.2809\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27765\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2313 - val_loss: 0.2814\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27765\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2254 - val_loss: 0.2831\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27765\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2178 - val_loss: 0.2838\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27765\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2093 - val_loss: 0.2833\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27765\n",
      "Epoch 00009: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.9870 - val_loss: 0.4687\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27765\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3689 - val_loss: 0.3239\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27765\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2863 - val_loss: 0.2917\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27765\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2570 - val_loss: 0.2818\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27765\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2428 - val_loss: 0.2792\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27765\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2337 - val_loss: 0.2821\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27765\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2270 - val_loss: 0.2857\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27765\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2198 - val_loss: 0.2839\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27765\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2116 - val_loss: 0.2849\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27765\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2011 - val_loss: 0.2939\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27765\n",
      "Epoch 00010: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.7602 - val_loss: 0.4453\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27765\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3594 - val_loss: 0.3175\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27765\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2780 - val_loss: 0.2880\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27765\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2508 - val_loss: 0.2805\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27765\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2373 - val_loss: 0.2815\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27765\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2288 - val_loss: 0.2808\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27765\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2204 - val_loss: 0.2831\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27765\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2137 - val_loss: 0.2836\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27765\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2050 - val_loss: 0.2846\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27765\n",
      "Epoch 00009: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.7535 - val_loss: 0.4479\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27765\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3572 - val_loss: 0.3230\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27765\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2789 - val_loss: 0.2934\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27765\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2539 - val_loss: 0.2863\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27765\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2417 - val_loss: 0.2879\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27765\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2352 - val_loss: 0.2820\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27765\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2282 - val_loss: 0.2828\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27765\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2236 - val_loss: 0.2866\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27765\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2219 - val_loss: 0.2978\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27765\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2140 - val_loss: 0.2867\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27765\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.2056 - val_loss: 0.2832\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27765\n",
      "Epoch 00011: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.8568 - val_loss: 0.4645\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27765\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3626 - val_loss: 0.3227\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27765\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2825 - val_loss: 0.2906\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27765\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2556 - val_loss: 0.2828\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27765\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2428 - val_loss: 0.2802\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27765\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2346 - val_loss: 0.2864\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27765\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2297 - val_loss: 0.3018\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27765\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2236 - val_loss: 0.2902\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27765\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2156 - val_loss: 0.2978\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27765\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2098 - val_loss: 0.2926\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27765\n",
      "Epoch 00010: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 2.0016 - val_loss: 0.4542\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27765\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3572 - val_loss: 0.3138\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27765\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2798 - val_loss: 0.2866\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27765\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2530 - val_loss: 0.2803\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27765\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2422 - val_loss: 0.2780\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27765\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2338 - val_loss: 0.2807\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27765\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2281 - val_loss: 0.2821\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27765\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2205 - val_loss: 0.2803\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27765\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2122 - val_loss: 0.2895\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27765\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2024 - val_loss: 0.2808\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27765\n",
      "Epoch 00010: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 1.9261 - val_loss: 0.4592\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27765\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3637 - val_loss: 0.3220\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27765\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2841 - val_loss: 0.2907\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27765\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2577 - val_loss: 0.2857\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27765\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2443 - val_loss: 0.2916\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27765\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2369 - val_loss: 0.2828\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27765\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2281 - val_loss: 0.2842\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27765\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2203 - val_loss: 0.2820\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27765\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2121 - val_loss: 0.2870\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27765\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1999 - val_loss: 0.2753\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.27765 to 0.27534, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1890 - val_loss: 0.2728\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.27534 to 0.27284, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1751 - val_loss: 0.2709\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.27284 to 0.27087, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1613 - val_loss: 0.2682\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27087 to 0.26820, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1496 - val_loss: 0.2734\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26820\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1387 - val_loss: 0.2680\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26820 to 0.26796, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.1259 - val_loss: 0.2709\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.26796\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.1152 - val_loss: 0.2705\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26796\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.1039 - val_loss: 0.2741\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26796\n",
      "Epoch 00018: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.8514 - val_loss: 0.4690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26796\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3651 - val_loss: 0.3270\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26796\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2848 - val_loss: 0.2968\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26796\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2580 - val_loss: 0.2886\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26796\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2433 - val_loss: 0.2842\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26796\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2346 - val_loss: 0.2822\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26796\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2303 - val_loss: 0.2856\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26796\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2216 - val_loss: 0.2850\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26796\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2158 - val_loss: 0.2824\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26796\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2030 - val_loss: 0.2797\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26796\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1918 - val_loss: 0.2768\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26796\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1764 - val_loss: 0.2702\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26796\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1605 - val_loss: 0.2764\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26796\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1466 - val_loss: 0.2628\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.26796 to 0.26277, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.1321 - val_loss: 0.2598\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.26277 to 0.25978, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.1178 - val_loss: 0.2599\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.25978\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.1051 - val_loss: 0.2582\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25978 to 0.25819, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0928 - val_loss: 0.2600\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.25819\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0818 - val_loss: 0.2652\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.25819\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.0714 - val_loss: 0.2684\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.25819\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0636 - val_loss: 0.2701\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.25819\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0563 - val_loss: 0.2761\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.25819\n",
      "Epoch 00022: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.8466 - val_loss: 0.4152\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.25819\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3407 - val_loss: 0.3068\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25819\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2741 - val_loss: 0.2904\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25819\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2499 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25819\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2372 - val_loss: 0.2881\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25819\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2294 - val_loss: 0.2799\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25819\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2198 - val_loss: 0.2869\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25819\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2106 - val_loss: 0.2808\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25819\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2009 - val_loss: 0.2796\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25819\n",
      "Epoch 00009: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with Adamax.\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adamax')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_adamax.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_adamax = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.0921342]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.9031482]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.745195]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [4.0004554]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [3.9323356]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.975093]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.5537486]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.1400733]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [3.8123753]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.7884164]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_adamax[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5081221461296082\n",
      "R2 score: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_adamax = np.sqrt(mean_squared_error(y_test_reg,pred_reg_adamax))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_adamax))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_adamax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Nadam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_nadam.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.2243 - val_loss: 0.3243\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32429, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2854 - val_loss: 0.3206\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.32429 to 0.32060, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2551 - val_loss: 0.3275\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32060\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2292 - val_loss: 0.2818\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32060 to 0.28183, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1995 - val_loss: 0.2752\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.28183 to 0.27515, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1695 - val_loss: 0.2888\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27515\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1373 - val_loss: 0.3249\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27515\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1167 - val_loss: 0.2868\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27515\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0963 - val_loss: 0.2880\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27515\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0807 - val_loss: 0.2994\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27515\n",
      "Epoch 00010: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.3626 - val_loss: 0.3303\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27515\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2851 - val_loss: 0.2966\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27515\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2529 - val_loss: 0.2954\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27515\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2285 - val_loss: 0.2999\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27515\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1872 - val_loss: 0.2813\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27515\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1443 - val_loss: 0.2860\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27515\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1116 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27515\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0888 - val_loss: 0.2885\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27515\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0708 - val_loss: 0.3036\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27515\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0612 - val_loss: 0.3039\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27515\n",
      "Epoch 00010: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.3158 - val_loss: 0.3149\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27515\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2870 - val_loss: 0.2916\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27515\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2593 - val_loss: 0.3016\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27515\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2325 - val_loss: 0.2836\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27515\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1984 - val_loss: 0.2864\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27515\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1659 - val_loss: 0.2783\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27515\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1344 - val_loss: 0.2814\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27515\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1102 - val_loss: 0.2841\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27515\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0904 - val_loss: 0.2874\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27515\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0772 - val_loss: 0.2872\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27515\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0662 - val_loss: 0.2972\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27515\n",
      "Epoch 00011: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.1421 - val_loss: 0.3123\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27515\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2817 - val_loss: 0.2942\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27515\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2498 - val_loss: 0.2960\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27515\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2179 - val_loss: 0.2903\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27515\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1700 - val_loss: 0.2934\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27515\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1321 - val_loss: 0.2909\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27515\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1028 - val_loss: 0.2841\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27515\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0838 - val_loss: 0.2940\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27515\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0704 - val_loss: 0.3054\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27515\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0589 - val_loss: 0.2942\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27515\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0503 - val_loss: 0.2990\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27515\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0442 - val_loss: 0.3065\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27515\n",
      "Epoch 00012: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.1766 - val_loss: 0.3349\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27515\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2823 - val_loss: 0.2962\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27515\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2551 - val_loss: 0.2971\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27515\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2283 - val_loss: 0.2910\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27515\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1909 - val_loss: 0.2888\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27515\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1534 - val_loss: 0.2888\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27515\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1224 - val_loss: 0.3033\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27515\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0965 - val_loss: 0.3294\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27515\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0806 - val_loss: 0.3173\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27515\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0669 - val_loss: 0.3158\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27515\n",
      "Epoch 00010: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.2355 - val_loss: 0.3107\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27515\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2822 - val_loss: 0.2899\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27515\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2531 - val_loss: 0.2940\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27515\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2257 - val_loss: 0.2936\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27515\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1860 - val_loss: 0.2826\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27515\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1518 - val_loss: 0.2865\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27515\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1203 - val_loss: 0.2879\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27515\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0960 - val_loss: 0.2988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27515\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0802 - val_loss: 0.2962\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27515\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0661 - val_loss: 0.3137\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27515\n",
      "Epoch 00010: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.1997 - val_loss: 0.3065\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27515\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2807 - val_loss: 0.2966\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27515\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2547 - val_loss: 0.3024\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27515\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2253 - val_loss: 0.2771\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27515\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1912 - val_loss: 0.2762\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27515\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1563 - val_loss: 0.2730\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27515 to 0.27300, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1256 - val_loss: 0.3049\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27300\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0980 - val_loss: 0.2887\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27300\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0807 - val_loss: 0.2956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27300\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0682 - val_loss: 0.2980\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27300\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0584 - val_loss: 0.3257\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27300\n",
      "Epoch 00011: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.1427 - val_loss: 0.3421\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27300\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2834 - val_loss: 0.3069\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27300\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2523 - val_loss: 0.2866\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27300\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2105 - val_loss: 0.2889\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27300\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1714 - val_loss: 0.2860\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27300\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1407 - val_loss: 0.2854\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27300\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1105 - val_loss: 0.2937\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27300\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0891 - val_loss: 0.2966\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27300\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0750 - val_loss: 0.3055\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27300\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0641 - val_loss: 0.3016\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27300\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0547 - val_loss: 0.3064\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27300\n",
      "Epoch 00011: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.2548 - val_loss: 0.3281\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27300\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2864 - val_loss: 0.2993\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27300\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2548 - val_loss: 0.2929\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27300\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2290 - val_loss: 0.3083\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27300\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1913 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27300\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1524 - val_loss: 0.2872\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27300\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1233 - val_loss: 0.2953\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27300\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1016 - val_loss: 0.3020\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27300\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0831 - val_loss: 0.3152\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27300\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0706 - val_loss: 0.3102\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27300\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0609 - val_loss: 0.3275\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27300\n",
      "Epoch 00011: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.2424 - val_loss: 0.3317\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27300\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2788 - val_loss: 0.2981\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27300\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2502 - val_loss: 0.3015\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27300\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2255 - val_loss: 0.3037\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27300\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1896 - val_loss: 0.2950\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27300\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1512 - val_loss: 0.3089\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27300\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1142 - val_loss: 0.3080\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27300\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0888 - val_loss: 0.2985\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27300\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0695 - val_loss: 0.3110\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27300\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0562 - val_loss: 0.3053\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27300\n",
      "Epoch 00010: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with Nadam.\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='nadam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_nadam.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_nadam = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.2940738]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.6654196]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.591123]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [4.0020547]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.586219]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.7807727]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.8276873]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [3.7874167]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [3.8861163]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.7481275]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_nadam[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5224981307983398\n",
      "R2 score: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_nadam = np.sqrt(mean_squared_error(y_test_reg,pred_reg_nadam))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_nadam))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_nadam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot to show the best optimizer\n",
    "\n",
    "score_list_reg_opt=[score_reg_relu_stopping,score_relu_sgd,score_relu_rmsprop, score_relu_adagrad,score_relu_adadelta,score_relu_adamax,score_relu_nadam]\n",
    "names =['adam','SGD','RMSprop','Adagrad', 'Adadelta','Adamax','Nadam']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg_opt)), score_list_reg_opt)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Experiments with hidden layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 2 hidden Layers with adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_2l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.8660 - val_loss: 0.4020\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40204, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3141 - val_loss: 0.3004\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40204 to 0.30042, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2549 - val_loss: 0.2945\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.30042 to 0.29446, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2347 - val_loss: 0.3086\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.29446\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2146 - val_loss: 0.2885\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.29446 to 0.28852, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1855 - val_loss: 0.2829\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.28852 to 0.28289, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1598 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28289\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1366 - val_loss: 0.2906\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28289\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1137 - val_loss: 0.2987\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28289\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0952 - val_loss: 0.3001\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28289\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0771 - val_loss: 0.3110\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28289\n",
      "Epoch 00011: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.9125 - val_loss: 0.4030\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28289\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3195 - val_loss: 0.3080\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28289\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2598 - val_loss: 0.2941\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28289\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2414 - val_loss: 0.2907\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28289\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2241 - val_loss: 0.2894\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28289\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1968 - val_loss: 0.2834\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28289\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1617 - val_loss: 0.2862\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28289\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1354 - val_loss: 0.2909\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28289\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1111 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28289\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0908 - val_loss: 0.3008\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28289\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0751 - val_loss: 0.2946\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28289\n",
      "Epoch 00011: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.9045 - val_loss: 0.3930\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28289\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3146 - val_loss: 0.3072\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28289\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2581 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28289\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2395 - val_loss: 0.3018\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28289\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2141 - val_loss: 0.2858\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28289\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1898 - val_loss: 0.2803\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.28289 to 0.28032, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1641 - val_loss: 0.2795\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.28032 to 0.27949, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1388 - val_loss: 0.2834\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27949\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1161 - val_loss: 0.2868\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27949\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0971 - val_loss: 0.2953\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27949\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0810 - val_loss: 0.3009\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27949\n",
      "Epoch 00011: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.9406 - val_loss: 0.3788\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27949\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3127 - val_loss: 0.2975\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27949\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2605 - val_loss: 0.2969\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27949\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2425 - val_loss: 0.2889\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27949\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2235 - val_loss: 0.2834\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27949\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1958 - val_loss: 0.2794\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27949 to 0.27943, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1662 - val_loss: 0.2709\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.27943 to 0.27088, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1378 - val_loss: 0.2853\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27088\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1097 - val_loss: 0.2831\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27088\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0894 - val_loss: 0.2893\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27088\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0722 - val_loss: 0.2912\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27088\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0595 - val_loss: 0.2985\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27088\n",
      "Epoch 00012: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.8813 - val_loss: 0.3908\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27088\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3211 - val_loss: 0.3047\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27088\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2648 - val_loss: 0.2894\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27088\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2481 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27088\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2397 - val_loss: 0.2928\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27088\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2279 - val_loss: 0.2865\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27088\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1979 - val_loss: 0.2994\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27088\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1664 - val_loss: 0.2786\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27088\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1350 - val_loss: 0.2849\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27088\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1109 - val_loss: 0.2894\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27088\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0890 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27088\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0722 - val_loss: 0.3013\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27088\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0596 - val_loss: 0.3064\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27088\n",
      "Epoch 00013: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 2.0779 - val_loss: 0.4278\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27088\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3438 - val_loss: 0.3121\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27088\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2703 - val_loss: 0.2913\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27088\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2473 - val_loss: 0.2879\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27088\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2308 - val_loss: 0.2918\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27088\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2124 - val_loss: 0.2896\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27088\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1882 - val_loss: 0.2838\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27088\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1530 - val_loss: 0.2897\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27088\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1251 - val_loss: 0.2921\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27088\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0963 - val_loss: 0.2954\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27088\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0776 - val_loss: 0.2994\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27088\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0631 - val_loss: 0.3053\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27088\n",
      "Epoch 00012: early stopping\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.8490 - val_loss: 0.4073\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27088\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3268 - val_loss: 0.3060\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27088\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2610 - val_loss: 0.2924\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27088\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2405 - val_loss: 0.2943\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27088\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2314 - val_loss: 0.2955\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27088\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2147 - val_loss: 0.2945\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27088\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1945 - val_loss: 0.2971\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27088\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1645 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27088\n",
      "Epoch 00008: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 2.1389 - val_loss: 0.4307\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27088\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3361 - val_loss: 0.3035\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27088\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2656 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27088\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2447 - val_loss: 0.2982\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27088\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2319 - val_loss: 0.2902\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27088\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2190 - val_loss: 0.2840\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27088\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1888 - val_loss: 0.2814\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27088\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1593 - val_loss: 0.2858\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27088\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1277 - val_loss: 0.2898\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27088\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1050 - val_loss: 0.2920\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27088\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0850 - val_loss: 0.2963\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27088\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0714 - val_loss: 0.3006\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27088\n",
      "Epoch 00012: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.8937 - val_loss: 0.4100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27088\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.3304 - val_loss: 0.3128\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27088\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2654 - val_loss: 0.2964\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27088\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2460 - val_loss: 0.2927\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27088\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2338 - val_loss: 0.2998\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27088\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2199 - val_loss: 0.3257\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27088\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1944 - val_loss: 0.2841\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27088\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.1625 - val_loss: 0.2815\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27088\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.1322 - val_loss: 0.2921\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27088\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1051 - val_loss: 0.2898\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27088\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0843 - val_loss: 0.3020\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27088\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.0679 - val_loss: 0.2991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27088\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.0549 - val_loss: 0.3028\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27088\n",
      "Epoch 00013: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.9360 - val_loss: 0.3997\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27088\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3281 - val_loss: 0.3035\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27088\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2622 - val_loss: 0.2972\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27088\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2417 - val_loss: 0.2885\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27088\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2259 - val_loss: 0.2941\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27088\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2021 - val_loss: 0.2905\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27088\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1692 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27088\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1392 - val_loss: 0.2880\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27088\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.1123 - val_loss: 0.3009\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27088\n",
      "Epoch 00009: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_2l.hdf5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.0266707]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.8119447]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.5450063]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [3.97307]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.2067795]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.9883056]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.713993]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.031068]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [3.8721972]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.9428751]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5204581618309021\n",
      "R2 score: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_2l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl))\n",
    "print(\"Final score (RMSE): {}\".format(score_2l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 3 Hidden Layers with adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_3l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.5957 - val_loss: 0.3582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35817, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2992 - val_loss: 0.3131\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35817 to 0.31313, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2521 - val_loss: 0.2881\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31313 to 0.28812, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2318 - val_loss: 0.2869\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28812 to 0.28688, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2054 - val_loss: 0.2799\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.28688 to 0.27991, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1759 - val_loss: 0.2788\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27991 to 0.27876, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1497 - val_loss: 0.2865\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27876\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.1242 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27876\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.1001 - val_loss: 0.2988\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27876\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0821 - val_loss: 0.3001\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27876\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0658 - val_loss: 0.3072\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27876\n",
      "Epoch 00011: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 2.4880 - val_loss: 0.3922\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27876\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3143 - val_loss: 0.3021\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27876\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2562 - val_loss: 0.2904\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27876\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2379 - val_loss: 0.2898\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27876\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2180 - val_loss: 0.2789\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27876\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1916 - val_loss: 0.2725\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27876 to 0.27247, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1604 - val_loss: 0.2689\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.27247 to 0.26894, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1321 - val_loss: 0.2739\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26894\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1047 - val_loss: 0.2704\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26894\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0854 - val_loss: 0.2721\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26894\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0678 - val_loss: 0.2750\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26894\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0534 - val_loss: 0.2801\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26894\n",
      "Epoch 00012: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.9918 - val_loss: 0.3694\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26894\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.3070 - val_loss: 0.2879\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26894\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2531 - val_loss: 0.2813\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26894\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2307 - val_loss: 0.2893\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26894\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2109 - val_loss: 0.2892\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26894\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1839 - val_loss: 0.2902\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26894\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1518 - val_loss: 0.2905\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26894\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.1203 - val_loss: 0.2856\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26894\n",
      "Epoch 00008: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 2.4390 - val_loss: 0.4130\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26894\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.3319 - val_loss: 0.3050\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26894\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2637 - val_loss: 0.2898\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26894\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2418 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26894\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2242 - val_loss: 0.3034\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26894\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1971 - val_loss: 0.2890\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26894\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1628 - val_loss: 0.2756\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26894\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1366 - val_loss: 0.2889\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26894\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1125 - val_loss: 0.2930\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26894\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0922 - val_loss: 0.2997\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26894\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0748 - val_loss: 0.2993\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26894\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0605 - val_loss: 0.3076\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26894\n",
      "Epoch 00012: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.7707 - val_loss: 0.3769\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26894\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3138 - val_loss: 0.2974\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26894\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2604 - val_loss: 0.2890\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26894\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2446 - val_loss: 0.2910\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26894\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2179 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26894\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1769 - val_loss: 0.2800\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26894\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1423 - val_loss: 0.2981\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26894\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1098 - val_loss: 0.2917\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26894\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0872 - val_loss: 0.3059\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26894\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0683 - val_loss: 0.3148\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26894\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0554 - val_loss: 0.3086\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26894\n",
      "Epoch 00011: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 2.2516 - val_loss: 0.3815\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26894\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3142 - val_loss: 0.2995\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26894\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2557 - val_loss: 0.2855\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26894\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2343 - val_loss: 0.2824\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26894\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2079 - val_loss: 0.2782\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26894\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1744 - val_loss: 0.2838\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26894\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1449 - val_loss: 0.2769\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26894\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1174 - val_loss: 0.2819\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26894\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0924 - val_loss: 0.2921\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26894\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0759 - val_loss: 0.2835\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26894\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0595 - val_loss: 0.2933\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26894\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0493 - val_loss: 0.2937\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26894\n",
      "Epoch 00012: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.8695 - val_loss: 0.3429\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26894\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2967 - val_loss: 0.3075\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26894\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2544 - val_loss: 0.2953\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26894\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2388 - val_loss: 0.2902\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26894\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.2117 - val_loss: 0.2855\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26894\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1744 - val_loss: 0.2850\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26894\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1411 - val_loss: 0.2782\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26894\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1133 - val_loss: 0.2752\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26894\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0889 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26894\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0727 - val_loss: 0.2839\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26894\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0594 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26894\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0495 - val_loss: 0.2930\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26894\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0421 - val_loss: 0.3022\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26894\n",
      "Epoch 00013: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 2.1508 - val_loss: 0.3786\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26894\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3168 - val_loss: 0.2979\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26894\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2593 - val_loss: 0.2872\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26894\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2398 - val_loss: 0.2848\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26894\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2178 - val_loss: 0.2807\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26894\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1868 - val_loss: 0.2793\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26894\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1567 - val_loss: 0.2760\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26894\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1240 - val_loss: 0.2876\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26894\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0956 - val_loss: 0.2948\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26894\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0755 - val_loss: 0.2972\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26894\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0608 - val_loss: 0.3082\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26894\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0488 - val_loss: 0.3058\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26894\n",
      "Epoch 00012: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.8475 - val_loss: 0.3809\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26894\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3154 - val_loss: 0.3014\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26894\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2574 - val_loss: 0.2890\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26894\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2401 - val_loss: 0.2949\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26894\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2173 - val_loss: 0.2818\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26894\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1909 - val_loss: 0.2856\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26894\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1620 - val_loss: 0.2791\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26894\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1351 - val_loss: 0.2829\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26894\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1110 - val_loss: 0.2908\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26894\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0943 - val_loss: 0.2986\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26894\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0766 - val_loss: 0.3000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26894\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.0639 - val_loss: 0.3086\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26894\n",
      "Epoch 00012: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.9733 - val_loss: 0.3570\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26894\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3094 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26894\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2559 - val_loss: 0.2887\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26894\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2358 - val_loss: 0.2886\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26894\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2139 - val_loss: 0.2788\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26894\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1780 - val_loss: 0.2761\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26894\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1480 - val_loss: 0.2806\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26894\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1163 - val_loss: 0.2808\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26894\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0877 - val_loss: 0.2838\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26894\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0683 - val_loss: 0.2889\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26894\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0545 - val_loss: 0.2972\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26894\n",
      "Epoch 00011: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(10, activation='relu')) # Hidden 3\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_3l.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl_3 = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.3867779]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.8098164]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.412424]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [3.9339142]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.3762555]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.819237]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.832407]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.03011]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.0332227]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.8713186]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl_3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5185952186584473\n",
      "R2 score: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_3l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl_3))\n",
    "print(\"Final score (RMSE): {}\".format(score_3l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4 Hidden Layers with adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_4l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.7213 - val_loss: 0.3273\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32730, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2859 - val_loss: 0.2929\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.32730 to 0.29293, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2474 - val_loss: 0.2897\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.29293 to 0.28966, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2229 - val_loss: 0.2842\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28966 to 0.28419, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1902 - val_loss: 0.2809\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.28419 to 0.28087, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1552 - val_loss: 0.2752\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.28087 to 0.27517, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1241 - val_loss: 0.2804\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27517\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0959 - val_loss: 0.2855\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27517\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0762 - val_loss: 0.2912\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27517\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0609 - val_loss: 0.2963\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27517\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0483 - val_loss: 0.2987\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27517\n",
      "Epoch 00011: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 2.3053 - val_loss: 0.3681\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27517\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.3078 - val_loss: 0.2988\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27517\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2580 - val_loss: 0.2899\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27517\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2407 - val_loss: 0.2826\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27517\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2143 - val_loss: 0.2765\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27517\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1831 - val_loss: 0.2681\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27517 to 0.26807, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1535 - val_loss: 0.2705\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26807\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.1202 - val_loss: 0.2720\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26807\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0917 - val_loss: 0.2823\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26807\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0740 - val_loss: 0.2816\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26807\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0578 - val_loss: 0.2868\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26807\n",
      "Epoch 00011: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.9561 - val_loss: 0.3913\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26807\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.3200 - val_loss: 0.3035\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26807\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2582 - val_loss: 0.2932\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26807\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2399 - val_loss: 0.2967\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26807\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2195 - val_loss: 0.2981\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26807\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1967 - val_loss: 0.2911\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26807\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1655 - val_loss: 0.2872\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26807\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.1296 - val_loss: 0.2908\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26807\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.1002 - val_loss: 0.2897\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26807\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0789 - val_loss: 0.2920\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26807\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0633 - val_loss: 0.2955\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26807\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.0510 - val_loss: 0.2933\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26807\n",
      "Epoch 00012: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.1206 - val_loss: 0.3417\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26807\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2939 - val_loss: 0.2917\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26807\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2518 - val_loss: 0.2970\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26807\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2341 - val_loss: 0.2880\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26807\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2134 - val_loss: 0.2993\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26807\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1774 - val_loss: 0.2841\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26807\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1350 - val_loss: 0.2877\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26807\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.1022 - val_loss: 0.2832\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26807\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0765 - val_loss: 0.2928\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26807\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0606 - val_loss: 0.2980\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26807\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0501 - val_loss: 0.2996\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26807\n",
      "Epoch 00011: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.4372 - val_loss: 0.3208\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26807\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2854 - val_loss: 0.2895\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26807\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2468 - val_loss: 0.2887\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26807\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2163 - val_loss: 0.2825\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26807\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1712 - val_loss: 0.2805\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26807\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1283 - val_loss: 0.2769\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26807\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0951 - val_loss: 0.2857\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26807\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0741 - val_loss: 0.3045\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26807\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0609 - val_loss: 0.2893\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26807\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0496 - val_loss: 0.3002\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26807\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0402 - val_loss: 0.2974\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26807\n",
      "Epoch 00011: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.1468 - val_loss: 0.3295\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26807\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2847 - val_loss: 0.2903\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26807\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2477 - val_loss: 0.2945\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26807\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2212 - val_loss: 0.2855\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26807\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1811 - val_loss: 0.2976\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26807\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1381 - val_loss: 0.3065\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26807\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1035 - val_loss: 0.2877\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26807\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0748 - val_loss: 0.2961\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26807\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0596 - val_loss: 0.3031\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26807\n",
      "Epoch 00009: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.7919 - val_loss: 0.3781\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26807\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.3084 - val_loss: 0.3058\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26807\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2575 - val_loss: 0.3009\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26807\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2398 - val_loss: 0.2972\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26807\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2154 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26807\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1806 - val_loss: 0.2788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26807\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1463 - val_loss: 0.2819\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26807\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.1118 - val_loss: 0.2751\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26807\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0864 - val_loss: 0.2877\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26807\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0676 - val_loss: 0.2877\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26807\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0541 - val_loss: 0.2890\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26807\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.0429 - val_loss: 0.2979\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26807\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.0360 - val_loss: 0.3041\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26807\n",
      "Epoch 00013: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.6500 - val_loss: 0.3540\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26807\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2814 - val_loss: 0.2917\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26807\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2441 - val_loss: 0.2870\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26807\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2188 - val_loss: 0.2829\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26807\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1844 - val_loss: 0.2902\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26807\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1389 - val_loss: 0.2931\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26807\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1057 - val_loss: 0.2871\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26807\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0773 - val_loss: 0.2947\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26807\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0606 - val_loss: 0.2937\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26807\n",
      "Epoch 00009: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.8590 - val_loss: 0.3376\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26807\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2914 - val_loss: 0.2875\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26807\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2488 - val_loss: 0.2838\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26807\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2134 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26807\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1793 - val_loss: 0.2858\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26807\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1461 - val_loss: 0.2771\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26807\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1178 - val_loss: 0.2797\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26807\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0910 - val_loss: 0.2819\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26807\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0714 - val_loss: 0.2924\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26807\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0577 - val_loss: 0.2970\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26807\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0458 - val_loss: 0.2902\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26807\n",
      "Epoch 00011: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.3150 - val_loss: 0.3656\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26807\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3013 - val_loss: 0.2929\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26807\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2495 - val_loss: 0.2855\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26807\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2248 - val_loss: 0.3069\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26807\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1983 - val_loss: 0.2810\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26807\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1574 - val_loss: 0.2730\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26807\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1242 - val_loss: 0.2842\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26807\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0940 - val_loss: 0.2860\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26807\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0733 - val_loss: 0.2882\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26807\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0591 - val_loss: 0.2965\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26807\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0457 - val_loss: 0.3103\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26807\n",
      "Epoch 00011: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(80, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "    model_reg_relu.add(Dense(60, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(20, activation='relu')) # Hidden 3\n",
    "    model_reg_relu.add(Dense(10, activation='relu')) # Hidden 4\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_4l.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl_4 = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.0704691]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.5892537]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.516894]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [4.093336]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.164758]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.899861]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [5.012513]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [3.9891157]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [3.922152]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.4778225]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl_4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5177568793296814\n",
      "R2 score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_4l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl_4))\n",
    "print(\"Final score (RMSE): {}\".format(score_4l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5 Hidden Layers with adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_5l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.5028 - val_loss: 0.3173\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31731, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2768 - val_loss: 0.2930\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31731 to 0.29302, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2405 - val_loss: 0.2916\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.29302 to 0.29159, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2075 - val_loss: 0.2804\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.29159 to 0.28039, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1662 - val_loss: 0.2764\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.28039 to 0.27641, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1295 - val_loss: 0.2886\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27641\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0933 - val_loss: 0.2908\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27641\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0708 - val_loss: 0.2850\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27641\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0548 - val_loss: 0.2899\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27641\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0424 - val_loss: 0.2957\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27641\n",
      "Epoch 00010: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.6605 - val_loss: 0.3323\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27641\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2895 - val_loss: 0.2851\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27641\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2496 - val_loss: 0.2967\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27641\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2221 - val_loss: 0.2803\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27641\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1848 - val_loss: 0.2720\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.27641 to 0.27200, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1476 - val_loss: 0.2665\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27200 to 0.26648, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1120 - val_loss: 0.2761\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26648\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0840 - val_loss: 0.2733\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26648\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0653 - val_loss: 0.2799\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26648\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0499 - val_loss: 0.2905\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26648\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0419 - val_loss: 0.2913\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26648\n",
      "Epoch 00011: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.6935 - val_loss: 0.3209\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26648\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2774 - val_loss: 0.2839\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26648\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2417 - val_loss: 0.2779\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26648\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2069 - val_loss: 0.2862\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26648\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1689 - val_loss: 0.2625\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.26648 to 0.26251, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1337 - val_loss: 0.2691\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26251\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0970 - val_loss: 0.2772\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26251\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0763 - val_loss: 0.2788\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26251\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0608 - val_loss: 0.2846\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26251\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0487 - val_loss: 0.2853\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26251\n",
      "Epoch 00010: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 2.1313 - val_loss: 0.3522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26251\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2856 - val_loss: 0.2927\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26251\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2501 - val_loss: 0.2816\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26251\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2172 - val_loss: 0.2797\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26251\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1799 - val_loss: 0.2713\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26251\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1450 - val_loss: 0.2890\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26251\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1136 - val_loss: 0.2794\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26251\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0874 - val_loss: 0.2933\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26251\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0707 - val_loss: 0.3059\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26251\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0530 - val_loss: 0.2991\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26251\n",
      "Epoch 00010: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 2.3141 - val_loss: 0.3391\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26251\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2875 - val_loss: 0.3001\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26251\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2457 - val_loss: 0.2797\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26251\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2104 - val_loss: 0.2793\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26251\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1707 - val_loss: 0.2705\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26251\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1342 - val_loss: 0.2765\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26251\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1047 - val_loss: 0.2839\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26251\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0827 - val_loss: 0.2897\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26251\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0630 - val_loss: 0.2999\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26251\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0515 - val_loss: 0.2995\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26251\n",
      "Epoch 00010: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.7131 - val_loss: 0.3183\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26251\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2824 - val_loss: 0.2876\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26251\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2391 - val_loss: 0.2880\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26251\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2106 - val_loss: 0.2918\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26251\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1624 - val_loss: 0.2885\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26251\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1176 - val_loss: 0.2988\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26251\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0849 - val_loss: 0.2918\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26251\n",
      "Epoch 00007: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 2.2531 - val_loss: 0.3290\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26251\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2930 - val_loss: 0.2865\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26251\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2481 - val_loss: 0.2853\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26251\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2166 - val_loss: 0.2840\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26251\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1725 - val_loss: 0.2826\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26251\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1282 - val_loss: 0.2969\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26251\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0939 - val_loss: 0.2943\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26251\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0694 - val_loss: 0.3153\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26251\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0536 - val_loss: 0.3096\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26251\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0432 - val_loss: 0.3206\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26251\n",
      "Epoch 00010: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.4562 - val_loss: 0.3111\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26251\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2840 - val_loss: 0.2910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26251\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2473 - val_loss: 0.2999\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26251\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2238 - val_loss: 0.2946\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26251\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1992 - val_loss: 0.2928\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26251\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1564 - val_loss: 0.2876\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26251\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1116 - val_loss: 0.2994\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26251\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0874 - val_loss: 0.2940\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26251\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0651 - val_loss: 0.2987\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26251\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0516 - val_loss: 0.2986\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26251\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.0419 - val_loss: 0.2959\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26251\n",
      "Epoch 00011: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.7000 - val_loss: 0.3288\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26251\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2748 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26251\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2357 - val_loss: 0.2841\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26251\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.1981 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26251\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1582 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26251\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1221 - val_loss: 0.2851\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26251\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0954 - val_loss: 0.3063\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26251\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0743 - val_loss: 0.2973\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26251\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0597 - val_loss: 0.3009\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26251\n",
      "Epoch 00009: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.4740 - val_loss: 0.3171\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26251\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2765 - val_loss: 0.2894\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26251\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2311 - val_loss: 0.2744\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26251\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.1894 - val_loss: 0.2768\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26251\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1487 - val_loss: 0.2886\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26251\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1136 - val_loss: 0.2903\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26251\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0852 - val_loss: 0.2965\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26251\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0666 - val_loss: 0.2926\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26251\n",
      "Epoch 00008: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(80, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "    model_reg_relu.add(Dense(60, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(40, activation='relu')) # Hidden 3\n",
    "    model_reg_relu.add(Dense(20, activation='relu')) # Hidden 4\n",
    "    model_reg_relu.add(Dense(10, activation='relu')) # Hidden 5\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_5l.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl_5 = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.0704691]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.5892537]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.516894]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [4.093336]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.164758]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.899861]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [5.012513]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [3.9891157]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [3.922152]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.4778225]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl_4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5123612880706787\n",
      "R2 score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_5l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl_5))\n",
    "print(\"Final score (RMSE): {}\".format(score_5l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot to show the best optimizer\n",
    "\n",
    "score_list_reg_layers=[score_2l,score_3l, score_4l,score_5l]\n",
    "names =['2 Layers','3 Layers','4 Layers', '5 Layers']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg_layers)), score_list_reg_layers)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Activation Function - Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Training without early stopping and Model Checkpoint and Sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with sigmoid\n",
    "model_reg_sig = Sequential()\n",
    "\n",
    "model_reg_sig.add(Dense(25, input_dim=x_train_reg.shape[1], activation='sigmoid'))  \n",
    "model_reg_sig.add(Dense(10, activation='sigmoid')) # Hidden 2\n",
    "model_reg_sig.add(Dense(1)) # Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 6s - loss: 4.0584\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.1386\n",
      "Epoch 3/100\n",
      " - 1s - loss: 1.0512\n",
      "Epoch 4/100\n",
      " - 1s - loss: 1.0268\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.9146\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6063\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3869\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3052\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.2689\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2490\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.2357\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.2276\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.2204\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.2151\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.2108\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.2060\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.2026\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.1997\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.1966\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.1938\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.1919\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.1888\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.1869\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.1845\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.1836\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.1810\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.1798\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.1779\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.1769\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.1750\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.1745\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.1728\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.1720\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.1706\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.1689\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.1681\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.1667\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.1655\n",
      "Epoch 39/100\n",
      " - 2s - loss: 0.1645\n",
      "Epoch 40/100\n",
      " - 2s - loss: 0.1639\n",
      "Epoch 41/100\n",
      " - 2s - loss: 0.1632\n",
      "Epoch 42/100\n",
      " - 2s - loss: 0.1619\n",
      "Epoch 43/100\n",
      " - 2s - loss: 0.1607\n",
      "Epoch 44/100\n",
      " - 2s - loss: 0.1598\n",
      "Epoch 45/100\n",
      " - 2s - loss: 0.1589\n",
      "Epoch 46/100\n",
      " - 2s - loss: 0.1579\n",
      "Epoch 47/100\n",
      " - 2s - loss: 0.1570\n",
      "Epoch 48/100\n",
      " - 3s - loss: 0.1562\n",
      "Epoch 49/100\n",
      " - 3s - loss: 0.1554\n",
      "Epoch 50/100\n",
      " - 3s - loss: 0.1544\n",
      "Epoch 51/100\n",
      " - 2s - loss: 0.1536\n",
      "Epoch 52/100\n",
      " - 2s - loss: 0.1530\n",
      "Epoch 53/100\n",
      " - 2s - loss: 0.1521\n",
      "Epoch 54/100\n",
      " - 2s - loss: 0.1516\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.1503\n",
      "Epoch 56/100\n",
      " - 2s - loss: 0.1499\n",
      "Epoch 57/100\n",
      " - 2s - loss: 0.1492\n",
      "Epoch 58/100\n",
      " - 2s - loss: 0.1488\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.1480\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.1469\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.1468\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.1458\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.1448\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.1444\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.1436\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.1430\n",
      "Epoch 67/100\n",
      " - 2s - loss: 0.1425\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.1418\n",
      "Epoch 69/100\n",
      " - 2s - loss: 0.1412\n",
      "Epoch 70/100\n",
      " - 2s - loss: 0.1413\n",
      "Epoch 71/100\n",
      " - 2s - loss: 0.1400\n",
      "Epoch 72/100\n",
      " - 2s - loss: 0.1397\n",
      "Epoch 73/100\n",
      " - 2s - loss: 0.1388\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.1384\n",
      "Epoch 75/100\n",
      " - 2s - loss: 0.1378\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.1371\n",
      "Epoch 77/100\n",
      " - 2s - loss: 0.1370\n",
      "Epoch 78/100\n",
      " - 2s - loss: 0.1364\n",
      "Epoch 79/100\n",
      " - 2s - loss: 0.1356\n",
      "Epoch 80/100\n",
      " - 2s - loss: 0.1353\n",
      "Epoch 81/100\n",
      " - 2s - loss: 0.1346\n",
      "Epoch 82/100\n",
      " - 2s - loss: 0.1343\n",
      "Epoch 83/100\n",
      " - 2s - loss: 0.1336\n",
      "Epoch 84/100\n",
      " - 2s - loss: 0.1335\n",
      "Epoch 85/100\n",
      " - 2s - loss: 0.1329\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.1321\n",
      "Epoch 87/100\n",
      " - 2s - loss: 0.1318\n",
      "Epoch 88/100\n",
      " - 2s - loss: 0.1313\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.1310\n",
      "Epoch 90/100\n",
      " - 2s - loss: 0.1305\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.1298\n",
      "Epoch 92/100\n",
      " - 2s - loss: 0.1293\n",
      "Epoch 93/100\n",
      " - 2s - loss: 0.1288\n",
      "Epoch 94/100\n",
      " - 2s - loss: 0.1284\n",
      "Epoch 95/100\n",
      " - 2s - loss: 0.1278\n",
      "Epoch 96/100\n",
      " - 2s - loss: 0.1275\n",
      "Epoch 97/100\n",
      " - 2s - loss: 0.1270\n",
      "Epoch 98/100\n",
      " - 2s - loss: 0.1266\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.1258\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.1256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2624fbdbb70>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training with sigmoid \n",
    "model_reg_sig.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_reg_sig.fit(x_train_reg,y_train_reg,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_sig_simple = model_reg_sig.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_sig_simple.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.0799503]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [4.0102205]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.6716404]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [4.2371492]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.3635006]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.914568]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.69597]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.202832]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.3296256]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.365282]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_sig_simple[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5161359310150146\n",
      "R2 score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_sig = np.sqrt(mean_squared_error(y_test_reg,pred_reg_sig_simple))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_sig))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_sig_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Training with early stopping and Model Checkpoint and Sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_sigmoid = ModelCheckpoint(filepath=\"./best_weights_sigmoid.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 2.4801 - val_loss: 1.1049\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.10491, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.0944 - val_loss: 0.9753\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.10491 to 0.97535, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.0576 - val_loss: 0.9754\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.97535\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.0572 - val_loss: 0.9751\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.97535 to 0.97514, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0573 - val_loss: 0.9756\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.97514\n",
      "Epoch 00005: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 11.4972 - val_loss: 7.9403\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.97514\n",
      "Epoch 2/100\n",
      " - 2s - loss: 6.9835 - val_loss: 5.7805\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.97514\n",
      "Epoch 3/100\n",
      " - 2s - loss: 5.1169 - val_loss: 4.1997\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.97514\n",
      "Epoch 4/100\n",
      " - 2s - loss: 3.7439 - val_loss: 3.0487\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.97514\n",
      "Epoch 5/100\n",
      " - 2s - loss: 2.7568 - val_loss: 2.2437\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.97514\n",
      "Epoch 6/100\n",
      " - 3s - loss: 2.0763 - val_loss: 1.7025\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.97514\n",
      "Epoch 7/100\n",
      " - 3s - loss: 1.6304 - val_loss: 1.3614\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.97514\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.3567 - val_loss: 1.1620\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.97514\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.2007 - val_loss: 1.0561\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.97514\n",
      "Epoch 10/100\n",
      " - 3s - loss: 1.1196 - val_loss: 1.0054\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.97514\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.0814 - val_loss: 0.9843\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.97514\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.0654 - val_loss: 0.9771\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.97514\n",
      "Epoch 13/100\n",
      " - 3s - loss: 1.0596 - val_loss: 0.9753\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.97514\n",
      "Epoch 14/100\n",
      " - 3s - loss: 1.0579 - val_loss: 0.9751\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.97514 to 0.97505, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.0574 - val_loss: 0.9752\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.97505\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.0573 - val_loss: 0.9753\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.97505\n",
      "Epoch 00016: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 9.0439 - val_loss: 5.2231\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.97505\n",
      "Epoch 2/100\n",
      " - 2s - loss: 3.7310 - val_loss: 2.3610\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.97505\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.8604 - val_loss: 1.3163\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.97505\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.2415 - val_loss: 1.0354\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.97505\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0875 - val_loss: 0.9803\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.97505\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.0603 - val_loss: 0.9751\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.97505\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.0574 - val_loss: 0.9753\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.97505\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.0573 - val_loss: 0.9754\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.97505\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.0572 - val_loss: 0.9754\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.97505\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 5.7386 - val_loss: 2.5576\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.97505\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.6695 - val_loss: 1.0581\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.97505\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.0831 - val_loss: 0.9757\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.97505\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.0577 - val_loss: 0.9752\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.97505\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0575 - val_loss: 0.9755\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.97505\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0576 - val_loss: 0.9756\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.97505\n",
      "Epoch 00006: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 3.5812 - val_loss: 1.5050\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.97505\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.2543 - val_loss: 0.9991\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.97505\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.0654 - val_loss: 0.9751\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.97505\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.0574 - val_loss: 0.9757\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.97505\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0574 - val_loss: 0.9752\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.97505\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0574 - val_loss: 0.9753\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.97505\n",
      "Epoch 00006: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 2.3400 - val_loss: 1.0003\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.97505\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.0629 - val_loss: 0.9754\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.97505\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.0572 - val_loss: 0.9750\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.97505 to 0.97498, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.0574 - val_loss: 0.9751\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.97498\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0572 - val_loss: 0.9765\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.97498\n",
      "Epoch 00005: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 2.0589 - val_loss: 0.9903\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.97498\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.0618 - val_loss: 0.9750\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.97498\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.0573 - val_loss: 0.9760\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.97498\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.0571 - val_loss: 0.9751\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.97498\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0569 - val_loss: 0.9749\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.97498 to 0.97489, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 00005: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.4812 - val_loss: 0.9748\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.97489 to 0.97482, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.0567 - val_loss: 0.9740\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.97482 to 0.97399, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.0546 - val_loss: 0.9694\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.97399 to 0.96943, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.9912 - val_loss: 0.5863\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.96943 to 0.58626, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.3672 - val_loss: 0.2913\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.58626 to 0.29132, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2582 - val_loss: 0.2635\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.29132 to 0.26347, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.2353 - val_loss: 0.2571\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.26347 to 0.25710, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.2194 - val_loss: 0.2620\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25710\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2100 - val_loss: 0.2505\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.25710 to 0.25048, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.1993 - val_loss: 0.2436\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.25048 to 0.24359, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.1954 - val_loss: 0.2465\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.24359\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.1879 - val_loss: 0.2410\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.24359 to 0.24103, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1821 - val_loss: 0.2430\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.24103\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.1782 - val_loss: 0.2530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss did not improve from 0.24103\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1760 - val_loss: 0.2419\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.24103\n",
      "Epoch 00015: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.3584 - val_loss: 0.9747\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24103\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.0568 - val_loss: 0.9745\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24103\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.0459 - val_loss: 0.9193\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24103\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.4968 - val_loss: 0.2962\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24103\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2684 - val_loss: 0.2764\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24103\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2442 - val_loss: 0.2620\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24103\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.2262 - val_loss: 0.2637\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.24103\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.2156 - val_loss: 0.2523\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.24103\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2065 - val_loss: 0.2508\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.24103\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.1974 - val_loss: 0.2508\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.24103\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.1896 - val_loss: 0.2430\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.24103\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1860 - val_loss: 0.2443\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.24103\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.1820 - val_loss: 0.2454\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.24103\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1784 - val_loss: 0.2524\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.24103\n",
      "Epoch 00014: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 2.9735 - val_loss: 1.2456\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24103\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.1428 - val_loss: 0.9795\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24103\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.0581 - val_loss: 0.9759\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24103\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.0574 - val_loss: 0.9754\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24103\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0573 - val_loss: 0.9753\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24103\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.0574 - val_loss: 0.9751\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24103\n",
      "Epoch 00006: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_sig = Sequential()\n",
    "\n",
    "    model_reg_sig.add(Dense(120, input_dim=x_train_reg.shape[1], activation='sigmoid'))  \n",
    "    model_reg_sig.add(Dense(80, activation='sigmoid')) # Hidden 2\n",
    "    model_reg_sig.add(Dense(60, activation='sigmoid')) # Hidden 3\n",
    "    model_reg_sig.add(Dense(10, activation='sigmoid')) # Hidden 4\n",
    "    model_reg_sig.add(Dense(1)) # Output\n",
    "    model_reg_sig.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=1, mode='auto')\n",
    "    model_reg_sig.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_sigmoid],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_sig.load_weights('./best_weights_sigmoid.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_sig_stopping = model_reg_sig.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_sig_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.5, predicted Stars: [3.24848]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.881753]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.6787076]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [4.222487]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [4.2403736]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [4.709323]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.5, predicted Stars: [4.7718234]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.150016]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.1454115]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.5785422]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_sig_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.4909469783306122\n",
      "R2 score: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_sig_stopping = np.sqrt(mean_squared_error(y_test_reg,pred_reg_sig_stopping))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_sig_stopping))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_sig_stopping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Activation Function - Tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Training without early stopping and Model Checkpoint and Tanh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg_tanh, x_test_reg_tanh, y_train_reg_tanh, y_test_reg_tanh = train_test_split(x_matrix_zscore, y_stars_regression , test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with tanh\n",
    "model_reg_tanh = Sequential()\n",
    "\n",
    "model_reg_tanh.add(Dense(25, input_dim=x_train_reg_tanh.shape[1], activation='tanh'))  \n",
    "model_reg_tanh.add(Dense(10, activation='tanh')) # Hidden 2\n",
    "model_reg_tanh.add(Dense(1)) # Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 9s - loss: 2.2848\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.8098\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.3159\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.2379\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2177\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2077\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.2000\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.1954\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.1899\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.1860\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1810\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1772\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1728\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.1701\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.1669\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1630\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.1598\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.1575\n",
      "Epoch 19/100\n",
      " - 2s - loss: 0.1546\n",
      "Epoch 20/100\n",
      " - 2s - loss: 0.1513\n",
      "Epoch 21/100\n",
      " - 2s - loss: 0.1498\n",
      "Epoch 22/100\n",
      " - 2s - loss: 0.1461\n",
      "Epoch 23/100\n",
      " - 2s - loss: 0.1439\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.1419\n",
      "Epoch 25/100\n",
      " - 2s - loss: 0.1386\n",
      "Epoch 26/100\n",
      " - 2s - loss: 0.1363\n",
      "Epoch 27/100\n",
      " - 2s - loss: 0.1336\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.1313\n",
      "Epoch 29/100\n",
      " - 2s - loss: 0.1290\n",
      "Epoch 30/100\n",
      " - 3s - loss: 0.1266\n",
      "Epoch 31/100\n",
      " - 2s - loss: 0.1242\n",
      "Epoch 32/100\n",
      " - 2s - loss: 0.1225\n",
      "Epoch 33/100\n",
      " - 2s - loss: 0.1198\n",
      "Epoch 34/100\n",
      " - 2s - loss: 0.1177\n",
      "Epoch 35/100\n",
      " - 2s - loss: 0.1157\n",
      "Epoch 36/100\n",
      " - 3s - loss: 0.1133\n",
      "Epoch 37/100\n",
      " - 2s - loss: 0.1111\n",
      "Epoch 38/100\n",
      " - 2s - loss: 0.1093\n",
      "Epoch 39/100\n",
      " - 2s - loss: 0.1067\n",
      "Epoch 40/100\n",
      " - 2s - loss: 0.1052\n",
      "Epoch 41/100\n",
      " - 2s - loss: 0.1038\n",
      "Epoch 42/100\n",
      " - 2s - loss: 0.1016\n",
      "Epoch 43/100\n",
      " - 2s - loss: 0.0993\n",
      "Epoch 44/100\n",
      " - 2s - loss: 0.0977\n",
      "Epoch 45/100\n",
      " - 2s - loss: 0.0966\n",
      "Epoch 46/100\n",
      " - 2s - loss: 0.0945\n",
      "Epoch 47/100\n",
      " - 3s - loss: 0.0927\n",
      "Epoch 48/100\n",
      " - 2s - loss: 0.0908\n",
      "Epoch 49/100\n",
      " - 2s - loss: 0.0892\n",
      "Epoch 50/100\n",
      " - 2s - loss: 0.0878\n",
      "Epoch 51/100\n",
      " - 2s - loss: 0.0862\n",
      "Epoch 52/100\n",
      " - 2s - loss: 0.0845\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.0833\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.0820\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.0801\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.0793\n",
      "Epoch 57/100\n",
      " - 4s - loss: 0.0780\n",
      "Epoch 58/100\n",
      " - 2s - loss: 0.0767\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.0749\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.0737\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.0727\n",
      "Epoch 62/100\n",
      " - 3s - loss: 0.0714\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.0707\n",
      "Epoch 64/100\n",
      " - 2s - loss: 0.0694\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.0677\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.0669\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.0658\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.0654\n",
      "Epoch 69/100\n",
      " - 2s - loss: 0.0644\n",
      "Epoch 70/100\n",
      " - 2s - loss: 0.0630\n",
      "Epoch 71/100\n",
      " - 2s - loss: 0.0614\n",
      "Epoch 72/100\n",
      " - 2s - loss: 0.0611\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.0599\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.0590\n",
      "Epoch 75/100\n",
      " - 2s - loss: 0.0583\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.0569\n",
      "Epoch 77/100\n",
      " - 2s - loss: 0.0561\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.0555\n",
      "Epoch 79/100\n",
      " - 2s - loss: 0.0546\n",
      "Epoch 80/100\n",
      " - 2s - loss: 0.0539\n",
      "Epoch 81/100\n",
      " - 2s - loss: 0.0528\n",
      "Epoch 82/100\n",
      " - 2s - loss: 0.0517\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.0513\n",
      "Epoch 84/100\n",
      " - 2s - loss: 0.0502\n",
      "Epoch 85/100\n",
      " - 2s - loss: 0.0492\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.0483\n",
      "Epoch 87/100\n",
      " - 2s - loss: 0.0479\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.0469\n",
      "Epoch 89/100\n",
      " - 2s - loss: 0.0461\n",
      "Epoch 90/100\n",
      " - 2s - loss: 0.0457\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.0455\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.0447\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.0435\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.0428\n",
      "Epoch 95/100\n",
      " - 2s - loss: 0.0426\n",
      "Epoch 96/100\n",
      " - 2s - loss: 0.0413\n",
      "Epoch 97/100\n",
      " - 2s - loss: 0.0411\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.0401\n",
      "Epoch 99/100\n",
      " - 2s - loss: 0.0398\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.0393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2623d34a940>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training with sigmoid \n",
    "model_reg_tanh.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_reg_tanh.fit(x_train_reg_tanh,y_train_reg_tanh,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_tanh_simple = model_reg_tanh.predict(x_test_reg_tanh)\n",
    "print(\"Shape: {}\".format(pred_reg_tanh_simple.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.0, predicted Stars: [3.1018705]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 5.0, predicted Stars: [4.5146933]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [4.7276216]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [4.6877384]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 3.0, predicted Stars: [2.2276354]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 4.5, predicted Stars: [4.6085005]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 2.5, predicted Stars: [2.8314338]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.5, predicted Stars: [4.330737]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 2.0, predicted Stars: [1.3806022]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 1.0, predicted Stars: [1.8194293]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg_tanh[i],pred_reg_tanh_simple[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.6366003155708313\n",
      "R2 score: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_tanh = np.sqrt(mean_squared_error(y_test_reg_tanh,pred_reg_tanh_simple))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_tanh))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg_tanh, pred_reg_tanh_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Training with early stopping and Model Checkpoint and Tanh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_tanh = ModelCheckpoint(filepath=\"./best_weights_tanh.hdf5\", verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.8416 - val_loss: 0.2456\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24556, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2337 - val_loss: 0.2516\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24556\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2123 - val_loss: 0.2373\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24556 to 0.23731, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1987 - val_loss: 0.2385\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23731\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1877 - val_loss: 0.2302\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23731 to 0.23024, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1778 - val_loss: 0.2343\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23024\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1698 - val_loss: 0.2333\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23024\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1593 - val_loss: 0.2367\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23024\n",
      "Epoch 00008: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.0720 - val_loss: 0.2710\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23024\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2441 - val_loss: 0.2700\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23024\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2115 - val_loss: 0.2460\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23024\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1986 - val_loss: 0.3097\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23024\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1868 - val_loss: 0.2351\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23024\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1739 - val_loss: 0.2366\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23024\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1676 - val_loss: 0.2376\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23024\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1591 - val_loss: 0.2344\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23024\n",
      "Epoch 00008: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.8941 - val_loss: 0.2466\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23024\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2319 - val_loss: 0.2403\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23024\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2087 - val_loss: 0.2327\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23024\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1959 - val_loss: 0.2335\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23024\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1840 - val_loss: 0.2487\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23024\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1754 - val_loss: 0.2463\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23024\n",
      "Epoch 00006: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 0.8454 - val_loss: 0.2499\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23024\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2348 - val_loss: 0.2547\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23024\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2133 - val_loss: 0.2553\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23024\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1980 - val_loss: 0.2332\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23024\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1859 - val_loss: 0.2312\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23024\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1758 - val_loss: 0.2333\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23024\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1656 - val_loss: 0.2368\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23024\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1622 - val_loss: 0.2437\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23024\n",
      "Epoch 00008: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.0833 - val_loss: 0.2598\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23024\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2437 - val_loss: 0.2324\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23024\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2123 - val_loss: 0.2323\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23024\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1978 - val_loss: 0.2399\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23024\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1837 - val_loss: 0.2322\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23024\n",
      "Epoch 00005: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 0.9520 - val_loss: 0.2518\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23024\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2382 - val_loss: 0.2376\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23024\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2142 - val_loss: 0.2320\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23024\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1977 - val_loss: 0.2448\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23024\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1864 - val_loss: 0.2349\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23024\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1783 - val_loss: 0.2454\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23024\n",
      "Epoch 00006: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 0.8491 - val_loss: 0.2800\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23024\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2324 - val_loss: 0.2308\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23024\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2122 - val_loss: 0.2328\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23024\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1975 - val_loss: 0.2512\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23024\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1873 - val_loss: 0.2493\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23024\n",
      "Epoch 00005: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 0.9604 - val_loss: 0.2563\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23024\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2371 - val_loss: 0.2399\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23024\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2105 - val_loss: 0.2355\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23024\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1999 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23024 to 0.22860, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1857 - val_loss: 0.2316\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22860\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1768 - val_loss: 0.2314\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.22860\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.1674 - val_loss: 0.2344\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.22860\n",
      "Epoch 00007: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.9177 - val_loss: 0.2483\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22860\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2406 - val_loss: 0.2319\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22860\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2124 - val_loss: 0.2318\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22860\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1985 - val_loss: 0.2284\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22860 to 0.22837, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1846 - val_loss: 0.2564\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22837\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1757 - val_loss: 0.2296\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.22837\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1672 - val_loss: 0.2484\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.22837\n",
      "Epoch 00007: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.9568 - val_loss: 0.2465\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.22837\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.2343 - val_loss: 0.2378\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.22837\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.2147 - val_loss: 0.2465\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22837\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.1975 - val_loss: 0.2399\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22837\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1836 - val_loss: 0.2343\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22837\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1762 - val_loss: 0.2360\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.22837\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.1707 - val_loss: 0.2315\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.22837\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.1614 - val_loss: 0.2496\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.22837\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.1534 - val_loss: 0.2617\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.22837\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.1476 - val_loss: 0.2614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss did not improve from 0.22837\n",
      "Epoch 00010: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_tanh = Sequential()\n",
    "\n",
    "    model_reg_tanh.add(Dense(120, input_dim=x_train_reg_tanh.shape[1], activation='tanh'))  \n",
    "    model_reg_tanh.add(Dense(80, activation='tanh')) # Hidden 2\n",
    "    model_reg_tanh.add(Dense(40, activation='tanh')) # Hidden 3\n",
    "    model_reg_tanh.add(Dense(20, activation='tanh')) # Hidden 3\n",
    "    model_reg_tanh.add(Dense(1)) # Output\n",
    "    model_reg_tanh.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=1, mode='auto')\n",
    "    model_reg_tanh.fit(x_train_reg_tanh,y_train_reg_tanh,validation_data=(x_test_reg_tanh,y_test_reg_tanh),callbacks=[monitor,checkpointer_tanh],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_tanh.load_weights('./best_weights_tanh.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_tanh_stopping = model_reg_tanh.predict(x_test_reg_tanh)\n",
    "print(\"Shape: {}\".format(pred_reg_tanh_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 3.0, predicted Stars: [2.6935403]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 5.0, predicted Stars: [4.7206078]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.9964209]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [4.661306]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 3.0, predicted Stars: [3.7038476]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 4.5, predicted Stars: [4.876346]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 2.5, predicted Stars: [2.7314773]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.5, predicted Stars: [4.3106217]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 2.0, predicted Stars: [2.1593182]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 1.0, predicted Stars: [1.4617368]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg_tanh[i],pred_reg_tanh_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.4778800308704376\n",
      "R2 score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_tanh_stopping = np.sqrt(mean_squared_error(y_test_reg_tanh,pred_reg_tanh_stopping))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_tanh_stopping))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg_tanh, pred_reg_tanh_stopping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting RMSE score for all regression models\n",
    "\n",
    "score_list_reg=[score_lin_classic,score_log_classic,score_reg_relu,score_reg_relu_stopping,score_reg_sig,score_reg_sig_stopping,score_reg_tanh,score_reg_tanh_stopping]\n",
    "names =['Linear Regression','Logistic Regression','Relu','Relu Stopping','Sigmoid','Sigmoid Stopping','Tanh','Tanh Stopping']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg)), score_list_reg)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting RMSE score for all regression models\n",
    "\n",
    "score_list_reg=[score_lin_classic,score_reg_sig]\n",
    "names =['Linear Regression','Sigmoid']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg)), score_list_reg)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prediction for Sigmoid\n",
    "chart_regression(pred_reg_stopping[0:100].flatten(),y_test_reg[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training and Prediction for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train test data for linear regression\n",
    "\n",
    "x_train_lr, x_test_lr, y_train_lr, y_test_lr = train_test_split(x_matrix_minmax, merge_df['encoded_stars'] , test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#implementing Nearest Neighbor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(x_train_lr, y_train_lr) \n",
    "\n",
    "y_pred_knn = knn.predict(x_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - hTF1Qo6PRFnDgg1rh9a9BQ actual stars label - 6 predicted - 8\n",
      "business id - bAPjkuNJ67j2F4C5HQQHhQ actual stars label - 6 predicted - 4\n",
      "business id - dFcs3q8ynbFEaAnbyGSLjQ actual stars label - 6 predicted - 6\n",
      "business id - jrhc4s5XMR8S8kpGdU08og actual stars label - 7 predicted - 6\n",
      "business id - e7207sqC-pSn6GIf31ikhQ actual stars label - 6 predicted - 6\n",
      "business id - CF9TxeEdP5QxihYFAl4sUg actual stars label - 6 predicted - 6\n",
      "business id - zZPCAFK85NtitSNVP_wfYg actual stars label - 5 predicted - 7\n",
      "business id - 42U4Vlzr7nmQa1Bk8J4flw actual stars label - 8 predicted - 7\n",
      "business id - TTrYd662CZFRPaiwl-sUqA actual stars label - 2 predicted - 4\n",
      "business id - -lBIxCbHxuN3YO_sUkWeUQ actual stars label - 3 predicted - 6\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test_lr.index[i]\n",
    "    print(\"business id - %s actual stars label - %d predicted - %d\" \n",
    "          %(merge_df['business_id'][idx], y_test_lr[idx], y_pred_knn[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.295\n",
      "Precision score: 0.2960480875614052\n",
      "Recall score: 0.295\n",
      "F1 score: 0.2918900582503685\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "score_knn_acc = metrics.accuracy_score(y_test_lr, y_pred_knn)\n",
    "print(\"Accuracy score: {}\".format(score_knn_acc))\n",
    "\n",
    "score_knn_precision = metrics.precision_score(y_test_lr, y_pred_knn, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_knn_precision))\n",
    "\n",
    "score_knn_recall = metrics.recall_score(y_test_lr, y_pred_knn, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_knn_recall))\n",
    "\n",
    "score_knn_f1 = metrics.f1_score(y_test_lr, y_pred_knn, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_knn_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** SVM **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "\n",
    "svm_model.fit(x_train_lr, y_train_lr)\n",
    "\n",
    "y_pred_svm = svm_model.predict(x_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - hTF1Qo6PRFnDgg1rh9a9BQ actual stars label - 6 predicted - 6\n",
      "business id - bAPjkuNJ67j2F4C5HQQHhQ actual stars label - 6 predicted - 6\n",
      "business id - dFcs3q8ynbFEaAnbyGSLjQ actual stars label - 6 predicted - 6\n",
      "business id - jrhc4s5XMR8S8kpGdU08og actual stars label - 7 predicted - 7\n",
      "business id - e7207sqC-pSn6GIf31ikhQ actual stars label - 6 predicted - 6\n",
      "business id - CF9TxeEdP5QxihYFAl4sUg actual stars label - 6 predicted - 6\n",
      "business id - zZPCAFK85NtitSNVP_wfYg actual stars label - 5 predicted - 5\n",
      "business id - 42U4Vlzr7nmQa1Bk8J4flw actual stars label - 8 predicted - 8\n",
      "business id - TTrYd662CZFRPaiwl-sUqA actual stars label - 2 predicted - 3\n",
      "business id - -lBIxCbHxuN3YO_sUkWeUQ actual stars label - 3 predicted - 3\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test_lr.index[i]\n",
    "    print(\"business id - %s actual stars label - %d predicted - %d\" \n",
    "          %(merge_df['business_id'][idx], y_test_lr[idx], y_pred_svm[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.4365\n",
      "Precision score: 0.43072237226007926\n",
      "Recall score: 0.4365\n",
      "F1 score: 0.4278230138666609\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "score_svm_acc = metrics.accuracy_score(y_test_lr, y_pred_svm)\n",
    "print(\"Accuracy score: {}\".format(score_svm_acc))\n",
    "\n",
    "score_svm_precision = metrics.precision_score(y_test_lr, y_pred_svm, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_svm_precision))\n",
    "\n",
    "score_svm_recall = metrics.recall_score(y_test_lr, y_pred_svm, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_svm_recall))\n",
    "\n",
    "score_svm_f1 = metrics.f1_score(y_test_lr, y_pred_svm, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_svm_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** MNB **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "\n",
    "mnb_model.fit(x_train_lr, y_train_lr)\n",
    "\n",
    "y_pred_mnb = mnb_model.predict(x_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - hTF1Qo6PRFnDgg1rh9a9BQ actual stars label - 6 predicted - 8\n",
      "business id - bAPjkuNJ67j2F4C5HQQHhQ actual stars label - 6 predicted - 6\n",
      "business id - dFcs3q8ynbFEaAnbyGSLjQ actual stars label - 6 predicted - 6\n",
      "business id - jrhc4s5XMR8S8kpGdU08og actual stars label - 7 predicted - 7\n",
      "business id - e7207sqC-pSn6GIf31ikhQ actual stars label - 6 predicted - 6\n",
      "business id - CF9TxeEdP5QxihYFAl4sUg actual stars label - 6 predicted - 8\n",
      "business id - zZPCAFK85NtitSNVP_wfYg actual stars label - 5 predicted - 8\n",
      "business id - 42U4Vlzr7nmQa1Bk8J4flw actual stars label - 8 predicted - 8\n",
      "business id - TTrYd662CZFRPaiwl-sUqA actual stars label - 2 predicted - 3\n",
      "business id - -lBIxCbHxuN3YO_sUkWeUQ actual stars label - 3 predicted - 0\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test_lr.index[i]\n",
    "    print(\"business id - %s actual stars label - %d predicted - %d\" \n",
    "          %(merge_df['business_id'][idx], y_test_lr[idx], y_pred_mnb[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.3325\n",
      "Precision score: 0.29977451126707483\n",
      "Recall score: 0.3325\n",
      "F1 score: 0.2831433707336793\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "score_mnb_acc = metrics.accuracy_score(y_test_lr, y_pred_mnb)\n",
    "print(\"Accuracy score: {}\".format(score_mnb_acc))\n",
    "\n",
    "score_mnb_precision = metrics.precision_score(y_test_lr, y_pred_mnb, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_mnb_precision))\n",
    "\n",
    "score_mnb_recall = metrics.recall_score(y_test_lr, y_pred_mnb, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_mnb_recall))\n",
    "\n",
    "score_mnb_f1 = metrics.f1_score(y_test_lr, y_pred_mnb, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_mnb_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tensorflow for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**  Activation ReLU, Optimizer adam with stopping and checkpoint **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Encoding stars \n",
    "\n",
    "hotcoded_stars_df = pd.get_dummies(merge_df['encoded_stars'], sparse = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_stars_encoded = hotcoded_stars_df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train test data for classification\n",
    "\n",
    "x_train_lr, x_test_lr, y_train_lr, y_test_lr = train_test_split(x_matrix_minmax, y_stars_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_classification = ModelCheckpoint(filepath=\"./best_weights_softmax.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.7959 - val_loss: 1.4505\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.45049, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.3058 - val_loss: 1.2739\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.45049 to 1.27392, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.1656 - val_loss: 1.2378\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.27392 to 1.23780, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.0929 - val_loss: 1.2401\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23780\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0442 - val_loss: 1.2510\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23780\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.9955 - val_loss: 1.2537\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23780\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.9575 - val_loss: 1.2779\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23780\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9166 - val_loss: 1.3053\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23780\n",
      "Epoch 00008: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.8140 - val_loss: 1.4588\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23780\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.3215 - val_loss: 1.2939\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23780\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.1831 - val_loss: 1.2566\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23780\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.1076 - val_loss: 1.2534\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23780\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0581 - val_loss: 1.2452\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23780\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0175 - val_loss: 1.2583\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23780\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.9788 - val_loss: 1.2727\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23780\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9459 - val_loss: 1.2947\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23780\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.9129 - val_loss: 1.3219\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23780\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.8839 - val_loss: 1.3420\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.23780\n",
      "Epoch 00010: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.8010 - val_loss: 1.4709\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23780\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.3165 - val_loss: 1.2674\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23780\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.1696 - val_loss: 1.2413\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23780\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.1010 - val_loss: 1.2354\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.23780 to 1.23536, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0510 - val_loss: 1.2420\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23536\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0123 - val_loss: 1.2524\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23536\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.9734 - val_loss: 1.2646\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23536\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9370 - val_loss: 1.2780\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23536\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.9004 - val_loss: 1.3069\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23536\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.8020 - val_loss: 1.4752\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23536\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.3313 - val_loss: 1.2995\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23536\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.1859 - val_loss: 1.2497\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23536\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.1126 - val_loss: 1.2462\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23536\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0623 - val_loss: 1.2529\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23536\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0196 - val_loss: 1.2725\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23536\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.9854 - val_loss: 1.2771\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23536\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.9522 - val_loss: 1.2949\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23536\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.9177 - val_loss: 1.3365\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23536\n",
      "Epoch 00009: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.7869 - val_loss: 1.4603\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23536\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.3198 - val_loss: 1.2813\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23536\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.1799 - val_loss: 1.2412\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23536\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.1074 - val_loss: 1.2447\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23536\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0577 - val_loss: 1.2501\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23536\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0087 - val_loss: 1.2573\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23536\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.9674 - val_loss: 1.2771\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23536\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9249 - val_loss: 1.2961\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23536\n",
      "Epoch 00008: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.7886 - val_loss: 1.4659\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23536\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.3301 - val_loss: 1.2997\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23536\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.1912 - val_loss: 1.2613\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23536\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.1112 - val_loss: 1.2479\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23536\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0551 - val_loss: 1.2459\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23536\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0049 - val_loss: 1.2576\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23536\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.9620 - val_loss: 1.2723\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23536\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9253 - val_loss: 1.2954\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23536\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.8879 - val_loss: 1.3220\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23536\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.8559 - val_loss: 1.3439\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.23536\n",
      "Epoch 00010: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.7550 - val_loss: 1.4295\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23536\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.3113 - val_loss: 1.2803\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23536\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.1731 - val_loss: 1.2418\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23536\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.1059 - val_loss: 1.2347\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.23536 to 1.23467, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0505 - val_loss: 1.2443\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23467\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0079 - val_loss: 1.2520\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23467\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.9722 - val_loss: 1.2719\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23467\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9370 - val_loss: 1.2835\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23467\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.9040 - val_loss: 1.3473\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23467\n",
      "Epoch 00009: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.7973 - val_loss: 1.4559\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23467\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.3046 - val_loss: 1.2801\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23467\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.1711 - val_loss: 1.2391\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23467\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.1017 - val_loss: 1.2465\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23467\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0528 - val_loss: 1.2395\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23467\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0068 - val_loss: 1.2660\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23467\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.9609 - val_loss: 1.2810\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23467\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9216 - val_loss: 1.3000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23467\n",
      "Epoch 00008: early stopping\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.7763 - val_loss: 1.4221\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23467\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.2925 - val_loss: 1.2744\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23467\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.1733 - val_loss: 1.2403\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23467\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.1130 - val_loss: 1.2308\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.23467 to 1.23076, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0659 - val_loss: 1.2448\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23076\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0265 - val_loss: 1.2616\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23076\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.9906 - val_loss: 1.2731\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23076\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9532 - val_loss: 1.2830\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23076\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.9179 - val_loss: 1.3009\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23076\n",
      "Epoch 00009: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.8012 - val_loss: 1.4639\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23076\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.3294 - val_loss: 1.2816\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23076\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.1866 - val_loss: 1.2457\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23076\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.1151 - val_loss: 1.2374\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23076\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0629 - val_loss: 1.2513\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23076\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0172 - val_loss: 1.2533\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23076\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.9779 - val_loss: 1.2734\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23076\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9399 - val_loss: 1.2956\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23076\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.8989 - val_loss: 1.3148\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23076\n",
      "Epoch 00009: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow classification\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_classification = Sequential()\n",
    "    model_classification.add(Dense(50, input_dim=x_train_lr.shape[1], activation='relu')) # Hidden 1\n",
    "    model_classification.add(Dense(25, activation='relu')) # Hidden 2\n",
    "    model_classification.add(Dense(y_train_lr.shape[1], activation='softmax')) # Output\n",
    "    model_classification.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')\n",
    "    model_classification.fit(x_train_lr,y_train_lr,validation_data=(x_test_lr,y_test_lr),callbacks=[monitor,checkpointer_classification],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_classification.load_weights('./best_weights_softmax.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 9)\n",
      "[[1.57125442e-06 3.69864756e-05 3.72855255e-04 ... 4.69381094e-01\n",
      "  8.04057717e-02 8.68645962e-03]\n",
      " [6.61713706e-09 1.00357943e-06 2.85136102e-05 ... 5.67960978e-01\n",
      "  6.79508969e-02 2.83170491e-03]\n",
      " [6.42697913e-08 2.51377787e-06 2.37257864e-05 ... 4.19736505e-01\n",
      "  3.43536168e-01 1.01730205e-01]\n",
      " ...\n",
      " [7.86424056e-03 7.96710700e-02 3.31100374e-01 ... 2.20426053e-04\n",
      "  2.06276991e-06 2.48024108e-08]\n",
      " [1.39642442e-02 4.28913832e-02 1.21607192e-01 ... 3.21689360e-02\n",
      "  5.17557329e-03 6.98405609e-04]\n",
      " [4.68939447e-08 4.24472864e-06 1.00527162e-04 ... 5.09665132e-01\n",
      "  5.90828583e-02 3.58550926e-03]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = model_classification.predict(x_test_lr)\n",
    "print(\"Shape: {}\".format(pred_class.shape))\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predict_stars = np.argmax(pred_class,axis=1)\n",
    "true_stars = np.argmax(y_test_lr,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 6, predicted Stars: 6\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 6, predicted Stars: 6\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 6, predicted Stars: 6\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 7, predicted Stars: 7\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 6, predicted Stars: 6\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 6, predicted Stars: 6\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 5, predicted Stars: 5\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 8, predicted Stars: 8\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 2, predicted Stars: 3\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 3, predicted Stars: 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],true_stars[i],predict_stars[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.486\n",
      "Precision score: 0.47548869999990334\n",
      "Recall score: 0.486\n",
      "F1 score: 0.47420108580812714\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "score_tf_acc_stopping = metrics.accuracy_score(true_stars, predict_stars)\n",
    "print(\"Accuracy score: {}\".format(score_tf_acc_stopping))\n",
    "\n",
    "score_tf_precision_stopping = metrics.precision_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_tf_precision_stopping))\n",
    "\n",
    "score_tf_recall_stopping = metrics.recall_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_tf_recall_stopping))\n",
    "\n",
    "score_tf_f1_stopping = metrics.f1_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_tf_f1_stopping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** Classification with Sigmoid **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train test data for classification\n",
    "\n",
    "x_train_lr, x_test_lr, y_train_lr, y_test_lr = train_test_split(x_matrix_minmax, y_stars_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_classification_sig = ModelCheckpoint(filepath=\"./best_weights_softmax_sig.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.0628 - val_loss: 2.0041\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.00407, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.9567 - val_loss: 1.8903\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.00407 to 1.89027, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.7827 - val_loss: 1.6956\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.89027 to 1.69557, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.6031 - val_loss: 1.5357\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.69557 to 1.53569, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.4699 - val_loss: 1.4360\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.53569 to 1.43604, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.3885 - val_loss: 1.3779\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.43604 to 1.37785, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.3299 - val_loss: 1.3396\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.37785 to 1.33963, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.2842 - val_loss: 1.3086\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.33963 to 1.30862, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.2478 - val_loss: 1.2858\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.30862 to 1.28579, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.2183 - val_loss: 1.2713\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.28579 to 1.27135, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.1934 - val_loss: 1.2598\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.27135 to 1.25976, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.1730 - val_loss: 1.2610\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.25976\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.1541 - val_loss: 1.2488\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.25976 to 1.24879, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.1371 - val_loss: 1.2454\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.24879 to 1.24535, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.1239 - val_loss: 1.2450\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.24535 to 1.24498, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.1110 - val_loss: 1.2449\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.24498 to 1.24491, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.0972 - val_loss: 1.2447\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.24491 to 1.24468, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.0861 - val_loss: 1.2436\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.24468 to 1.24356, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.0753 - val_loss: 1.2431\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.24356 to 1.24305, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.0657 - val_loss: 1.2436\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24305\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.0543 - val_loss: 1.2488\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24305\n",
      "Epoch 22/100\n",
      " - 2s - loss: 1.0460 - val_loss: 1.2510\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.24305\n",
      "Epoch 23/100\n",
      " - 2s - loss: 1.0380 - val_loss: 1.2531\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.24305\n",
      "Epoch 00023: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.0478 - val_loss: 2.0012\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24305\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.9543 - val_loss: 1.8936\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24305\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.7933 - val_loss: 1.7049\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24305\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.6061 - val_loss: 1.5384\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24305\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.4770 - val_loss: 1.4468\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24305\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.3971 - val_loss: 1.3887\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24305\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.3399 - val_loss: 1.3524\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24305\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.2955 - val_loss: 1.3251\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24305\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.2611 - val_loss: 1.3007\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24305\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.2294 - val_loss: 1.2865\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24305\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.2042 - val_loss: 1.2707\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24305\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.1830 - val_loss: 1.2624\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24305\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.1640 - val_loss: 1.2544\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24305\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.1464 - val_loss: 1.2538\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24305\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.1326 - val_loss: 1.2506\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24305\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.1182 - val_loss: 1.2466\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24305\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.1061 - val_loss: 1.2477\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24305\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.0953 - val_loss: 1.2491\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24305\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.0841 - val_loss: 1.2487\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24305\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.0725 - val_loss: 1.2500\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24305\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.0632 - val_loss: 1.2532\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24305\n",
      "Epoch 00021: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.0468 - val_loss: 1.9990\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24305\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.9520 - val_loss: 1.8939\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24305\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.7954 - val_loss: 1.6990\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24305\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.6149 - val_loss: 1.5472\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24305\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.4890 - val_loss: 1.4544\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24305\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.4090 - val_loss: 1.4038\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24305\n",
      "Epoch 7/100\n",
      " - 3s - loss: 1.3485 - val_loss: 1.3569\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24305\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.3012 - val_loss: 1.3277\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24305\n",
      "Epoch 9/100\n",
      " - 3s - loss: 1.2639 - val_loss: 1.3024\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24305\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.2306 - val_loss: 1.2825\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24305\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.2048 - val_loss: 1.2721\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24305\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.1813 - val_loss: 1.2638\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24305\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.1616 - val_loss: 1.2554\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24305\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.1445 - val_loss: 1.2477\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24305\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.1280 - val_loss: 1.2546\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24305\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.1126 - val_loss: 1.2478\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24305\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.0991 - val_loss: 1.2451\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24305\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.0863 - val_loss: 1.2452\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24305\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.0743 - val_loss: 1.2459\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24305\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.0642 - val_loss: 1.2472\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24305\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.0525 - val_loss: 1.2526\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24305\n",
      "Epoch 22/100\n",
      " - 2s - loss: 1.0429 - val_loss: 1.2549\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.24305\n",
      "Epoch 00022: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 2.0263 - val_loss: 1.9978\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24305\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 1.9369 - val_loss: 1.8580\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24305\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.7418 - val_loss: 1.6421\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24305\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.5628 - val_loss: 1.5059\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24305\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.4585 - val_loss: 1.4328\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24305\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.3910 - val_loss: 1.3863\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24305\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.3402 - val_loss: 1.3514\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24305\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.3007 - val_loss: 1.3232\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24305\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.2656 - val_loss: 1.3055\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24305\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.2377 - val_loss: 1.2864\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24305\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.2122 - val_loss: 1.2790\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24305\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.1914 - val_loss: 1.2765\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24305\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.1738 - val_loss: 1.2693\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24305\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.1567 - val_loss: 1.2663\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24305\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.1413 - val_loss: 1.2586\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24305\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.1273 - val_loss: 1.2522\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24305\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.1144 - val_loss: 1.2601\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24305\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.1011 - val_loss: 1.2500\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24305\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.0899 - val_loss: 1.2527\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24305\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.0784 - val_loss: 1.2572\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24305\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.0666 - val_loss: 1.2605\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24305\n",
      "Epoch 22/100\n",
      " - 2s - loss: 1.0578 - val_loss: 1.2564\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.24305\n",
      "Epoch 23/100\n",
      " - 2s - loss: 1.0467 - val_loss: 1.2566\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.24305\n",
      "Epoch 00023: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.0405 - val_loss: 1.9952\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24305\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.9429 - val_loss: 1.8738\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24305\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.7691 - val_loss: 1.6695\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24305\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.5809 - val_loss: 1.5233\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24305\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.4652 - val_loss: 1.4422\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24305\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.3924 - val_loss: 1.3909\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24305\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.3382 - val_loss: 1.3504\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24305\n",
      "Epoch 8/100\n",
      " - 3s - loss: 1.2973 - val_loss: 1.3234\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24305\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.2609 - val_loss: 1.3039\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24305\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.2317 - val_loss: 1.2876\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24305\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.2079 - val_loss: 1.2767\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24305\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.1867 - val_loss: 1.2668\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24305\n",
      "Epoch 13/100\n",
      " - 3s - loss: 1.1681 - val_loss: 1.2615\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24305\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.1496 - val_loss: 1.2580\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24305\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.1347 - val_loss: 1.2589\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24305\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.1210 - val_loss: 1.2497\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24305\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.1077 - val_loss: 1.2503\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24305\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.0961 - val_loss: 1.2484\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24305\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.0839 - val_loss: 1.2558\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24305\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.0744 - val_loss: 1.2567\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24305\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.0644 - val_loss: 1.2533\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24305\n",
      "Epoch 22/100\n",
      " - 2s - loss: 1.0539 - val_loss: 1.2618\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.24305\n",
      "Epoch 23/100\n",
      " - 2s - loss: 1.0445 - val_loss: 1.2619\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.24305\n",
      "Epoch 00023: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.0359 - val_loss: 1.9833\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24305\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.9129 - val_loss: 1.8254\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24305\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.7234 - val_loss: 1.6373\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24305\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.5619 - val_loss: 1.5089\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24305\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.4530 - val_loss: 1.4264\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24305\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.3776 - val_loss: 1.3733\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24305\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.3203 - val_loss: 1.3320\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24305\n",
      "Epoch 8/100\n",
      " - 3s - loss: 1.2776 - val_loss: 1.3114\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24305\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.2422 - val_loss: 1.2862\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24305\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.2124 - val_loss: 1.2723\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24305\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.1896 - val_loss: 1.2616\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24305\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.1690 - val_loss: 1.2525\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24305\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.1516 - val_loss: 1.2524\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24305\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.1356 - val_loss: 1.2433\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24305\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.1214 - val_loss: 1.2547\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24305\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.1081 - val_loss: 1.2456\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24305\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.0976 - val_loss: 1.2435\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24305\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.0873 - val_loss: 1.2508\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24305\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.0769 - val_loss: 1.2507\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24305\n",
      "Epoch 00019: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 2.0832 - val_loss: 2.0074\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24305\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.9706 - val_loss: 1.9246\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24305\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.8353 - val_loss: 1.7496\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24305\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.6480 - val_loss: 1.5760\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24305\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.5029 - val_loss: 1.4672\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24305\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.4147 - val_loss: 1.4057\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24305\n",
      "Epoch 7/100\n",
      " - 3s - loss: 1.3532 - val_loss: 1.3607\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24305\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.3065 - val_loss: 1.3302\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24305\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.2687 - val_loss: 1.3067\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24305\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.2356 - val_loss: 1.2901\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24305\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.2093 - val_loss: 1.2791\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24305\n",
      "Epoch 12/100\n",
      " - 3s - loss: 1.1861 - val_loss: 1.2706\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24305\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.1655 - val_loss: 1.2582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24305\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.1469 - val_loss: 1.2524\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24305\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.1315 - val_loss: 1.2492\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24305\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.1157 - val_loss: 1.2469\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24305\n",
      "Epoch 17/100\n",
      " - 3s - loss: 1.1015 - val_loss: 1.2469\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24305\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.0894 - val_loss: 1.2471\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24305\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.0770 - val_loss: 1.2477\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24305\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.0653 - val_loss: 1.2505\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24305\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.0548 - val_loss: 1.2573\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24305\n",
      "Epoch 00021: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.0332 - val_loss: 2.0045\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24305\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.9576 - val_loss: 1.8903\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24305\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.7796 - val_loss: 1.6749\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24305\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.5847 - val_loss: 1.5176\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24305\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.4629 - val_loss: 1.4352\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24305\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.3899 - val_loss: 1.3808\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24305\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.3369 - val_loss: 1.3446\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24305\n",
      "Epoch 8/100\n",
      " - 3s - loss: 1.2939 - val_loss: 1.3163\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24305\n",
      "Epoch 9/100\n",
      " - 3s - loss: 1.2591 - val_loss: 1.2988\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24305\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.2312 - val_loss: 1.2845\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24305\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.2050 - val_loss: 1.2678\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24305\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.1836 - val_loss: 1.2621\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24305\n",
      "Epoch 13/100\n",
      " - 3s - loss: 1.1645 - val_loss: 1.2538\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24305\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.1479 - val_loss: 1.2571\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24305\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.1322 - val_loss: 1.2482\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24305\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.1186 - val_loss: 1.2518\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24305\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.1060 - val_loss: 1.2570\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24305\n",
      "Epoch 18/100\n",
      " - 3s - loss: 1.0954 - val_loss: 1.2439\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24305\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.0834 - val_loss: 1.2474\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24305\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.0739 - val_loss: 1.2476\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24305\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.0648 - val_loss: 1.2493\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24305\n",
      "Epoch 22/100\n",
      " - 2s - loss: 1.0540 - val_loss: 1.2517\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.24305\n",
      "Epoch 23/100\n",
      " - 3s - loss: 1.0439 - val_loss: 1.2548\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.24305\n",
      "Epoch 00023: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.0366 - val_loss: 1.9786\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24305\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.9072 - val_loss: 1.8251\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24305\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.7333 - val_loss: 1.6601\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24305\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.5852 - val_loss: 1.5376\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24305\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.4821 - val_loss: 1.4589\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24305\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.4116 - val_loss: 1.4077\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24305\n",
      "Epoch 7/100\n",
      " - 3s - loss: 1.3594 - val_loss: 1.3714\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24305\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.3150 - val_loss: 1.3411\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24305\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.2787 - val_loss: 1.3147\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24305\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.2460 - val_loss: 1.2965\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24305\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.2175 - val_loss: 1.2822\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24305\n",
      "Epoch 12/100\n",
      " - 3s - loss: 1.1922 - val_loss: 1.2689\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24305\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.1711 - val_loss: 1.2633\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24305\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.1530 - val_loss: 1.2601\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24305\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.1356 - val_loss: 1.2625\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24305\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.1203 - val_loss: 1.2481\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24305\n",
      "Epoch 17/100\n",
      " - 3s - loss: 1.1067 - val_loss: 1.2518\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24305\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.0934 - val_loss: 1.2477\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24305\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.0810 - val_loss: 1.2523\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24305\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.0704 - val_loss: 1.2558\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24305\n",
      "Epoch 21/100\n",
      " - 3s - loss: 1.0602 - val_loss: 1.2568\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24305\n",
      "Epoch 00021: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.0215 - val_loss: 1.9853\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24305\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.9254 - val_loss: 1.8467\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24305\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.7422 - val_loss: 1.6450\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24305\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.5684 - val_loss: 1.5141\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24305\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.4599 - val_loss: 1.4352\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24305\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.3878 - val_loss: 1.3833\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24305\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.3334 - val_loss: 1.3492\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24305\n",
      "Epoch 8/100\n",
      " - 3s - loss: 1.2888 - val_loss: 1.3141\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24305\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.2510 - val_loss: 1.2956\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24305\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.2221 - val_loss: 1.2772\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24305\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.1971 - val_loss: 1.2654\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24305\n",
      "Epoch 12/100\n",
      " - 3s - loss: 1.1750 - val_loss: 1.2589\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24305\n",
      "Epoch 13/100\n",
      " - 3s - loss: 1.1557 - val_loss: 1.2541\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24305\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.1408 - val_loss: 1.2484\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24305\n",
      "Epoch 15/100\n",
      " - 3s - loss: 1.1268 - val_loss: 1.2490\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24305\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.1131 - val_loss: 1.2463\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24305\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.1000 - val_loss: 1.2509\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24305\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.0897 - val_loss: 1.2458\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24305\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.0783 - val_loss: 1.2529\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24305\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.0695 - val_loss: 1.2486\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24305\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.0607 - val_loss: 1.2509\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24305\n",
      "Epoch 00021: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow classification\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_classification = Sequential()\n",
    "    model_classification.add(Dense(50, input_dim=x_train_lr.shape[1], activation='sigmoid')) # Hidden 1\n",
    "    model_classification.add(Dense(25, activation='sigmoid')) # Hidden 2\n",
    "    model_classification.add(Dense(y_train_lr.shape[1], activation='softmax')) # Output\n",
    "    model_classification.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')\n",
    "    model_classification.fit(x_train_lr,y_train_lr,validation_data=(x_test_lr,y_test_lr),callbacks=[monitor,checkpointer_classification_sig],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_classification.load_weights('./best_weights_softmax_sig.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 9)\n",
      "[[2.6428386e-05 6.6561646e-05 7.2737178e-04 ... 4.8010001e-01\n",
      "  8.4608644e-02 5.6764153e-03]\n",
      " [7.1267641e-06 2.3806502e-05 3.0396684e-04 ... 5.5357748e-01\n",
      "  9.2104904e-02 3.4559101e-03]\n",
      " [2.6218740e-06 6.3406983e-06 4.7278310e-05 ... 3.3798721e-01\n",
      "  4.8585954e-01 9.7511649e-02]\n",
      " ...\n",
      " [5.2497108e-02 1.1034695e-01 2.7520877e-01 ... 3.7755424e-03\n",
      "  4.2102387e-04 8.3321484e-06]\n",
      " [9.8571796e-03 1.6618140e-02 8.0279812e-02 ... 5.3628657e-02\n",
      "  9.1221323e-03 5.2331603e-04]\n",
      " [1.9931931e-05 6.4284206e-05 7.9478079e-04 ... 3.8323784e-01\n",
      "  4.5505017e-02 2.5554695e-03]]\n"
     ]
    }
   ],
   "source": [
    "pred_softmax_sig = model_classification.predict(x_test_lr)\n",
    "print(\"Shape: {}\".format(pred_softmax_sig.shape))\n",
    "print(pred_softmax_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predict_stars = np.argmax(pred_softmax_sig,axis=1)\n",
    "true_stars = np.argmax(y_test_lr,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 6, predicted Stars: 6\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 6, predicted Stars: 6\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 6, predicted Stars: 7\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 7, predicted Stars: 7\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 6, predicted Stars: 6\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 6, predicted Stars: 6\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 5, predicted Stars: 5\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 8, predicted Stars: 8\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 2, predicted Stars: 3\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 3, predicted Stars: 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],true_stars[i],predict_stars[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.4915\n",
      "Precision score: 0.47394875547054105\n",
      "Recall score: 0.4915\n",
      "F1 score: 0.48090283018481284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChandiniNagendra\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ChandiniNagendra\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "score_acc_softmax_sig = metrics.accuracy_score(true_stars, predict_stars)\n",
    "print(\"Accuracy score: {}\".format(score_acc_softmax_sig))\n",
    "\n",
    "score_precision_softmax_sig = metrics.precision_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_precision_softmax_sig))\n",
    "\n",
    "score_recall_softmax_sig = metrics.recall_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_recall_softmax_sig))\n",
    "\n",
    "score_f1_softmax_sig = metrics.f1_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_f1_softmax_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** Classification with Tanh **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_classification_tanh = ModelCheckpoint(filepath=\"./best_weights_softmax_tanh.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.7209 - val_loss: 1.4131\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.41310, saving model to ./best_weights_softmax_tanh.hdf5\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.2957 - val_loss: 1.2751\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.41310 to 1.27507, saving model to ./best_weights_softmax_tanh.hdf5\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.1763 - val_loss: 1.2436\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.27507 to 1.24358, saving model to ./best_weights_softmax_tanh.hdf5\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.1064 - val_loss: 1.2450\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24358\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0568 - val_loss: 1.2562\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24358\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.0103 - val_loss: 1.2773\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24358\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.9727 - val_loss: 1.3041\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24358\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.9391 - val_loss: 1.3219\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24358\n",
      "Epoch 00008: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.7054 - val_loss: 1.4022\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24358\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.2986 - val_loss: 1.2820\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24358\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.1809 - val_loss: 1.2482\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24358\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.1122 - val_loss: 1.2511\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24358\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0579 - val_loss: 1.2626\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24358\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.0106 - val_loss: 1.2844\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24358\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.9722 - val_loss: 1.2968\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24358\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.9323 - val_loss: 1.3274\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24358\n",
      "Epoch 00008: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.7120 - val_loss: 1.4163\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24358\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.2992 - val_loss: 1.2825\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24358\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.1799 - val_loss: 1.2517\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24358\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.1135 - val_loss: 1.2512\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24358\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0642 - val_loss: 1.2629\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24358\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.0211 - val_loss: 1.2927\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24358\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.9837 - val_loss: 1.3018\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24358\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9469 - val_loss: 1.3239\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24358\n",
      "Epoch 00008: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.7590 - val_loss: 1.4411\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24358\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.3082 - val_loss: 1.2780\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24358\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.1784 - val_loss: 1.2580\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24358\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.1086 - val_loss: 1.2526\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24358\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0575 - val_loss: 1.2550\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24358\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.0109 - val_loss: 1.2735\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24358\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.9709 - val_loss: 1.3001\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24358\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9353 - val_loss: 1.3301\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24358\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.9059 - val_loss: 1.3670\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24358\n",
      "Epoch 00009: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.7221 - val_loss: 1.4095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24358\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.2926 - val_loss: 1.2763\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24358\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.1698 - val_loss: 1.2451\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24358\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.1008 - val_loss: 1.2484\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24358\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0481 - val_loss: 1.2550\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24358\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.0042 - val_loss: 1.2679\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24358\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.9663 - val_loss: 1.3113\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24358\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.9259 - val_loss: 1.3406\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24358\n",
      "Epoch 00008: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.6803 - val_loss: 1.3693\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24358\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.2686 - val_loss: 1.2589\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24358\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.1605 - val_loss: 1.2445\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24358\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.0947 - val_loss: 1.2403\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.24358 to 1.24032, saving model to ./best_weights_softmax_tanh.hdf5\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0435 - val_loss: 1.2569\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24032\n",
      "Epoch 6/100\n",
      " - 4s - loss: 1.0010 - val_loss: 1.2736\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24032\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.9590 - val_loss: 1.3058\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24032\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.9245 - val_loss: 1.3333\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24032\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.8933 - val_loss: 1.3687\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24032\n",
      "Epoch 00009: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.7144 - val_loss: 1.3866\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24032\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.2815 - val_loss: 1.2660\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24032\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.1682 - val_loss: 1.2330\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.24032 to 1.23301, saving model to ./best_weights_softmax_tanh.hdf5\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.0999 - val_loss: 1.2394\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23301\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0483 - val_loss: 1.2575\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23301\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.0054 - val_loss: 1.2679\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23301\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.9632 - val_loss: 1.3079\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23301\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.9291 - val_loss: 1.3359\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23301\n",
      "Epoch 00008: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.7010 - val_loss: 1.3870\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23301\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.2844 - val_loss: 1.2729\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23301\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.1723 - val_loss: 1.2480\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23301\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.1098 - val_loss: 1.2454\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23301\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0599 - val_loss: 1.2597\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23301\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.0131 - val_loss: 1.2756\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23301\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.9753 - val_loss: 1.2959\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23301\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.9386 - val_loss: 1.3339\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23301\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.9047 - val_loss: 1.3631\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23301\n",
      "Epoch 00009: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.7306 - val_loss: 1.4077\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23301\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.2931 - val_loss: 1.2812\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23301\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.1729 - val_loss: 1.2533\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23301\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 1.1017 - val_loss: 1.2521\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23301\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.0468 - val_loss: 1.2629\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23301\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.9996 - val_loss: 1.2909\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23301\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.9606 - val_loss: 1.3178\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23301\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.9241 - val_loss: 1.3449\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23301\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.8924 - val_loss: 1.3882\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23301\n",
      "Epoch 00009: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.6647 - val_loss: 1.3781\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23301\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.2870 - val_loss: 1.2728\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23301\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.1801 - val_loss: 1.2467\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23301\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.1112 - val_loss: 1.2478\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23301\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0570 - val_loss: 1.2572\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23301\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.0138 - val_loss: 1.2783\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23301\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.9732 - val_loss: 1.2978\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23301\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.9365 - val_loss: 1.3340\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23301\n",
      "Epoch 00008: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow classification\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_classification = Sequential()\n",
    "    model_classification.add(Dense(50, input_dim=x_train_lr.shape[1], activation='tanh')) # Hidden 1\n",
    "    model_classification.add(Dense(25, activation='tanh')) # Hidden 2\n",
    "    model_classification.add(Dense(y_train_lr.shape[1], activation='softmax')) # Output\n",
    "    model_classification.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')\n",
    "    model_classification.fit(x_train_lr,y_train_lr,validation_data=(x_test_lr,y_test_lr),callbacks=[monitor,checkpointer_classification_tanh],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_classification.load_weights('./best_weights_softmax_tanh.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 9)\n",
      "[[2.9309979e-04 7.6368195e-04 3.1096060e-03 ... 3.5218918e-01\n",
      "  7.3664486e-02 8.2561085e-03]\n",
      " [3.5263372e-05 1.9878068e-04 7.2009966e-04 ... 4.3902308e-01\n",
      "  9.6078582e-02 4.3154527e-03]\n",
      " [4.7294710e-05 1.5183951e-04 4.9645797e-04 ... 3.8862678e-01\n",
      "  3.9821169e-01 6.5379322e-02]\n",
      " ...\n",
      " [9.0967201e-02 1.5227582e-01 2.4234036e-01 ... 1.4888047e-03\n",
      "  1.4658453e-04 4.6561631e-06]\n",
      " [4.3624546e-02 6.2864169e-02 1.3514607e-01 ... 3.3515919e-02\n",
      "  6.8771937e-03 5.9607241e-04]\n",
      " [8.0422702e-05 4.6633021e-04 1.7533089e-03 ... 3.8126311e-01\n",
      "  6.2727369e-02 3.2474271e-03]]\n"
     ]
    }
   ],
   "source": [
    "pred_class_tanh = model_classification.predict(x_test_lr)\n",
    "print(\"Shape: {}\".format(pred_class_tanh.shape))\n",
    "print(pred_class_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predict_stars_tanh = np.argmax(pred_class_tanh,axis=1)\n",
    "true_stars = np.argmax(y_test_lr,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 6, predicted Stars: 5\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 6, predicted Stars: 6\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 6, predicted Stars: 7\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 7, predicted Stars: 7\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 6, predicted Stars: 6\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 6, predicted Stars: 6\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 5, predicted Stars: 5\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 8, predicted Stars: 8\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 2, predicted Stars: 3\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 3, predicted Stars: 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],true_stars[i],predict_stars_tanh[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.494\n",
      "Precision score: 0.49170562004997825\n",
      "Recall score: 0.494\n",
      "F1 score: 0.4857120550063005\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "score_tf_acc_tanh = metrics.accuracy_score(true_stars, predict_stars_tanh)\n",
    "print(\"Accuracy score: {}\".format(score_tf_acc_tanh))\n",
    "\n",
    "score_tf_precision_tanh = metrics.precision_score(true_stars, predict_stars_tanh, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_tf_precision_tanh))\n",
    "\n",
    "score_tf_recall_tanh = metrics.recall_score(true_stars, predict_stars_tanh, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_tf_recall_tanh))\n",
    "\n",
    "score_tf_f1_tanh = metrics.f1_score(true_stars, predict_stars_tanh, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_tf_f1_tanh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEVCAYAAAAb/KWvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGORJREFUeJzt3Xu0XWV97vHvQzCgyEVkc0QIJAq1RuUiMdXTKiAgQRiJcjEBuamQYo0twlFBGFQ5x3EQKranxiIVWm8QEFsNEKD1UusNT4J6kMtAAgWJIAa5qZRL5Dl/vHPb5XaHPXeyNnOvN89njAz2nGuOnd9kZT3rne9833fKNhERUZeNui4gIiL6L+EeEVGhhHtERIUS7hERFUq4R0RUKOEeEVGhhHtERIUS7hERFUq4R0RUaOOu/uJtttnG06dP7+qvj4gYSNdff/39tofGOq6zcJ8+fTorVqzo6q+PiBhIku5qc1y6ZSIiKpRwj4ioUMI9IqJCrcJd0hxJt0paKenUUV4/TtJqST9s/hzf/1IjIqKtMW+oSpoCLAb2B1YByyUttX3ziEMvtb1oAmqMiIhxatNynw2stH2H7SeAJcC8iS0rIiLWR5tw3x64u2d7VbNvpEMl3SDpcknTRvtFkhZKWiFpxerVq9eh3IiIaKNNuGuUfSOfzXcFMN32rsBXgE+P9otsX2B7lu1ZQ0NjjsGPiIh11GYS0yqgtyW+A3BP7wG2f9Gz+ffAR9a/tIiI8Zl+6lVdl9DKnWcfNOF/R5twXw7sImkG8FNgAXBk7wGStrN9b7M5F7ilr1VGRN8lCOs2ZrjbXiNpEXAtMAW4yPZNks4CVtheCvy5pLnAGuAB4LgJrDkiIsbQam0Z28uAZSP2ndnz82nAaf0tLWJySUs3BklmqEZEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVq9YDsmHh5+HJE9FNa7hERFUq4R0RUKOEeEVGhhHtERIUS7hERFUq4R0RUKOEeEVGhhHtERIUS7hERFUq4R0RUKOEeEVGhVuEuaY6kWyWtlHTq0xx3mCRLmtW/EiMiYrzGDHdJU4DFwIHATOAISTNHOW5z4M+B7/W7yIiIGJ82LffZwErbd9h+AlgCzBvluP8JnAM81sf6IiJiHbQJ9+2Bu3u2VzX7fkvSHsA021c+3S+StFDSCkkrVq9ePe5iIyKinTbhrlH2+bcvShsBHwNOGesX2b7A9izbs4aGhtpXGRER49Im3FcB03q2dwDu6dneHHg58G+S7gReDSzNTdWIiO60CfflwC6SZkiaCiwAlg6/aPth29vYnm57OnAdMNf2igmpOCIixjRmuNteAywCrgVuAS6zfZOksyTNnegCIyJi/Fo9Q9X2MmDZiH1nruXYvde/rIiIWB+ZoRoRUaGEe0REhRLuEREVSrhHRFQo4R4RUaGEe0REhRLuEREVSrhHRFQo4R4RUaGEe0REhRLuEREVSrhHRFQo4R4RUaGEe0REhRLuEREVSrhHRFQo4R4RUaGEe0REhRLuEREVSrhHRFQo4R4RUaGEe0REhRLuEREV2rjrAqJO00+9qusSWrnz7IO6LiFiQqTlHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoVbhLmmOpFslrZR06iivnyjpR5J+KOlbkmb2v9SIiGhrzHCXNAVYDBwIzASOGCW8L7b9Ctu7A+cA5/W90oiIaK1Ny302sNL2HbafAJYA83oPsP1Iz+ZmgPtXYkREjFebhcO2B+7u2V4F/NHIgyS9CzgZmAq8frRfJGkhsBBgxx13HG+tERHRUpuWu0bZ93stc9uLbb8YeD9wxmi/yPYFtmfZnjU0NDS+SiMiorU24b4KmNazvQNwz9McvwR40/oUFRER66dNt8xyYBdJM4CfAguAI3sPkLSL7duazYOA25hAWSs8IuLpjRnuttdIWgRcC0wBLrJ9k6SzgBW2lwKLJO0HPAk8CBw7kUVHRMTTa/UkJtvLgGUj9p3Z8/Nf9LmuiIhYD5mhGhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoYR7RESFEu4RERVKuEdEVCjhHhFRoVbhLmmOpFslrZR06iivnyzpZkk3SPqqpJ36X2pERLQ1ZrhLmgIsBg4EZgJHSJo54rAfALNs7wpcDpzT70IjIqK9Ni332cBK23fYfgJYAszrPcD2120/2mxeB+zQ3zIjImI82oT79sDdPdurmn1r8w7g6tFekLRQ0gpJK1avXt2+yoiIGJc24a5R9nnUA6WjgFnAuaO9bvsC27NszxoaGmpfZUREjMvGLY5ZBUzr2d4BuGfkQZL2A04H9rL9eH/Ki4iIddGm5b4c2EXSDElTgQXA0t4DJO0BfBKYa/vn/S8zIiLGY8xwt70GWARcC9wCXGb7JklnSZrbHHYu8FzgC5J+KGnpWn5dREQ8A9p0y2B7GbBsxL4ze37er891RUTEesgM1YiICiXcIyIqlHCPiKhQwj0iokIJ94iICiXcIyIqlHCPiKhQwj0iokIJ94iICiXcIyIqlHCPiKhQwj0iokIJ94iICiXcIyIqlHCPiKhQwj0iokIJ94iICiXcIyIqlHCPiKhQwj0iokIJ94iICiXcIyIqlHCPiKhQwj0iokIJ94iICiXcIyIqlHCPiKhQwj0iokIJ94iICiXcIyIqlHCPiKhQwj0iokIJ94iICrUKd0lzJN0qaaWkU0d5/XWSvi9pjaTD+l9mRESMx5jhLmkKsBg4EJgJHCFp5ojDfgIcB1zc7wIjImL8Nm5xzGxgpe07ACQtAeYBNw8fYPvO5rWnJqDGiIgYpzbdMtsDd/dsr2r2jZukhZJWSFqxevXqdfkVERHRQptw1yj7vC5/me0LbM+yPWtoaGhdfkVERLTQJtxXAdN6tncA7pmYciIioh/ahPtyYBdJMyRNBRYASye2rIiIWB9jhrvtNcAi4FrgFuAy2zdJOkvSXABJr5K0Cjgc+KSkmyay6IiIeHptRstgexmwbMS+M3t+Xk7promIiEkgM1QjIiqUcI+IqFDCPSKiQgn3iIgKJdwjIiqUcI+IqFDCPSKiQgn3iIgKJdwjIiqUcI+IqFDCPSKiQgn3iIgKJdwjIiqUcI+IqFDCPSKiQgn3iIgKJdwjIiqUcI+IqFDCPSKiQgn3iIgKJdwjIiqUcI+IqFDCPSKiQgn3iIgKJdwjIiqUcI+IqFDCPSKiQgn3iIgKJdwjIiqUcI+IqFDCPSKiQgn3iIgKJdwjIirUKtwlzZF0q6SVkk4d5fVNJF3avP49SdP7XWhERLQ3ZrhLmgIsBg4EZgJHSJo54rB3AA/a3hn4GPCRfhcaERHttWm5zwZW2r7D9hPAEmDeiGPmAZ9ufr4c2FeS+ldmRESMh2w//QHSYcAc28c320cDf2R7Uc8xNzbHrGq2b2+OuX/E71oILGw2XwLc2q8T6YNtgPvHPGqw1HZOtZ0P1HdOtZ0PTL5z2sn20FgHbdziF43WAh/5jdDmGGxfAFzQ4u98xklaYXtW13X0U23nVNv5QH3nVNv5wOCeU5tumVXAtJ7tHYB71naMpI2BLYEH+lFgRESMX5twXw7sImmGpKnAAmDpiGOWAsc2Px8GfM1j9fdERMSEGbNbxvYaSYuAa4EpwEW2b5J0FrDC9lLgQuCzklZSWuwLJrLoCTIpu4vWU23nVNv5QH3nVNv5wICe05g3VCMiYvBkhmpERIUS7hERFUq4b0Ak5f2O2EDkwz4KSS/ouoZ+kvRSANtP1Rbwtc2ElrRz1zVMNEnP7rqGdTFon52BKvaZIGkH4HRJx3VdSz9I2hP4kaQLoY6AlzRb0jxJs2y7hoBXsQnwLUnVrs0k6fnA+yXN6bqW8ZC0se2nmp9f1Ls44mT99zfQH/IJ8ivgx8Bukt7adTF9cB/wI2BvSZ+HwQ54SQcAFwOvAf5N0itrmFPh4nHg1cCCZqhxjZ5NGYL9Okmv77qYNiS9Anhj8/NfAF8Clkj6IJT3bjIGfJvlBzYIkqYBj9leLekfgPnAayTJ9uc6Lm+d2V4l6aPAc4A9Jf2z7TcPB/xwa2QQSDoQOAt4m+1vSvpPYHtJv7L9447LW2eSNrf9SwDbd0p6LfBdSdg+s+Py+qb597ZK0veAI4F3SHrM9ne6rm0Me1G+jLYFXgvsA2xBucrayPaZwwE/mRoaA9l66zdJs4C7gGslLQD2tn0hcBNldu4xnRY4TpL2lXSGpKlNC/12ysSyc4CfS/oiDFYLvmkZLQJ+2QT7dsBJlBnR35D0rk4LXEfN/ZDTm+4zAGz/hHJlcpyk93ZWXB81wfdUc+X1IeA7wHbAIZO1BT/cGrf9ceBrwEHAU8Djtv+D8h4dI+m85rhJE+yQcAfA9gpgGbA7pYX7HkmfAF4JTAVeL+nQDktsrVnb528oLdy/BE4DbqMsxXxYs/2opGuhBHxHpbYmaafmg3M4MFXSxcClwOm2j6VcZZ0h6XVd1rmOHgSGgDdL2mN4ZxPwc4A3SnpJV8WtL0k7SnpO07J9FqV742O2/xY4HngUOLq5Wpk0RrbCbZ9PWe58M2AvSc9r3qO9gTmShiZb18wGHe6S9pL01wC2DwauBt5ke1/gH4B7KZdhxwDvlrRZZ8W20ITbAuAA4AbgBZRgXwr8IbCX7QcoLeC7mpvHk1Zzk3Fz4ApJp9l+FHgD5ZL4WbY/AWD73ylfXtt0V217wyHQ3KT7GfABYCvgLb0BT3nv7gQee8aL7J/jgZc0YfkksJryhbWV7TuAS4A/AeZJmhTvX2+wSzpB0lmS5gKXUeo9EvgTSVvbvhPY1fbqtNwnl1spl77nAtg+CHiepKttL2/6O98CvAo4wfavO6y1jU2Bt9j+KfA2Sl/hGsqTsm4F7pe0s+2HgT8dXn9/smpuMv6SEhCHSDqlCfjDAUs6H6DpStsf+GF31Y7LC5v//qYJ+PuA/wVsDhwqae/m9TnAHwBPPPMl9kfzGbof+JqkLSgBeS8wv2nJPwrcCHxq5PMfutIT7PsDf0pZU+tgypXwJcCVwAnA7KZb8zcdlfq0Nvi1ZSS9ELgO+CfbJzX7vg6ssb1/p8WNk6QZwCeAv7Z9raTXAJ8DPmz7oiZI1nRbZTuSXkkJhYdtPyxpV+AfgUtsnyvpOcA1lG60NcDbbd/cWcEtNC32LShLZL+3udQfbsGvUZlf8U7KVdYmwI7AMbZv7KrmfpF0OWWkzFspV8MHA7tRujk+YPuKDsv7PSpDoY+lNOpWNlfFhwK/AD4MHAJ82/bI5c8nD9sb1B/Kne7llG/eVzf7tqa0bM/rOe4HwJe6rrfF+TxnxPafASuA7ZrtVwG3AKd0Xes4zmk74GHKMM6vUz5ULwNmNO/LwuFzp7SkXtZ1zeM8v9dSuife3rNvas/PO1Hu97yw61rX8fyGG40vA/YFtm62z6fc29qi2d4d2LnrentrHvEePUW5rwOl9f5aygq4p3Vdb5s/G9RQyOYycGfKA0eOAbZrWhT3AW8CrpN0r+1zbe8haacOyx2TpNnAsZK+bfviZvffAS8H9gDutb1c0tuAxZIutP1QV/W2IWlL2/dKeg+lW2kb4EXAeyn3RH5MuXm6te2zgSO6q7a94X5cSVNcRvu8Gbiy2X8h8GRz3DxgI9v/3GnB66E5z3nAByldMA9L+r+2T2y60q6RdIDtSdGNNqKP/QXAE817tBflfs+9Lle+36F0wdzeZb2tdf3t8gx+M+8D/BXlsngR8H7gfZSW7Rcpo0tWUr6tz+i63hbn8wbg25RhZSuBjwFvbV47Bbh8xPGbdF1zi3M6ALgeeF2zfXRzXvMpo5beTOn3XA08RAl+dVlzy/NSz88zaVrkwJ7Neby92T6BEoZ/0HXN63m+z6XcxH9Fs71v8z4e3GwvoTxjeTLUulPPz/8D+DLwTWBus++/N+/Ju7quddzn1nUBz8CbN3yJeChwTvPzVk0AfhTYr9m3GaUf8OPAzK7rHuOcDqbcPBz+sPy35nyWAP9KGX1wG3DYyP8Pk/kP8G7KyJB/BQ5o9h1N6Ws/vOe4FwFDXde7Duc3fPXxBcp9kOHwWE2Z9XgzsFvXdfbhPLcCvgfMabY3BU4H/k/XtY2o88Dmc7Il5V7HV5r911CuEI9ptveitNa3HITP0fCfDWG0zHDX0/Mofeu4dE38PeXG1lxJ82z/2vaVwEmexDfmmsvGUyj9zlc2Y4jvowwFPIbyD/No4MXAGyRNgck3wWItLqF0K10NnCjpYNufBb4K7CfpRADbd9he3WGdYxo55lnSPsD+tg+kXB3OkPQsl9mZcyl97Efa/n/PfLXrp2do5wxJz28+X+dTRji9yvZjlPtAW0vaTJNg4lwzmeqjwNEuo8eeBE6QdDKlgfFB4COS3mn7G5T7Og8PyOcIqHz5gWbc7ApJu1H61Tcffs32I5L+ETgKOEhlqveXmaTDmno8TvmH+J+SNgXe10wA2YQypOwkyhDXZcCPbU/q82lGwWD7BsojGp+gdF38HWVuwVO2P6uyqNauTZ/8w91V3NpUyns1bBPg6yozTregzKd4UmXxs+9K2sVlbZmBY9uS3gicDfxa0scpXYWbARdKupJyb+TPPAmGE0t6A/AZSvfLQwC2P6Uy63k/ypfsQ5KOAvaR9Dk3y0MMkuqHQjaTDz4M/G9gGvB5yuJgU2z/QmWJ1QOBS23/vLtK22laSSdT+txfBnwF+BZlcbBFwGWeZMPK1kZlhcDVlCuokylLQPyAMsN2KeVq60jgQttflrSF7Ue6qretJjzeSek6u9H2FyX9IbAYeBawbxPs76bcZ5gPPDpIrUL4nZvEm1KG4J5H+Yy9hRKcX6NMpJsO3GX7u13VOkzSvpSGw4co3ZnbAlfZ/mbz+ucpXTC3U2bTvs/2XR2Vu16qbrkD2F4q6TFKd8XjwK6UluHGku4Hfkbp4hiIb+bmw/RJytoc04AvD7f4JC2k9HcOhObLdT/KF9SuwEuB9wA/pfSpf05l7e8jJX1lQIJ9DiU4PkMJjjmSvg/cTbkBvjllydsHKJOz3joZWrProvm3eBBldNa2wErbNzbdLodTrlA+a/u6Lusc4RHgONvfUVnW4SjKjFnb/hbl/s4hlMbTOwY12GEDaLkPa7ourqLcjHuQMvPvAco48f/osrZ+kHQ4ZQTQfNuDMVSr0bSmLqL0Ox9Gaa2vosyy3YTy73QQgn1rysSrebavUFne4cPA+U3Xy2b816qCBj4zme/vjEXS7sCnKPdKDgfusX1I89pcSlfM+13WYJlU1KyIKmkXyj2qqcAXbF/fvD4o3X9rtcGEO0DTL3gO5bL4vq7r6Yemn3A+ZRjdfA/obMbmvfkI8Brbv5I0YxC/dJuW7DmU83hE0jLKZKsbKBPlLrV9f+/Y6kGkssb5KcANts9TWVrgfEp35/zmmKHJfuMboAn4IylDay9pWvUD/f7ABtAt08v2smYi0zWS9vQArIjYwkOU4VzzbK/suph11bw3AMsl/fFwsA/ah8z2VZKeAq6XdA2lRbiYMlLreMqa+icNwpXI2jR97I9RugD3kPRi27c3o5k+I+lLtt9Emao/6dm+TdKllHkUtzX7Bubf3NpsUC33YZKea/tXXdcRv6+Z2fiXwCyatcM6LmmdNPcS/oWyDMR9zb6NKFPxJ8UCWePRc/P0JZTJPh+kdJl9iHIT/J9cHjSyBfAiT5LZp+PRDE19sus6+mWDDPeY3Gr58lV5ctRfAa8f5G7AnmA/gDKX4pXANygj0DYFTqW0eC8ZxK60WnU+mSBipBqCHcD21ZS12q+eDBN3xmu45ibYX0rpXjqbsmzHPZQHv/ySMhno5cCkeljFhi4t94gJNohXIirPFH4jcFEzJv+PKUvzHtS8vjvlBvhPgDOAB20P7LrzNRq41kTEoBnAYN8W2J6yNPZWkrakTMjaVNIJAE2f+nWUGd3zgYF5Hu+GIm9GRPxWM5P23ykzS+8CPk25afpsSrfMnpI+qvK0qDmUZwW8GvhNJaPPqpFwjwgAJE2nLEB3ru0v2f4F5QbqdMpTiW4CPkl5mMrbgRMpSzRvTc+6TTE5bFDj3CPiae0DfNX2hU0Xyx6Up0J9kzJz+HHKrNojVVYb3Rc4l7I07sCO269Vwj0iht0BHN8MeZxP6YrZDbiC8iDro4AdJJ3h8szXbSnPDLits4pjrTJaJiIAUHno+ELgOMqSvX9DWUZ6OrCAso7M5ra/31GJMQ4J94j4HSrPp32gZ3tvyvj2g5p++BgA6ZaJiN8xHOzNOkz7U2aifiDBPlgyWiYifk8T7LMpD1E5w/ZVHZcU45RumYgYVRPwz7f9s0FbnTMS7hERVUq3TEREhRLuEREVSrhHRFQo4R4RUaGEe0REhRLuEREV+v9qu88ZVf/UvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracy score for all classification models\n",
    "\n",
    "score_list_reg=[score_knn_acc,score_svm_acc,score_mnb_acc,score_tf_acc_stopping,score_acc_softmax_sig,score_tf_acc_tanh]\n",
    "names =['KNN','SVM','MNB','ReLU','Sigmoid','Tanh']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg)), score_list_reg)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "score_list_reg=[score_svm_acc,score_tf_acc_stopping]\n",
    "names =['SVM','ReLU']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg)), score_list_reg)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_matrix_minmax, y_stars_regression , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#USe linear regression for regularization\n",
    "model_regularization = Sequential()\n",
    "model_regularization.add(Dense(50, input_dim=x_train_reg.shape[1], activation='relu'))\n",
    "model_regularization.add(Dense(25, activation='relu'))\n",
    "model_regularization.add(Dense(10, \n",
    "                kernel_regularizer=regularizers.l1(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model_regularization.add(Dense(1)) \n",
    "model_regularization.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 5.6602 - val_loss: 2.8496\n",
      "Epoch 2/100\n",
      " - 3s - loss: 2.3152 - val_loss: 1.9242\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.6785 - val_loss: 1.5149\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.3359 - val_loss: 1.2629\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.1036 - val_loss: 1.0700\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.9203 - val_loss: 0.9381\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.7725 - val_loss: 0.8318\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.6581 - val_loss: 0.7528\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.5648 - val_loss: 0.6943\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.4888 - val_loss: 0.6444\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.4258 - val_loss: 0.6077\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.3740 - val_loss: 0.5708\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.3299 - val_loss: 0.5450\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.2927 - val_loss: 0.5198\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.2596 - val_loss: 0.4926\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.2337 - val_loss: 0.4739\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.2118 - val_loss: 0.4574\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.1932 - val_loss: 0.4441\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.1775 - val_loss: 0.4409\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.1642 - val_loss: 0.4313\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.1542 - val_loss: 0.4172\n",
      "Epoch 22/100\n",
      " - 3s - loss: 0.1454 - val_loss: 0.4152\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.1391 - val_loss: 0.4056\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.1332 - val_loss: 0.4011\n",
      "Epoch 25/100\n",
      " - 3s - loss: 0.1272 - val_loss: 0.3936\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.1221 - val_loss: 0.3861\n",
      "Epoch 27/100\n",
      " - 3s - loss: 0.1176 - val_loss: 0.3835\n",
      "Epoch 28/100\n",
      " - 3s - loss: 0.1137 - val_loss: 0.3813\n",
      "Epoch 29/100\n",
      " - 3s - loss: 0.1096 - val_loss: 0.3838\n",
      "Epoch 30/100\n",
      " - 3s - loss: 0.1052 - val_loss: 0.3738\n",
      "Epoch 31/100\n",
      " - 3s - loss: 0.1007 - val_loss: 0.3715\n",
      "Epoch 32/100\n",
      " - 3s - loss: 0.0966 - val_loss: 0.3666\n",
      "Epoch 33/100\n",
      " - 3s - loss: 0.0926 - val_loss: 0.3688\n",
      "Epoch 34/100\n",
      " - 3s - loss: 0.0894 - val_loss: 0.3645\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.0858 - val_loss: 0.3613\n",
      "Epoch 36/100\n",
      " - 3s - loss: 0.0826 - val_loss: 0.3589\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.0799 - val_loss: 0.3593\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.0767 - val_loss: 0.3551\n",
      "Epoch 39/100\n",
      " - 3s - loss: 0.0730 - val_loss: 0.3550\n",
      "Epoch 40/100\n",
      " - 3s - loss: 0.0700 - val_loss: 0.3507\n",
      "Epoch 41/100\n",
      " - 3s - loss: 0.0671 - val_loss: 0.3523\n",
      "Epoch 42/100\n",
      " - 3s - loss: 0.0651 - val_loss: 0.3527\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.0625 - val_loss: 0.3528\n",
      "Epoch 44/100\n",
      " - 3s - loss: 0.0610 - val_loss: 0.3530\n",
      "Epoch 45/100\n",
      " - 3s - loss: 0.0587 - val_loss: 0.3513\n",
      "Epoch 00045: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2624ecc82b0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model_regularization.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor],verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_regularization = model_regularization.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.557976484298706\n",
      "R2 score: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_regularization = np.sqrt(metrics.mean_squared_error(pred_regularization,y_test_reg))\n",
    "print(\"Final score (RMSE): {}\".format(score_regularization))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_regularization))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** DROPOUT **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00021: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2628c4062b0>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropout\n",
    "\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Dense(50, input_dim=x_train_reg.shape[1]))\n",
    "model_dropout.add(Dropout(0.1))\n",
    "\n",
    "model_dropout.add(Dense(25, activation='relu'))\n",
    "model_dropout.add(Dense(10, activation='relu'))\n",
    "model_dropout.add(Dense(1))\n",
    "\n",
    "model_dropout.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model_dropout.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor],verbose=0,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_dropout = model_dropout.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5267772078514099\n",
      "R2 score: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_dropout = np.sqrt(metrics.mean_squared_error(pred_dropout,y_test_reg))\n",
    "print(\"Final score (RMSE): {}\".format(score_dropout))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_594 (Dense)            (None, 50)                50100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_595 (Dense)            (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_596 (Dense)            (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_597 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 51,646\n",
      "Trainable params: 51,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** Regularization and dropout with Postal and categories **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# one-hot cooding of postal codes \n",
    "\n",
    "postal_hotcoded_df = pd.get_dummies(merge_df['postal code'], sparse = 'true')\n",
    "\n",
    "x_matrix_postal = np.column_stack((x_matrix_minmax, postal_hotcoded_df))\n",
    "x_matrix_final = np.column_stack((x_matrix_postal, category_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Checking to see if regularization helps with over fitting when using postal code and categories and one hot coded values\n",
    "#train test data\n",
    "x_train_reg_ad, x_test_reg_ad, y_train_reg_ad, y_test_reg_ad = train_test_split(x_matrix_final, y_stars_regression , test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#USe linear regression for regularization\n",
    "model_regularization_ad = Sequential()\n",
    "model_regularization_ad.add(Dense(50, input_dim=x_train_reg_ad.shape[1], activation='relu'))\n",
    "model_regularization_ad.add(Dense(25, activation='relu'))\n",
    "model_regularization_ad.add(Dense(10, \n",
    "                kernel_regularizer=regularizers.l1(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model_regularization_ad.add(Dense(1)) \n",
    "model_regularization_ad.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 5.1199 - val_loss: 2.9405\n",
      "Epoch 2/100\n",
      " - 5s - loss: 2.1971 - val_loss: 1.7155\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.3299 - val_loss: 1.3006\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.0018 - val_loss: 1.1061\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.8066 - val_loss: 0.9616\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.6680 - val_loss: 0.8667\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.5589 - val_loss: 0.7894\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.4736 - val_loss: 0.7381\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.4071 - val_loss: 0.6979\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.3541 - val_loss: 0.6550\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.3104 - val_loss: 0.6217\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.2726 - val_loss: 0.5894\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.2408 - val_loss: 0.5679\n",
      "Epoch 14/100\n",
      " - 4s - loss: 0.2137 - val_loss: 0.5478\n",
      "Epoch 15/100\n",
      " - 5s - loss: 0.1912 - val_loss: 0.5220\n",
      "Epoch 16/100\n",
      " - 5s - loss: 0.1721 - val_loss: 0.5016\n",
      "Epoch 17/100\n",
      " - 6s - loss: 0.1562 - val_loss: 0.4889\n",
      "Epoch 18/100\n",
      " - 6s - loss: 0.1412 - val_loss: 0.4758\n",
      "Epoch 19/100\n",
      " - 6s - loss: 0.1293 - val_loss: 0.4630\n",
      "Epoch 20/100\n",
      " - 6s - loss: 0.1207 - val_loss: 0.4559\n",
      "Epoch 21/100\n",
      " - 6s - loss: 0.1131 - val_loss: 0.4456\n",
      "Epoch 22/100\n",
      " - 5s - loss: 0.1073 - val_loss: 0.4421\n",
      "Epoch 23/100\n",
      " - 5s - loss: 0.1027 - val_loss: 0.4377\n",
      "Epoch 24/100\n",
      " - 5s - loss: 0.0977 - val_loss: 0.4243\n",
      "Epoch 25/100\n",
      " - 4s - loss: 0.0941 - val_loss: 0.4230\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.0904 - val_loss: 0.4177\n",
      "Epoch 27/100\n",
      " - 5s - loss: 0.0870 - val_loss: 0.4169\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.0838 - val_loss: 0.4114\n",
      "Epoch 29/100\n",
      " - 5s - loss: 0.0802 - val_loss: 0.4123\n",
      "Epoch 30/100\n",
      " - 4s - loss: 0.0778 - val_loss: 0.4074\n",
      "Epoch 31/100\n",
      " - 5s - loss: 0.0751 - val_loss: 0.4018\n",
      "Epoch 32/100\n",
      " - 5s - loss: 0.0721 - val_loss: 0.4093\n",
      "Epoch 33/100\n",
      " - 6s - loss: 0.0701 - val_loss: 0.4038\n",
      "Epoch 34/100\n",
      " - 5s - loss: 0.0670 - val_loss: 0.3955\n",
      "Epoch 35/100\n",
      " - 4s - loss: 0.0648 - val_loss: 0.4030\n",
      "Epoch 36/100\n",
      " - 5s - loss: 0.0643 - val_loss: 0.3963\n",
      "Epoch 37/100\n",
      " - 4s - loss: 0.0613 - val_loss: 0.3902\n",
      "Epoch 38/100\n",
      " - 6s - loss: 0.0582 - val_loss: 0.3908\n",
      "Epoch 39/100\n",
      " - 4s - loss: 0.0553 - val_loss: 0.3898\n",
      "Epoch 40/100\n",
      " - 5s - loss: 0.0534 - val_loss: 0.3887\n",
      "Epoch 41/100\n",
      " - 6s - loss: 0.0521 - val_loss: 0.3916\n",
      "Epoch 42/100\n",
      " - 5s - loss: 0.0516 - val_loss: 0.3836\n",
      "Epoch 43/100\n",
      " - 5s - loss: 0.0493 - val_loss: 0.3859\n",
      "Epoch 44/100\n",
      " - 5s - loss: 0.0480 - val_loss: 0.3837\n",
      "Epoch 45/100\n",
      " - 5s - loss: 0.0469 - val_loss: 0.3875\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.0449 - val_loss: 0.3899\n",
      "Epoch 47/100\n",
      " - 5s - loss: 0.0433 - val_loss: 0.3802\n",
      "Epoch 48/100\n",
      " - 6s - loss: 0.0419 - val_loss: 0.3803\n",
      "Epoch 49/100\n",
      " - 5s - loss: 0.0406 - val_loss: 0.3795\n",
      "Epoch 50/100\n",
      " - 6s - loss: 0.0395 - val_loss: 0.3790\n",
      "Epoch 51/100\n",
      " - 5s - loss: 0.0387 - val_loss: 0.3784\n",
      "Epoch 52/100\n",
      " - 5s - loss: 0.0381 - val_loss: 0.3835\n",
      "Epoch 53/100\n",
      " - 5s - loss: 0.0373 - val_loss: 0.3759\n",
      "Epoch 54/100\n",
      " - 4s - loss: 0.0362 - val_loss: 0.3729\n",
      "Epoch 55/100\n",
      " - 5s - loss: 0.0350 - val_loss: 0.3777\n",
      "Epoch 56/100\n",
      " - 4s - loss: 0.0335 - val_loss: 0.3761\n",
      "Epoch 57/100\n",
      " - 4s - loss: 0.0336 - val_loss: 0.3762\n",
      "Epoch 58/100\n",
      " - 5s - loss: 0.0333 - val_loss: 0.3746\n",
      "Epoch 59/100\n",
      " - 4s - loss: 0.0322 - val_loss: 0.3714\n",
      "Epoch 60/100\n",
      " - 5s - loss: 0.0310 - val_loss: 0.3751\n",
      "Epoch 61/100\n",
      " - 5s - loss: 0.0299 - val_loss: 0.3684\n",
      "Epoch 62/100\n",
      " - 4s - loss: 0.0294 - val_loss: 0.3689\n",
      "Epoch 63/100\n",
      " - 5s - loss: 0.0291 - val_loss: 0.3674\n",
      "Epoch 64/100\n",
      " - 5s - loss: 0.0289 - val_loss: 0.3705\n",
      "Epoch 65/100\n",
      " - 5s - loss: 0.0282 - val_loss: 0.3666\n",
      "Epoch 66/100\n",
      " - 5s - loss: 0.0277 - val_loss: 0.3663\n",
      "Epoch 67/100\n",
      " - 4s - loss: 0.0267 - val_loss: 0.3678\n",
      "Epoch 68/100\n",
      " - 5s - loss: 0.0272 - val_loss: 0.3693\n",
      "Epoch 69/100\n",
      " - 5s - loss: 0.0277 - val_loss: 0.3678\n",
      "Epoch 70/100\n",
      " - 6s - loss: 0.0263 - val_loss: 0.3649\n",
      "Epoch 71/100\n",
      " - 5s - loss: 0.0247 - val_loss: 0.3650\n",
      "Epoch 72/100\n",
      " - 5s - loss: 0.0241 - val_loss: 0.3636\n",
      "Epoch 73/100\n",
      " - 5s - loss: 0.0236 - val_loss: 0.3594\n",
      "Epoch 74/100\n",
      " - 4s - loss: 0.0233 - val_loss: 0.3677\n",
      "Epoch 75/100\n",
      " - 5s - loss: 0.0231 - val_loss: 0.3636\n",
      "Epoch 76/100\n",
      " - 5s - loss: 0.0229 - val_loss: 0.3640\n",
      "Epoch 77/100\n",
      " - 5s - loss: 0.0229 - val_loss: 0.3628\n",
      "Epoch 78/100\n",
      " - 5s - loss: 0.0229 - val_loss: 0.3674\n",
      "Epoch 00078: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2621d2084a8>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model_regularization_ad.fit(x_train_reg_ad,y_train_reg_ad,validation_data=(x_test_reg_ad,y_test_reg_ad),callbacks=[monitor],verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_regularization_ad = model_regularization_ad.predict(x_test_reg_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5929731130599976\n",
      "R2 score: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_regularization_ad = np.sqrt(metrics.mean_squared_error(pred_regularization_ad,y_test_reg_ad))\n",
    "print(\"Final score (RMSE): {}\".format(score_regularization_ad))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg_ad, pred_regularization_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2628e5b0198>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropout\n",
    "\n",
    "model_dropout_ad = Sequential()\n",
    "model_dropout_ad.add(Dense(50, input_dim=x_train_reg_ad.shape[1]))\n",
    "model_dropout_ad.add(Dropout(0.1))\n",
    "\n",
    "model_dropout_ad.add(Dense(25, activation='relu'))\n",
    "model_dropout_ad.add(Dense(10, activation='relu'))\n",
    "model_dropout_ad.add(Dense(1))\n",
    "\n",
    "model_dropout_ad.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model_dropout_ad.fit(x_train_reg_ad,y_train_reg_ad,validation_data=(x_test_reg_ad,y_test_reg_ad),callbacks=[monitor],verbose=0,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_dropout_ad = model_dropout_ad.predict(x_test_reg_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.6190357208251953\n",
      "R2 score: 0.63\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_dropout_ad = np.sqrt(metrics.mean_squared_error(pred_dropout_ad,y_test_reg_ad))\n",
    "print(\"Final score (RMSE): {}\".format(score_dropout_ad))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg_ad, pred_dropout_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_602 (Dense)            (None, 50)                275650    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_603 (Dense)            (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_604 (Dense)            (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_605 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 277,196\n",
      "Trainable params: 277,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dropout_ad.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** Relu with Postal Code and Categories **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# one-hot cooding of postal codes \n",
    "\n",
    "postal_hotcoded_df = pd.get_dummies(merge_df['postal code'], sparse = 'true')\n",
    "\n",
    "x_matrix_postal = np.column_stack((x_matrix_minmax, postal_hotcoded_df))\n",
    "x_matrix_final = np.column_stack((x_matrix_postal, category_matrix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_stars_regression.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_matrix_final, y_stars_regression , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_postal.hdf5\", verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.9413 - val_loss: 0.4421\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44208, saving model to ./best_weights_relu_postal.hdf5\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3170 - val_loss: 0.3742\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44208 to 0.37424, saving model to ./best_weights_relu_postal.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2093 - val_loss: 0.3575\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37424 to 0.35753, saving model to ./best_weights_relu_postal.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1638 - val_loss: 0.3651\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35753\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1313 - val_loss: 0.3673\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35753\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1028 - val_loss: 0.3779\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35753\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0800 - val_loss: 0.3782\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35753\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0617 - val_loss: 0.3743\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35753\n",
      "Epoch 00008: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 2.0633 - val_loss: 0.4554\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35753\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3248 - val_loss: 0.3717\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35753\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2199 - val_loss: 0.3599\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35753\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1732 - val_loss: 0.3765\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35753\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1424 - val_loss: 0.3649\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35753\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1171 - val_loss: 0.3646\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35753\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0948 - val_loss: 0.3727\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35753\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0753 - val_loss: 0.3687\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35753\n",
      "Epoch 00008: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.8389 - val_loss: 0.4187\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35753\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3058 - val_loss: 0.3653\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35753\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2085 - val_loss: 0.3584\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35753\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1666 - val_loss: 0.3567\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35753 to 0.35674, saving model to ./best_weights_relu_postal.hdf5\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1401 - val_loss: 0.3663\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35674\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1182 - val_loss: 0.3665\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35674\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0990 - val_loss: 0.3758\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35674\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0811 - val_loss: 0.4122\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35674\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0713 - val_loss: 0.3933\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35674\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 2.1206 - val_loss: 0.4467\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35674\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3176 - val_loss: 0.3588\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35674\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2166 - val_loss: 0.3595\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35674\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1729 - val_loss: 0.3634\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35674\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1470 - val_loss: 0.3580\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35674\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1230 - val_loss: 0.3649\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35674\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.1021 - val_loss: 0.3656\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35674\n",
      "Epoch 00007: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.9521 - val_loss: 0.4372\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35674\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3187 - val_loss: 0.3603\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35674\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.2177 - val_loss: 0.3553\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35674 to 0.35528, saving model to ./best_weights_relu_postal.hdf5\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1743 - val_loss: 0.3615\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35528\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1494 - val_loss: 0.3784\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35528\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.1305 - val_loss: 0.3737\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35528\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.1128 - val_loss: 0.3706\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35528\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0969 - val_loss: 0.3807\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35528\n",
      "Epoch 00008: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 2.0013 - val_loss: 0.4503\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35528\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3293 - val_loss: 0.3730\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35528\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2186 - val_loss: 0.3593\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35528\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1745 - val_loss: 0.3607\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35528\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1447 - val_loss: 0.3775\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35528\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.1236 - val_loss: 0.3955\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35528\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.1049 - val_loss: 0.3805\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35528\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0846 - val_loss: 0.3794\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35528\n",
      "Epoch 00008: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.8931 - val_loss: 0.4522\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35528\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3150 - val_loss: 0.3734\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35528\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2157 - val_loss: 0.3534\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35528 to 0.35337, saving model to ./best_weights_relu_postal.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1724 - val_loss: 0.3605\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35337\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.1439 - val_loss: 0.3667\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35337\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1259 - val_loss: 0.3734\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35337\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.1069 - val_loss: 0.3798\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35337\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0862 - val_loss: 0.3871\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35337\n",
      "Epoch 00008: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 2.1675 - val_loss: 0.4668\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35337\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.3334 - val_loss: 0.3748\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35337\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2208 - val_loss: 0.3591\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35337\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1749 - val_loss: 0.3671\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35337\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1475 - val_loss: 0.3601\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35337\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1248 - val_loss: 0.3727\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35337\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.1053 - val_loss: 0.3716\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35337\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0870 - val_loss: 0.3809\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35337\n",
      "Epoch 00008: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 1.8176 - val_loss: 0.4323\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35337\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3115 - val_loss: 0.3653\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35337\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.2124 - val_loss: 0.3603\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35337\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1675 - val_loss: 0.3544\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35337\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.1392 - val_loss: 0.3716\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35337\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1150 - val_loss: 0.3790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35337\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0950 - val_loss: 0.3819\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35337\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0785 - val_loss: 0.3825\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35337\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.0659 - val_loss: 0.3955\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35337\n",
      "Epoch 00009: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 1.9074 - val_loss: 0.4366\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35337\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3191 - val_loss: 0.3612\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35337\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2128 - val_loss: 0.3630\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35337\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1684 - val_loss: 0.3515\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35337 to 0.35147, saving model to ./best_weights_relu_postal.hdf5\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.1350 - val_loss: 0.3645\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35147\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1052 - val_loss: 0.3665\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35147\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0825 - val_loss: 0.3652\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35147\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0650 - val_loss: 0.3724\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35147\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.0523 - val_loss: 0.3632\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35147\n",
      "Epoch 00009: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ReLU\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_postal.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars relu\n",
    "pred_reg_relu_stopping = model_reg_relu.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_relu_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 2.0, predicted Stars: [2.439553]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 2.5, predicted Stars: [3.9701362]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.390435]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 3.5, predicted Stars: [3.002405]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [3.9543777]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [5.473566]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [3.4923892]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 2.5, predicted Stars: [2.116056]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.3660235]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 5.0, predicted Stars: [4.863983]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_relu_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5928520560264587\n",
      "R2 score: 0.65\n"
     ]
    }
   ],
   "source": [
    "score_relu_postal = np.sqrt(mean_squared_error(y_test_reg,pred_reg_relu_stopping))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_postal))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_relu_stopping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Checkpointer sigmoid\n",
    "checkpointer_sigmoid_postal = ModelCheckpoint(filepath=\"./best_weights_sigmoid_postal.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 1.0841 - val_loss: 0.7533\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.75329, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.5629 - val_loss: 0.3704\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.75329 to 0.37037, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2973 - val_loss: 0.2891\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37037 to 0.28909, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.2282 - val_loss: 0.2746\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28909 to 0.27461, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1967 - val_loss: 0.2700\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.27461 to 0.26999, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1781 - val_loss: 0.2816\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26999\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.1639 - val_loss: 0.2801\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26999\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.1515 - val_loss: 0.2810\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26999\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.1433 - val_loss: 0.2879\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26999\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.1357 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26999\n",
      "Epoch 00010: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 2.0691 - val_loss: 0.9203\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26999\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.8395 - val_loss: 0.6737\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26999\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.5629 - val_loss: 0.4420\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26999\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.3637 - val_loss: 0.3297\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26999\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.2628 - val_loss: 0.2882\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26999\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.2140 - val_loss: 0.2815\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26999\n",
      "Epoch 7/100\n",
      " - 8s - loss: 0.1880 - val_loss: 0.2731\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26999\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.1686 - val_loss: 0.2723\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26999\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.1562 - val_loss: 0.2758\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26999\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.1446 - val_loss: 0.2790\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26999\n",
      "Epoch 11/100\n",
      " - 6s - loss: 0.1361 - val_loss: 0.2841\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26999\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.1289 - val_loss: 0.2898\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26999\n",
      "Epoch 00012: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 3.4963 - val_loss: 1.0022\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26999\n",
      "Epoch 2/100\n",
      " - 6s - loss: 1.0208 - val_loss: 0.9525\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26999\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.9098 - val_loss: 0.7593\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26999\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.6184 - val_loss: 0.4719\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26999\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.3798 - val_loss: 0.3379\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26999\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.2664 - val_loss: 0.2924\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26999\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.2134 - val_loss: 0.2771\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26999\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.1852 - val_loss: 0.2715\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26999\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.1663 - val_loss: 0.2728\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26999\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.1525 - val_loss: 0.2730\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26999\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.1418 - val_loss: 0.2755\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26999\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.1321 - val_loss: 0.2811\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26999\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.1250 - val_loss: 0.2846\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26999\n",
      "Epoch 00013: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 3.6421 - val_loss: 1.0020\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26999\n",
      "Epoch 2/100\n",
      " - 6s - loss: 1.0172 - val_loss: 0.9443\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26999\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.8921 - val_loss: 0.7363\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26999\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.6034 - val_loss: 0.4734\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26999\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.3934 - val_loss: 0.3551\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26999\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.2874 - val_loss: 0.3026\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26999\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.2319 - val_loss: 0.2820\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26999\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.1996 - val_loss: 0.2736\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26999\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.1790 - val_loss: 0.2704\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26999\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.1635 - val_loss: 0.2707\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26999\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.1517 - val_loss: 0.2725\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26999\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.1417 - val_loss: 0.2762\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26999\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.1332 - val_loss: 0.2800\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26999\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.1256 - val_loss: 0.2858\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.26999\n",
      "Epoch 00014: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 1.4456 - val_loss: 0.8170\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26999\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.6804 - val_loss: 0.5020\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26999\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.3988 - val_loss: 0.3350\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26999\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.2727 - val_loss: 0.2929\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26999\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.2207 - val_loss: 0.2759\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26999\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1934 - val_loss: 0.2771\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26999\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.1748 - val_loss: 0.2732\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26999\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.1607 - val_loss: 0.2782\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26999\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.1503 - val_loss: 0.2837\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26999\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.1406 - val_loss: 0.2876\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26999\n",
      "Epoch 11/100\n",
      " - 6s - loss: 0.1341 - val_loss: 0.2936\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26999\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.1272 - val_loss: 0.2973\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26999\n",
      "Epoch 00012: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 2.8987 - val_loss: 0.9634\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26999\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.9208 - val_loss: 0.7854\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26999\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.6731 - val_loss: 0.5314\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26999\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.4447 - val_loss: 0.3838\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26999\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.3179 - val_loss: 0.3164\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26999\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.2494 - val_loss: 0.2890\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26999\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.2107 - val_loss: 0.2776\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26999\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.1858 - val_loss: 0.2730\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26999\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.1682 - val_loss: 0.2732\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26999\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.1558 - val_loss: 0.2751\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26999\n",
      "Epoch 11/100\n",
      " - 6s - loss: 0.1452 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26999\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 0.1360 - val_loss: 0.2828\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26999\n",
      "Epoch 13/100\n",
      " - 6s - loss: 0.1283 - val_loss: 0.2859\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26999\n",
      "Epoch 00013: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 1.6044 - val_loss: 0.8682\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26999\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.7595 - val_loss: 0.5798\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26999\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.4616 - val_loss: 0.3629\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26999\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.2935 - val_loss: 0.2955\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26999\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.2281 - val_loss: 0.2771\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26999\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.1955 - val_loss: 0.2721\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26999\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.1760 - val_loss: 0.2751\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26999\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.1614 - val_loss: 0.2748\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26999\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.1491 - val_loss: 0.2943\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26999\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.1419 - val_loss: 0.2815\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26999\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.1327 - val_loss: 0.2863\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26999\n",
      "Epoch 00011: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 2.0033 - val_loss: 0.9245\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26999\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.8465 - val_loss: 0.6804\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26999\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.5538 - val_loss: 0.4207\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26999\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.3359 - val_loss: 0.3139\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26999\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.2443 - val_loss: 0.2895\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26999\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.2036 - val_loss: 0.2785\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26999\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.1809 - val_loss: 0.2779\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26999\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1642 - val_loss: 0.2746\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26999\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.1517 - val_loss: 0.2767\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26999\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1420 - val_loss: 0.2813\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26999\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.1336 - val_loss: 0.2843\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26999\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.1263 - val_loss: 0.2892\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26999\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.1204 - val_loss: 0.2931\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.26999\n",
      "Epoch 00013: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.3828 - val_loss: 0.8250\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26999\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.6836 - val_loss: 0.4891\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26999\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.3813 - val_loss: 0.3215\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26999\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2613 - val_loss: 0.2837\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26999\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.2131 - val_loss: 0.2743\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26999\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1876 - val_loss: 0.2729\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26999\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1711 - val_loss: 0.2758\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26999\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1575 - val_loss: 0.2834\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26999\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.1473 - val_loss: 0.2859\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26999\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1389 - val_loss: 0.2882\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26999\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.1311 - val_loss: 0.2946\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26999\n",
      "Epoch 00011: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 2.2783 - val_loss: 0.9111\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.26999\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.8163 - val_loss: 0.6458\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26999\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.5355 - val_loss: 0.4278\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26999\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.3560 - val_loss: 0.3319\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.26999\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.2677 - val_loss: 0.2938\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.26999\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.2207 - val_loss: 0.2799\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26999\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1934 - val_loss: 0.2739\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.26999\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1746 - val_loss: 0.2748\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.26999\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.1610 - val_loss: 0.2749\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26999\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1499 - val_loss: 0.2790\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26999\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.1408 - val_loss: 0.2821\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.26999\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.1336 - val_loss: 0.2880\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.26999\n",
      "Epoch 00012: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sigmoid\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_sigmoid = Sequential()\n",
    "\n",
    "    model_reg_sigmoid.add(Dense(60, input_dim=x_train_reg.shape[1], activation='sigmoid')) \n",
    "    model_reg_sigmoid.add(Dense(30, activation='sigmoid')) # Hidden 2\n",
    "    model_reg_sigmoid.add(Dense(1)) # Output\n",
    "    model_reg_sigmoid.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_sigmoid.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_sigmoid_postal],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_sigmoid.load_weights('./best_weights_sigmoid_postal.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Predict stars sigmoid\n",
    "pred_reg_sigmoid_postal = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 2.0, predicted Stars: [2.439553]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 2.5, predicted Stars: [3.9701362]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.390435]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 3.5, predicted Stars: [3.002405]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [3.9543777]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 5.0, predicted Stars: [5.473566]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [3.4923892]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 2.5, predicted Stars: [2.116056]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.3660235]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 5.0, predicted Stars: [4.863983]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_sigmoid_postal[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5928520560264587\n",
      "R2 score: 0.65\n"
     ]
    }
   ],
   "source": [
    "score_sigmoid_postal = np.sqrt(mean_squared_error(y_test_reg,pred_reg_sigmoid_postal))\n",
    "print(\"Final score (RMSE): {}\".format(score_sigmoid_postal))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_sigmoid_postal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting RMSE score for all regression models\n",
    "\n",
    "score_list_reg=[score_regularization,score_dropout,score_regularization_ad,score_dropout_ad,score_relu_postal ,score_sigmoid_postal ]\n",
    "names =['Regularization','Dropout', 'Regularization-postal','Dropout-postal','ReLU-postal','Sigmoid-Postal']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg)), score_list_reg)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
